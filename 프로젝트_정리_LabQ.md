
---

## 1. SK PharmaAIX MR Assistant

**프로젝트명**: SK Chemical PharmaAIX - MR Assistant (제약 영업 지원 AI 챗봇)
**기간**: 2024.07 ~ 현재 (진행 중, 약 6개월)
**역할**: AI 파트 리드 / 랩큐 팀 PL (랩큐 팀원 3명 + BCG RA 5~6명 리딩)

**기술스택**:
- Backend: FastAPI, Python
- Database: MariaDB, Qdrant (Vector DB), AWS Redshift, Redis
- AI/ML: LangChain, LangGraph, Azure OpenAI API
- Infrastructure: Azure, Docker
- Collaboration: Slack, Jira, Confluence

**프로젝트 개요**:
- SK Chemical 제약 제품을 영업하는 MR(Medical Representative) 약 350명을 위한 AI 챗봇
- 영업활동 기록, 제품 정보 검색, 고성과자 노하우 공유를 통한 성과 향상 지원
- 제약 도메인 특화 RAG 기반 질의응답 시스템

**프로젝트 배경**:
- SK Chemical 주관, SK Discovery, BCG, 백엔드/프론트 업체, QA 업체, RAG 전문 업체 등 다수 업체 참여
- 운영 인수인계 목적으로 투입되었으나, 프로젝트 오픈 지연 및 다수 문제 발견
- BCG PM 다음으로 AI 파트 리더 역할 수행
- BCG RA(Research Analyst) 5~6명 (3개월마다 교체, 총 15명 경험) 및 랩큐 팀원 3명 리딩
- 추진팀, 인프라팀, 보안팀, QA팀, 백엔드, 프론트 등 거의 모든 팀과 협업

#### 담당 업무:

**1) AI 파트 리딩 및 멀티 팀 협업**
- BCG PM 다음으로 AI 파트 전체 리더 역할
- BCG RA 5~6명 (3개월 로테이션, 총 15명) 업무 분담 및 관리
- 랩큐 팀원 3명 PL 역할 (요구사항 분석, 일정 관리, 코드 리뷰)
- 추진팀, 인프라팀, 보안팀, QA팀, 백엔드, 프론트 등 다수 팀과 협업 및 조율

**2) 서비스 아키텍처 재설계**
- 기존 Chain 기반 챗봇 구조의 문제점 파악 및 개선
- **LangGraph 기반 Multi-Agent Supervisor 구조로 전환**:
  - Supervisor Agent: 사용자 질문 분석 및 적절한 하위 에이전트 호출
  - 다양한 Tool Agent 설계 및 구현 (MariaDB 조회, Qdrant 검색, Redshift 분석 등)
  - Agent 간 워크플로우 조율 및 응답 생성
- **Chain + Agentic 하이브리드 구조**:
  - 단순 질문: Chain 기반 빠른 응답
  - 복잡한 질문: Multi-Agent 기반 단계별 처리

**3) Vector Database 교체 (LanceDB → Qdrant)**
- 기존 LanceDB의 성능 및 확장성 문제 분석
- Qdrant로 마이그레이션:
  - 하이브리드 검색 (Dense + Sparse) 구현
  - 컬렉션 관리 및 임베딩 파이프라인 재구축
  - 검색 정확도 및 속도 향상

**4) 성능 고도화**
- **응답 속도 개선**:
  - 기존: 평균 3분 이상
  - 개선: 평균 30초 (약 83% 개선)
  - 비동기 처리, 캐싱 전략, Agent 워크플로우 최적화

- **답변 커버리지 및 품질 개선**:
  - 기존: 1,000개 질문 중 30%만 답변 가능
  - 개선: 100% 답변 가능 (설계 목적 외 질문도 대응)
  - 현재: AIX팀 검토 반복 후 99% 만족도 달성

- **세밀한 데이터 조회**:
  - MariaDB: 영업활동 기록, 제품 정보 등 구조화 데이터 조회
  - Qdrant: 문서 기반 제품 정보, 고성과자 노하우 검색
  - Redshift: 데이터 분석 및 집계

**5) 실시간 스트리밍 응답 구현**
- Server-Sent Events (SSE) 기반 스트리밍 적용
- 사용자 경험 개선 (실시간 응답 피드백)
- 긴 응답 시간에 대한 사용자 불만 해소

**6) 제약 도메인 특화 RAG 시스템 구축**
- 제약 제품 정보, 의약품 정보, 영업 노하우 등 도메인 지식 임베딩
- 약 350명 MR 사용자 맞춤형 답변 생성
- 영업활동 기록 기반 개인화 추천

**7) 품질 관리 및 테스트**
- AIX팀과 협업하여 1,000개 질문 기반 정성 평가
- 검토 & 개선 사이클 반복
- 99% 만족도 달성 (현재 진행형)

**8) 기술적 문제 해결 시도**
- **LLM 고유명사 오표기 문제 분석**:
  - 문제: OpenAI GPT가 제품명 "토스젯에이" 등 고유명사 자주 오타 (토크나이저가 (토스)(젯)(에이)로 분리)
  - 원인 분석: Transformer 구조상 다음 토큰 예측 모델 + 희귀 단어의 낮은 학습 빈도
  - 해결 시도: 커스텀 토크나이저 도입 제안 (user-defined tokens 추가)
  - 상태: 오픈 일정으로 인해 중장기 계획으로 이관

- **Context Engineering 제안**:
  - 문제: SK의 세밀한 요구사항으로 프롬프트 과도하게 증가 (Context 길이 한계)
  - 제안: Context Engineering (프롬프트 최적화, 동적 Context 구성)
  - 상태: 오픈 일정으로 인해 중장기 계획으로 이관

#### 프로젝트 핵심 목표:

**비즈니스 목표**:
- **MR 인당 생산성 11% 향상** (BCG 예상치)
- SK Chemical 제약 영업 MR 약 350명의 성과 향상 지원

**해결 방법: 4R 전략**
- **Right Target**: 적절한 타겟 고객 식별 및 추천
- **Right Product**: 고객 상황에 맞는 적절한 제품 추천
- **Right Message**: 효과적인 메시지 전달 전략 제공
- **Right Timing**: 최적의 타이밍 제안

---

#### Multi-Agent Supervisor 아키텍처 진화 (V1 → V2 → V3):

**V1: 완전 Chain 방식**
- **문제점**:
  - Orchestrator + Chain 방식으로 지나치게 지엽적
  - 설계된 specific한 질문만 답변 가능
  - 대부분의 실제 사용자 질의에 대답 불가
  - 응답 속도 3분 이상, 커버리지 30% 수준

**V2: Multi-Agent Supervisor 전환 (1차 재설계)**
- **변경 사항**:
  - Agentic Supervisor Multi-Agent 아키텍처로 전환
  - Supervisor가 사용자 질문 분석 후 적절한 Agent 호출
- **문제점**:
  - 많은 개발자들이 설계 의도대로 구현하지 못함
  - 아키텍처 이해도 부족으로 인한 구현 오류

**V3: 완전 재설계 (2차 재설계)**
- **변경 사항**:
  - Agent 구조, init, tool까지 직접 제작하여 배포
  - 개발자들이 그대로 사용할 수 있도록 완성된 형태로 제공
  - Chain + Agentic 하이브리드 구조
- **결과**:
  - 응답 속도 83% 개선 (3분 → 30초)
  - 답변 커버리지 233% 향상 (30% → 100%)
  - 답변 품질 99% 만족도 달성

---

#### 성능 개선 상세 과정:

**1) Vector DB 마이그레이션 (LanceDB → Qdrant)**
- **이유**: LanceDB가 어마어마하게 느림
- **효과**: 검색 속도 대폭 향상, 하이브리드 검색 지원

**2) 캐싱 전략**
- **Redis**: SQL Query - 응답 캐싱
- **Qdrant**: 챗봇 응답 캐싱
- **효과**: 반복 질의 시 즉시 응답

**3) 병렬처리 및 Forward Tool**
- **대상**: 1분 30초 ~ 3분 걸리는 오래 걸리는 질문
- **효과**: 50초대로 단축

**4) Agent 워크플로우 최적화**
- 불필요한 Agent 호출 제거
- Tool 호출 순서 최적화

---

#### 고객 만족도 99% 달성 방법:

**엑셀 기반 평가 프로세스**:
1. **질문 데이터셋**:
   - 전체 약 2,000개 질문
   - 주요 질문 약 300개 선별
   - 고성과자 질의 포함

2. **반복 개선 사이클** (약 10회 반복):
   - 챗봇 답변 엑셀 시트로 전달
   - 고객(최원철M님 등) 피드백 수집
   - 수정 후 재전달
   - 피드백 반영 방법:
     - **프롬프트 개선**: 고객 요구사항 구체화
     - **툴 추가 제작**: 부족한 기능 개발
     - **Few-shot 추가**: 예시 답변 제공

3. **반박 불가 전략**:
   - 고객이 직접 채점하고 피드백한 내용 100% 반영
   - "니네가 원하는대로 했는데?" 라는 논리로 고객 만족도 확보

---

#### BCG 프로젝트 전략 방식:

**Big Question → Sub-Question → Research 구조**
- SK 프로젝트에서 어느 정도 사용
- 큰 문제를 세부 질문으로 분해하여 해결

**이슈 관리 프로세스**:
1. 이슈 발생
2. Jira 티켓 생성 (현상, 재현방법 위주)
3. 팀장이 BE/FE/AI/인프라 팀으로 분배
4. AI 리더(본인)가 기술적 해결 방법 고려하여 티켓 생성

---

#### 프로젝트 도전 과제 및 극복:

**1) 대규모 인력 관리**
- **도전**: 다수 인턴급 RA(15명) + 타 업체 개발자 코드 리뷰 및 관리
- **어려움**: 물리적 시간 부족으로 세밀한 PR 리뷰 어려움
- **상황**: 한국자동차연구원 프로젝트 동시 진행으로 업무 과중 (주말 포함 매일 새벽 2시까지 근무 경험)
- **극복**: V3 아키텍처로 완성된 구조 제공, 명확한 가이드라인 제시

**2) 대기업 보안 정책**
- **도전**: 방화벽 신청 등 보안 승인 프로세스
- **구체적 사례**:
  - 방화벽 신청 → 승인 → 작업 완료까지 **5일 소요**
  - 담당자 전달 문제: 방화벽만 뚫고 SG(Security Group) 설정 담당자에게 미전달
  - 직접 원인 찾아서 해결해야 함
- **극복**: 사전에 모든 담당자 파악, 직접 커뮤니케이션

**3) 대규모 협업의 어려움**
- **도전**:
  - 약 10개 팀과 빈번한 회의 (추진팀, 인프라팀, 보안팀, QA팀, 백엔드, 프론트 등)
  - 수많은 회의, 오래 걸리는 의사결정
- **구체적 사례**:
  - 담당자들이 너무 많아 여러 팀의 협의 필요
  - 대부분 변경을 싫어함 ("20년 전에 멈춰있다"는 느낌)
  - 뭔가 바꾸려 하면 그 일이 다 내 일로 돌아옴
- **극복**:
  - 명확한 문서화 및 사전 조율
  - 변경 최소화 전략 (꼭 필요한 것만 변경)

**4) 기술 부채 관리**
- **도전**: 레거시 코드 개선 (Chain → Multi-Agent) 동시에 신규 기능 개발
- **극복**: 단계적 마이그레이션, 품질 유지하면서 빠른 오픈 일정 맞추기

#### 주요 성과:

- **응답 속도 83% 개선**: 3분 → 30초
- **답변 커버리지 233% 향상**: 30% → 100%
- **답변 품질 99% 만족도** 달성 (AIX팀 정성 평가)
- **Multi-Agent Supervisor 구조** 설계 및 구현
- **Vector DB 마이그레이션** 성공 (LanceDB → Qdrant)
- **멀티 팀 협업 경험** (약 10개 팀과 소통 및 조율)
- **대규모 팀 리딩 경험** (BCG RA 15명 + 랩큐 팀원 3명)

---

#### 배운 점 및 성장:

**1) 아키텍처 설계의 중요성**
- **교훈**: 개발자들이 이해하고 따라할 수 있는 명확한 구조 제공이 중요
- **사례**: V2에서 V3로 재설계한 이유가 개발자들의 구현 어려움
- **성장**: 완성된 구조(Agent, init, tool)를 제공하여 팀 생산성 향상

**2) 고객 중심 개발의 힘**
- **교훈**: 고객이 직접 채점하고 피드백하면 만족도를 극대화할 수 있음
- **방법**: 약 10회 반복 개선 사이클로 99% 만족도 달성
- **성장**: "니네가 원하는대로 했는데?" 전략으로 반박 불가 논리 구축

**3) 대기업 문화 이해**
- **교훈**: 변경을 싫어하는 조직 문화 이해
- **사례**: "20년 전에 멈춰있다"는 느낌, 변경 시 모든 일이 내 일로 돌아옴
- **성장**:
  - 변경 최소화 전략 수립
  - 사전 조율 및 명확한 문서화로 리스크 감소
  - 보안 프로세스 이해 (방화벽 신청 5일, 담당자 파악 중요성)

**4) 성능 최적화 경험**
- **교훈**: 병목 지점을 정확히 파악하고 단계적으로 개선
- **성과**:
  - LanceDB → Qdrant 마이그레이션으로 검색 속도 대폭 향상
  - 캐싱, 병렬처리, Forward Tool 조합으로 3분 → 50초
- **성장**: 데이터 기반 의사결정 능력 향상

**5) 멀티 팀 협업 및 커뮤니케이션**
- **교훈**: 10개 팀과 협업하려면 명확한 커뮤니케이션과 문서화 필수
- **협업한 전문가들**:
  - 글로벌 컨설팅사 (BCG) PM 및 컨설턴트
  - 클라우드 인프라 전문가 (AWS 아키텍트)
  - RAG 전문 개발 업체
  - 백엔드/프론트엔드 개발 전문 업체
  - QA 전문 업체
  - 케미칼 DT팀, 추진팀, 인프라팀, 보안팀
  - DBA (Database Administrator)
  - 부하 테스트 전문가
  - 3개월마다 교체되는 BCG RA 15명
- **각 분야 전문가에게 배운 점**:
  - **PM/컨설턴트**: Big Question → Sub-Question 구조로 문제 분해하는 사고방식
  - **인프라 전문가**: 보안 정책, 방화벽 신청 프로세스의 중요성 및 담당자 사전 파악의 필요성
  - **QA 전문가**: 체계적인 테스트 케이스 작성 방법론 (재현 가능성, 엣지 케이스)
  - **DBA**: 데이터 스키마 설계 시 장기적 관점과 확장성 고려
  - **부하 테스트 전문가**: 성능 병목 지점을 찾는 체계적인 방법론
  - **RAG 전문가**: 도메인 특화 임베딩 전략 및 하이브리드 검색 구현 노하우
- **프로젝트의 가장 큰 장점**:
  - 각 분야 최고 전문가들의 일하는 방식을 직접 관찰하고 배울 수 있었음
  - "이 사람은 왜 이렇게 접근하지?"를 끊임없이 고민하며 다양한 시각 습득
  - 단순히 협업이 아니라 각 전문가의 사고방식을 내 것으로 만드는 과정
- **어려움**: 수많은 회의, 오래 걸리는 의사결정
- **성장**:
  - 이슈 관리 프로세스 체계화 (Jira 티켓, 명확한 재현 방법)
  - 담당자 사전 파악 및 직접 커뮤니케이션
  - 불필요한 변경 제거
  - 각 전문가의 관점에서 문제를 바라보는 능력 향상
  - "내 방식이 최선인가?"를 항상 성찰하는 습관

**6) 기술 깊이의 중요성**
- **사례**: LLM 고유명사 오표기 문제를 토크나이저 레벨까지 분석
- **성장**: 표면적 증상이 아닌 근본 원인까지 파고드는 문제 해결 능력
- **한계 인식**: 오픈 일정으로 인해 커스텀 토크나이저 도입은 중장기 계획으로 이관
  - 이상적인 해결책과 현실적인 제약 사이의 균형 필요성 학습

---

## 2. 한국자동차연구원 AI 에이전트 개발

**프로젝트명**: 자동차 분야 특화 통합 데이터 관리 및 AI Agent
**기간**: 2024.03 말 ~ 2025.11 (약 1년 8개월)
**역할**:
- 1~2차: 1인 풀스택 개발 (2024.03~2024.10, 약 7개월)
- 3~4차: 메인 PL / 팀 3명 (본인 포함 개발자 3명) (2024.05~2025.11, 약 1년 6개월)

**기술스택**:
- Backend: FastAPI, Python, Celery, Redis
- Frontend: Next.js, React, TypeScript, BlockNote Editor
- Database: PostgreSQL (Kysely ORM), Qdrant (Vector DB)
- AI/ML: LangChain, LangGraph, OpenAI API (GPT-3.5/4/4o), Claude
- Infrastructure: Docker, Docker Compose, Nginx, Linux Server
- Authentication: Keycloak (SSO)
- Monitoring: LangSmith, DataDog
- 기타: Server-Sent Events (SSE)

---

### 1~2차 개발 (2024.03 말 ~ 2024.10, 약 7개월)
**역할**: 1인 풀스택 개발

#### 담당 업무:

**1) 서버 인프라 구축 및 배포**
- Docker Compose 기반 멀티 컨테이너 환경 구축
  - Web (Flask, Celery, Redis), MySQL, Nginx 컨테이너 구성
- 한국자동차연구원 내부 서버 (10.10.0.31) 배포 및 운영
- HTTPS 적용 및 도메인 설정 (https://agent.bigdata-car.kr/)
- VPN 및 SSH 접속 환경 설정

**2) 인증 및 권한 관리**
- Keycloak 기반 SSO(Single Sign-On) 로그인 시스템 구현
- KADaP에 Agent Client 등록 및 OAuth 2.0 토큰 관리
- 세션 기반 사용자 인증 및 권한 검증 로직 구현

**3) RAG 기반 보고서 자동 생성 시스템**
- **데이터 소스 관리**:
  - 사전 공개 데이터 / 공개 데이터 / 비공개 데이터 3단계 분류
  - 마이디스크 연동 파일 업로드 및 관리 시스템
  - 주기적 동기화 및 수동 동기화 버튼 구현
- **파일 처리 파이프라인**:
  - PDF, DOCX, PPTX 파일 자동 파싱 (pypdf, docx2txt, python-pptx)
  - RecursiveCharacterTextSplitter를 활용한 문서 청킹 (chunk_size=1000, overlap=200)
  - OpenAI Embeddings API를 통한 벡터 임베딩 생성
- **보고서 생성 엔진**:
  - 사용자 정의 프롬프트 및 조사 목적 기반 보고서 생성
  - DALL-E 3 연동 이미지 자동 생성 기능
  - 출처 표기 UI (PDF 페이지 번호 포함)

**4) 챗봇 시스템 구현**
- 각 자료조사별 독립적인 챗봇 세션 관리
- Chat history 저장 및 컨텍스트 유지
- RAG 기반 질의응답 (Qdrant Vector DB 활용)
- LangChain Agent 구조로 구현
- 참조 자료 출처 표기 기능

**5) 파일 및 폴더 관리**
- 마이디스크 마운트 및 파일 CRUD 구현
- 폴더 계층 구조 관리 (최대 10단계 깊이 제한)
- 파일 검색, 필터링, 정렬 기능
- 공개/비공개 파일 권한 관리

**6) UI/UX 개발**
- React 기반 반응형 웹 인터페이스
- 사이드바 자료 수집 목록 (작성중/완료 구분)
- 파일 드래그앤드롭 업로드
- 리스트/그리드 뷰 전환

**7) Private Model 연동**
- 내부 Private LLM 모델 연동 (LangChain을 통한 모델 추상화)
- 모빌리티 인사이트 챗봇에 Private Model 적용
- 모델 선택 드롭다운 UI 구현

**8) 벡터 DB 별 챗봇 생성**
- 모빌리티 인사이트 데이터 기반 챗봇
- 한국자동차공학회 최근 10년 논문 챗봇
- 기업 소개 자료 + 웹 데이터 통합 챗봇
- 각 챗봇별 독립적인 Qdrant 컬렉션 관리

**9) 관리자 기능 개발**
- 관리자 페이지 UI 설계 및 구현
- 자료 검색 기능 (제목, 작성자)
- 자료 분류(벡터 DB) 별 탭 및 폴더 설명 문구 작성 영역
- 유저 등록 자료 관리 (공개/비공개 분류)

**10) 토큰 사용량 추적 및 비용 계산**
- LLM API 호출 시 토큰 사용량 실시간 계산
- 모델별 가격 적용 (GPT-3.5/4, Claude 등)
- 사이드바 하단에 사용자별 토큰 사용량 표시
- 일별/주별/월별 사용량 통계 및 그래프

**11) UI/UX 개선**
- 파일 목록 검색 기능
- 자료 분류별 탭 제공 및 설명 문구
- 타인 제공 자료 / 연구원 제공 자료 / 개인 보유 자료 구분
- 보고서 생성 중 리셋 알림 (Toastr)
- 로그 색깔 부여 및 사이드바 스크롤 하단 고정
- 이중 스크롤 문제 해결

---

### 3~4차 개발 (2024.10 ~ 2025.11, 약 1년 1개월)
**역할**: 메인 PL (팀 3명: 본인 포함 개발자 3명)

#### 담당 업무:

**1) 프로젝트 리딩 및 아키텍처 설계**
- 전체 시스템 아키텍처 재설계 (Flask → FastAPI 마이그레이션)
- Next.js App Router 기반 프론트엔드 구조 설계
- API 설계 및 데이터베이스 스키마 설계
- 팀원 코드 리뷰 및 기술 가이드
- 프로젝트 일정 관리 및 요구사항 분석

**2) LangGraph 기반 멀티 에이전트 시스템**
- **Research Agent**:
  - Multi-Query 생성 (1개 질문 → 3~5개 검색 쿼리)
  - 하이브리드 검색: Dense (Cosine Similarity) + Sparse (BM25)
  - Reciprocal Rank Fusion 알고리즘으로 결과 병합
  - 웹 검색 (DuckDuckGo API) 연동
- **Report Agent**:
  - 검색 결과 기반 보고서 계획 수립
  - 섹션별 내용 생성 (참조 자료 인용)
  - 최종 수정 및 개선
- **Supervisor Agent**:
  - LangGraph Supervisor 패턴으로 에이전트 조율
  - 에이전트 간 상태(State) 전달 및 관리
  - PostgreSQL Checkpointer로 에이전트 상태 영속화

**3) 실시간 스트리밍 응답 시스템**
- Server-Sent Events (SSE) 기반 스트리밍 구현
- LLM 응답을 청크 단위로 실시간 전송
- 툴 콜링 상태 표시 ("검색 중", "작성 중" 등)
- 참조 자료 목록 실시간 업데이트
- 스트림 타임아웃 (2분) 및 에러 핸들링
- 네트워크 중단 시 재연결 로직

**4) 캐싱 레이어 구축**
- Redis 기반 검색 결과 캐싱
- 캐시 키 생성 전략 (쿼리 + 필터 조건 해시)
- TTL 1시간 설정 및 LRU 정책
- 캐시 히트율 추적
- 데이터 업데이트 시 캐시 무효화

**5) 보고서-채팅 연동 기능**
- 채팅 세션에서 보고서 생성 기능 ("보고서로 만들기")
- 보고서에서 채팅으로 편집 기능 ("채팅으로 편집")
- 보고서-채팅 연결 관계 저장 (report_chat_sessions 테이블)
- 멀티 세션 연결 지원

**6) BlockNote 에디터 통합**
- BlockNote 기반 WYSIWYG 에디터 통합
- 마크다운, 코드 블록, 이미지, 링크 삽입
- 보고서 버전 관리 및 비교 기능
- 이전 버전 복원 기능
- 자동 저장 기능
- PDF, HTML, Markdown 다운로드

**7) 파일 처리 고도화**
- XLSX 데이터 추출 (pandas, openpyxl)
- 대용량 파일 청크 단위 처리 (100MB+)
- 손상된 파일 에러 처리 및 재시도 로직
- 다중 파일 병렬 파싱
- 파싱 메타데이터 저장 (페이지 수, 단어 수 등)
- MIME 타입 기반 파일 형식 자동 감지

**8) Qdrant 벡터 DB 고도화**
- 하이브리드 검색 (Dense + Sparse 벡터)
- 메타데이터 필터링 (특정 파일/폴더만 검색)
- 배치 업로드 최적화 (배치 크기 100개)
- 중복 벡터 제거 (유사도 0.99 이상)
- 벡터 백업 및 복원 (스냅샷)
- 컬렉션 관리 (벡터 차원, 거리 메트릭 설정)

**9) API 설계 및 구현**
- RESTful API 설계 (12개 주요 엔드포인트)
- API 키 생성 및 관리 (OpenAI, Claude 등)
- API Rate Limiting
- 유효성 검사 및 에러 핸들링
- 인증/권한 검증 미들웨어

**10) 포괄적인 테스트 케이스 작성**
- 200+ 시나리오 테스트 케이스 작성
- 통합 테스트 (Qdrant, Redis, PostgreSQL)
- 보안 테스트 (SQL Injection, XSS, CSRF 방어)
- 성능 테스트 (동시 100명 접속, 10만 벡터 검색)
- 엣지 케이스 처리 (동시 업로드, 최대 파일 개수, 토큰 제한 초과 등)

**11) 챗봇 데이터 소스 관리**
- 파일, 컬렉션, 폴더를 데이터 소스로 추가
- 데이터 소스 우선순위 및 가중치 설정 (0.1~1.0)
- 데이터 소스 활성화/비활성화
- 데이터 소스별 사용 통계 (검색 횟수, 참조 횟수)

**12) 보고서 생성 UI/UX**
- 모델 선택 (GPT-3.5/4, Claude 등)
- 문체 선택 (-이다, -입니다, -함)
- 웹 검색 ON/OFF 토글
- 참고 자료 선택 (벡터스토어 + 개별 파일 다중 선택)
- 생성 과정 실시간 표시 (툴 콜링, 참조 자료)

**13) 권한 및 보안**
- 파일 접근 권한 검증 (소유자 또는 공개 파일만)
- API 키 암호화 저장
- 세션 관리 및 쿠키 보안 설정
- 민감 정보 로깅 방지
- HTTPS 적용

**14) 멀티 파일 파서 통합 (4차 - RAG용 임베딩 SW 모듈)**
- **4개 파서 통합 및 성능 비교**:
  - Upstage Document Parser (지원: PDF, DOC, DOCX, XLSX, PPT, PPTX, HWP, PNG, JPG)
  - LlamaParse (지원: PDF, DOC, DOCX, CSV, XLSX, PPT, PPTX, PNG, JPG)
  - Docling (지원: PDF, DOCX, CSV, XLSX, PPTX, PNG, JPG)
  - Unstructured (지원: PDF, DOC, DOCX, CSV, XLSX, PPT, PPTX, PNG, JPG)
- 파서별 지원 파일 형식 검증 및 에러 처리
- 파서별 비용 및 성능 분석 자료 작성

**15) 기본 파일 파서 설정 기능**
- 대시보드 파서 설정 섹션 UI 구현
  - 4개 파서 소개글, 지원 파일 형식, 비용 정보 표시
  - 기본값: Upstage
- 사용자별 기본 파서 선택 및 저장 기능
- API 엔드포인트 구현:
  - `GET /api/preferences/[userID]/parser`: 기본 파서 조회
  - `PUT /api/preferences/[userID]/parser`: 기본 파서 업데이트
- 유효하지 않은 파서 타입 검증 및 에러 처리

**16) 파일 업로드 및 파싱 통합**
- **챗봇/보고서 채팅창 파일 첨부 기능**:
  - 파일 첨부 버튼 클릭 업로드 및 드래그앤드롭
  - 기본 파서 지원 파일 형식 검증
  - 지원하지 않는 파일 형식 에러 처리
- **자료 관리 페이지 파일 파싱**:
  - 원하는 파서 선택 후 파싱 시작
  - 파싱 결과 JSON, HTML, Markdown, 테이블, 이미지 저장
  - 마이디스크 저장 경로: `/mnt/labq/USER/{user_id}/tools/agent/uploads/{파일명}_{파서명}_{날짜}/`

**17) 파싱 결과 시각화**
- PDF 문서 렌더링 (마우스 휠/줌 버튼으로 배율 조절)
- Markdown 뷰어 (파싱 결과 텍스트 표시)
- Interactive Highlight:
  - PDF 원문 마우스 호버 → 해당 Markdown 문단 노란색 하이라이트
  - Markdown 문단 마우스 호버 → 해당 PDF 문단 노란색 하이라이트
  - 파싱 성능 실시간 확인 가능

**18) 파싱 데이터 저장 및 벡터화**
- PostgreSQL 저장: files 테이블에 파싱된 파일 메타데이터 저장
- Qdrant 벡터스토어 저장: user_uploads 컬렉션에 임베딩 후 벡터 저장
- 파싱 결과 청킹 및 임베딩 생성
- 메타데이터 (파일명, 페이지 번호, 파서 타입) 함께 저장

**19) 엣지 케이스 처리**
- 특수 문자 파일명 처리, 긴 파일명 (255자 초과) 잘림 처리
- 중복 파일명 자동 넘버링
- 빈 파일 (0바이트) 업로드 에러 처리
- 유니코드 파일명 (한글, 일본어, 이모지) 인코딩 처리

---

### 주요 성과:

**기술적 성과**:
- 1인 개발에서 3명 팀 PL로 성장하며 1년 8개월간 프로젝트 전 단계 주도
- **전체 시스템 아키텍처 재설계 및 마이그레이션**:
  - Backend: Flask → FastAPI
  - Frontend: HTML/CSS/JS → Next.js + React
  - Vector DB: ChromaDB → Qdrant
  - 성능 개선 및 비동기 처리 도입
- LangGraph 멀티 에이전트 아키텍처 설계 및 구현으로 복잡한 AI 워크플로우 구현
- 하이브리드 검색 (Dense + Sparse) 도입으로 검색 정확도 향상
- Redis 캐싱 레이어 도입으로 반복 검색 성능 개선
- SSE 스트리밍으로 사용자 경험 개선 (실시간 응답)
- 4개 파일 파서 통합 및 성능 비교로 문서 파싱 정확도 향상

**정량적 성과**:
- **보고서 작성 시간 98% 단축**: 1시간 → 1분
  - 기존: 제안서 작성에 약 1시간 소요
  - 개선: AI 기반 자동 생성으로 약 1분으로 단축
  - 핵심: 프롭 프로젝트의 RAG 기반 자동 생성 원리를 한국자동차연구원 도메인에 이식

**프로젝트 관리 성과**:
- 200+ 테스트 케이스 작성으로 시스템 안정성 확보
- 체계적인 API 설계 및 문서화로 프론트엔드-백엔드 협업 효율화
- Docker 기반 배포 환경 구축으로 일관된 개발/운영 환경 제공
- Keycloak SSO 연동으로 사내 통합 인증 시스템 구축

**사용자 경험 성과**:
- 보고서 자동 생성으로 업무 시간 단축 (1시간 → 1분, 98% 개선)
- 챗봇 기반 사내 문서 검색으로 정보 접근성 향상
- 실시간 스트리밍 응답으로 AI 생성 과정 투명성 제공
- 멀티 파서 지원으로 다양한 문서 형식 처리 가능

---

## 2. 그린텍 하수처리공정 수질 예측 및 이상탐지

**프로젝트명**: 하수처리장 AI 프로젝트
**클라이언트**: (주)그린텍아이엔씨
**기간**: 2024.07.29 ~ 2024.11.30 (약 4개월)
**역할**: PL (팀 2명: 본인 포함)

**기술스택**:
- ML/DL: PyTorch, LightGBM, XGBoost, CatBoost, PyOD, COMBO, NumPy, Pandas, Numba
- Visualization: Matplotlib, Seaborn, Plotly Dash
- Backend: Flask, Gunicorn
- Time Series: statsmodels
- Development: Jupyter Notebook, Poetry
- Deployment: Docker

**주요 기능**:
- 하수처리 공정 단계별 수질 예측 모델 개발
- 실시간 이상 탐지 및 알림 시스템

#### 담당 업무: PL 겸 메인 개발자

**1) 데이터 분석 및 전처리**
- RTIS, ERP 시스템에서 수집한 공정 데이터 분석
- 인풋 데이터: ES-10/20 온도, 레벨, 압력, (열매/물) 유량, ES-20 COOH 분석값 등
- 타겟: ES-20 COOH 예측값
- 결측치 처리, 이상치 제거, 피처 엔지니어링
- 시계열 데이터 전처리 및 윈도우 생성

**2) 수질 예측 모델 개발**
- **앙상블 모델 개발**:
  - LightGBM, XGBoost, CatBoost 3개 모델 앙상블
  - 하이퍼파라미터 튜닝 (Optuna)
  - PyTorch 기반 딥러닝 모델 (LSTM, GRU) 실험
- **Time Series 모델링**:
  - statsmodels를 활용한 ARIMA, SARIMA 모델 실험
  - 시계열 분해 및 트렌드 분석
- **모델 성능 평가**:
  - RMSE, MAE, R² Score 기반 평가
  - Cross-validation 및 Time Series Split

**3) 이상 탐지 시스템**
- **PyOD 기반 이상 탐지**:
  - Isolation Forest, LOF, CBLOF 등 10+ 알고리즘 실험
  - COMBO를 활용한 앙상블 이상 탐지
  - 이상치 스코어 계산 및 임계값 설정
- **실시간 모니터링**:
  - 예측값과 실측값 비교
  - 임계값 초과 시 알림 트리거

**4) 시각화 대시보드**
- Plotly Dash 기반 실시간 모니터링 대시보드 개발
- 공정 단계별 수질 예측값 및 실측값 시각화
- 이상 탐지 알림 표시
- Matplotlib, Seaborn 기반 분석 리포트 자동 생성

**5) 배포 및 운영**
- Flask + Gunicorn 기반 API 서버 구축
- Docker 컨테이너화 및 배포
- 모델 버전 관리 및 재학습 파이프라인 구축

**6) 프로젝트 관리**
- 클라이언트 요구사항 분석 및 일정 관리
- 주간 진행 상황 보고 및 피드백 반영
- 팀원 업무 분담 및 코드 리뷰

#### 주요 성과:

**정량적 성과**:
- **수질 예측 모델 고성능 달성**:
  - T-N 방류수 예측: R² 0.9244 (RandomForest)
  - TOC 방류수 예측: R² 0.8640 (CatBoost)
  - BOD 방류수 예측: R² 0.7543 (ExtraTrees)
  - TOC 최초침전지 유출수 1단: R² 0.7977 (ExtraTrees)
  - pH 최초침전지 유출수 1단: R² 0.7439 (ExtraTrees)

- **이상 탐지 모델 고정확도 달성**:
  - Random Forest: Accuracy 98.50%, F1-score 98.39%
  - XGBoost: Accuracy 97.37%, F1-score 97.07%
  - SVM: Accuracy 96.99%, F1-score 95.51%

- **19개 타겟 변수 예측 모델 개발**:
  - 최초침전지 유출수 1단/2단 (각 6개 변수: pH, BOD, TOC, SS, T-N, T-P)
  - 방류수 (6개 변수: pH, BOD, TOC, SS, T-N, T-P)
  - 슬러지 발생량 (1개 변수)

**비즈니스 임팩트**:
- ES-20 COOH 예측 모델 개발로 품질 Hunting 최소화
- 예측값 기반 온도/유량 사전 Action으로 안정 운전 가능
- 이상 탐지 시스템으로 공정 이상 조기 발견 (98.5% 정확도)

---

## 3. 프랍(PROP) - 제안서 작성 AI Agent

**프로젝트명**: 제안서 및 문서 생성 자동화 시스템
**회사**: (주)랩큐 자체 프로젝트
**기간**: 2024.03 ~ 2024.04 (약 2개월)
**역할**: 유지보수 및 추가 개발 (기존 시스템 개선)

**기술스택**:
- Backend: Flask, Celery, Redis, MySQL
- Frontend: HTML, JavaScript (Vanilla JS)
- AI: OpenAI API (GPT-3.5-turbo, GPT-4, GPT-4o)
- Task Queue: Celery (비동기 작업 처리)
- Database: MySQL

**주요 기능**:
- AI 기반 사업 제안서, 기술 제안서 자동 생성
- 템플릿 기반 문서 구조 생성
- 사용자 정의 프롬프트 지원

#### 담당 업무:

**1) 기존 시스템 유지보수**
- 버그 수정 및 안정성 개선
- OpenAI API 버전 업데이트 (GPT-3.5 → GPT-4/GPT-4o)
- 사용자 가입 및 사용 로그 모니터링

**2) 제안서 생성 기능 개선**
- 프롬프트 엔지니어링을 통한 생성 품질 향상
- 제안서 섹션별 생성 로직 개선
- 템플릿 추가 및 커스터마이징

**3) 비동기 작업 처리**
- Celery를 활용한 문서 생성 비동기 처리
- Redis 기반 작업 큐 관리
- 생성 진행 상황 실시간 업데이트

**4) 사용자 관리**
- MySQL 기반 사용자 정보 관리
- 사용자별 생성 이력 저장
- 사용 통계 수집 (생성 횟수, 토큰 사용량 등)

#### 주요 성과:
- OpenAI API 업데이트로 제안서 품질 향상
- Celery 비동기 처리로 사용자 경험 개선
- 사용자 가입 및 사용 현황 모니터링 시스템 구축

---

## 4. SK Chemical AI/ML 프로젝트

### 4-1. Copoly CP-3 ES-20 COOH 예측

**프로젝트명**: Copolyester 생산 공정 COOH 예측 모델
**클라이언트**: SK Chemical DX Lab
**기간**: [TBD - 추후 WBS 확인 후 기재]
**역할**: ML 모델 개발

**해결 과제**:
- As-is: ES-20 COOH 변화에 따라 Polymer 반응성이 변하여 제품 품질 Hunting 발생
- To-be: ES-20 COOH 변화 예측으로 온도/유량 사전 Action 가능, 안정 운전

**데이터**:
- 인풋 (X): ES-10/20 온도, 레벨, 압력, (열매/물) 유량, ES-20 COOH 분석값 등
- 타겟 (y): ES-20 COOH 예측값
- 데이터 소스: RTIS, ERP

**기술스택**:
- Python, Pandas, NumPy
- ML 라이브러리 (scikit-learn, LightGBM, XGBoost 등 - 추정)

**담당 업무**:
- 공정 데이터 분석 및 전처리
- COOH 예측 ML 모델 개발
- 모델 성능 평가 및 하이퍼파라미터 튜닝
- 예측값 기반 Action 가이드 제공

**기대 효과**:
- 품질 Hunting 최소화로 안정 운전 가능
- 온도/유량 사전 Action으로 불량률 감소

---

### 4-2. QA팀 이미지 선별 모델 (이물 분석 검출 지원)

**프로젝트명**: 이미지 선별 모델을 활용한 이물 분석 검출 지원
**클라이언트**: SK Chemical QA팀
**기간**: 2025.02.24 ~ 2025.04.03 (약 1개월)
**역할**: Computer Vision 모델 개발
**협업**: 풍영환 (QA팀), 전한솔 (DT추진팀)

**해결 과제**:
- As-is: PET Chip 특성상 원통형이고 불투명하여 선별기기의 한계로 오류값 다수 발생, 사람이 직접 선별 시 업무 Load 과다
- To-be: 이미지 분석을 통해 사람이 직접 확인해야 하는 이미지 수 최소화

**데이터**:
- 인풋 (X): 선별기기 결과 Report (PDF 파일 형태)
- 타겟 (y): 이물 이미지 (정상/이물 분류)

**기술스택**:
- Python
- Computer Vision: [OpenCV, PyTorch/TensorFlow, YOLO/ResNet 등 - 추정]
- PDF 처리: PyPDF2, pdf2image 등

**담당 업무**:
- PDF 파일에서 이미지 추출 및 전처리
- 이물 검출 이미지 분류 모델 개발 (Binary Classification)
- 선별기기 결과를 1차 필터링하는 모델 개발
- 모델 성능 평가 (정확도, 재현율, F1-score)

**활용 모습**:
- 선별기기 결과 → 이미지 선별 모델 1차 필터링 → 사람 최종 선별

**기대 효과**:
- 업무 Load 감소 (사람이 확인해야 하는 이미지 수 XX% 감소)
- 산터우 공장 등 해외 공장 확대 가능

---

## 5. 네이버 부스트캠프 기업 해커톤

**프로젝트명**: 기업 해커톤
**주최**: 네이버 부스트캠프
**기간**: 2025.01.10 ~ 2025.02.14 (약 1개월)
**역할**: 기획, 운영, 평가

**과제**: 기업 평가 챗봇 개발

#### 담당 업무:
- 해커톤 과제 기획 및 평가 기준 수립
- 참가 팀 멘토링 및 기술 지원
- 해커톤 운영 및 결과 평가
- [구체적인 기술스택 및 결과 - 추후 추가 가능]

---
