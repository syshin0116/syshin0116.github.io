[
  {
    "path": "/home/user/syshin0116.github.io/content/index.md",
    "title": "Syshin's Knowledge Base",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n안녕하세요, syshin0116입니다! 이곳은 제가 배우고 경험한 것들을 정리하는 공간입니다.\n\n## 소개\n\nAI와 웹 개발, 특히 Python과 LangChain을 활용한 프로젝트에 관심이 많습니다.\n\n현재 RAG 기반 AI 솔루션 개발에 집중하고 있으며, 새로운 기술과 협업에 항상 열려 있습니다.\n\n## 연락처\n\n**Email:** [syshin0116@gmail.com](mailto:syshin0116@gmail.com)\n\n**GitHub:** [https://github.com/syshin0116](https://github.com/syshin0116)\n\n\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Others/2024-02-05-AI 개발자 채용 AI 관련 지식 필기.md",
    "title": "AI 개발자 면접 준비 - AI 지식 정리",
    "description": "AI 개발자 채용 면접을 위한 핵심 AI 지식 정리 - Text Embedding, LLM, Semantic Segmentation, MVC 패턴",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> AI 개발자 2차 면접(임원 면접 및 필기 테스트)을 위해 정리한 핵심 AI 지식이다. Text Embedding의 개념과 Word2Vec/GloVe/BERT의 차이, GPT-3/BERT/RoBERTa 등 LLM의 특징과 활용, Semantic Segmentation의 원리와 자율주행/의료영상 활용 사례, MVC 패턴의 구조, 그리고 LLM 기반 고객 대응 서비스의 전체 아키텍처(UI, 웹 서버, 컨트롤러, LLM 모델 서버, DB, API Gateway)를 다룬다.\n\n  \n\n## Intro:\n\n  \n\nAI 개발자 직무로 지원해, 면접 1차 합격 후, 2차 면접 안내를 받았고, 오늘 다녀왔다.\n\n  \n\n면접 내용 : 임원 면접(20분) / 간단한 프로그래밍 - AI 관련 지식 필기 테스트(30분)\n\n  \n  \n\n## AI 관련 지식 필기 테스트\n\n### Text Embedding 설명\n\n  \n\nText embedding은 텍스트 데이터를 고정된 길이의 벡터로 변환하는 과정입니다. 이 벡터는 컴퓨터가 처리할 수 있는 형태로 텍스트의 의미를 수치적으로 표현합니다. 이 과정은 자연어 처리(NLP)에서 중요한 역할을 하며, 단어, 문장, 문단을 벡터 공간에 매핑하여 단어 간의 의미적 관계를 반영합니다. 예를 들어, \"Word2Vec\", \"GloVe\", \"BERT\"의 Embedding 방식은 단어의 문맥적 의미를 포착하여 비슷한 의미를 가진 단어들이 벡터 공간에서 가까이 위치하게 합니다. 이를 통해 문서 분류, 감성 분석, 기계 번역 등의 작업을 효율적으로 수행할 수 있습니다.\n\n  \n\n### LLM(Large Language Model) 예시 및 특징\n\n  \n\nLLM 예시로는 \"GPT-3\", \"BERT\", \"RoBERTa\" 등이 있습니다. 이러한 모델들은 대규모 데이터셋에서 사전 학습되어, 다양한 자연어 처리 작업에 파인튜닝 없이도 높은 성능을 보일 수 있습니다.\n\n  \n\n-  **GPT-3**: OpenAI에 의해 개발된 모델로, 17"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Others/2024-01-18-포트폴리오 내용 정리.md",
    "title": "포트폴리오 프로젝트 아카이브",
    "description": "AI/ML 프로젝트 포트폴리오 종합 정리 - 대회 참가, 새싹 과정, Men-in-Black 프로젝트",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> AI/ML 학습 과정에서 수행한 다양한 프로젝트들의 종합 아카이브이다. 데이콘 대회 참가 경험, 머신러닝 양성 과정 프로젝트(HiTrip 여행지 추천, 자전거 도로 노선 제안), 새싹 과정 프로젝트(부동산 경매 낙찰가 예측, 뉴스기사 분석, 한국어 대화 요약), 그리고 Men-in-Black 교통 법규 위반 차량 감지 프로젝트를 포함한다. 특히 Men-in-Black에서는 YOLOv8을 활용한 차량 및 번호판 감지, EasyOCR을 통한 번호판 인식, ZoeDepth/MiDaS를 활용한 거리 추정 등 종합적인 Computer Vision 기술을 적용했다.\n\n## 기본:\n- Github Page: https://github.com/syshin0116\n- Git Blog: https://syshin0116.github.io\n\n## 포트폴리오:\n\n### 대회\n\n- 데이콘 Basic 추석 맞이 추석 선물 수요량 예측 AI 경진대회\n- 데이콘 월간 데이콘 쇼츠 - 뉴스 기사 레이블 복구 해커톤\n- 데이콘 제1회 신약개발 AI 경진대회\n- 2023 스마트농업 AI 경진대회\n### 새싹 이전:\n\n#### 머신러닝 딥러닝을 활용한 공공데이터 분석가 양성과정\n\n#### HiTrip(여행지 추천 웹사이트)\n\n![](assets/img/sample_portfolio.pdf)\n\n\n#### \\[데이콘]서울 시민데이터를 활용한 도시문제 해결- 새로운 자전거도로 노선 제안\n\n![](assets/img/서울_시민데이터를_활용한_도시문제_해결_경진대회_7팀_발표자료.pdf)\n\n\n\n## 새싹:\n\n#### 부동산 경매 낙찰가 예측\n![](assets/img/LazyEstate_부동산%20경매%20낙찰가%20예측%20모델.pdf)\n\n#### 부동산 관련 뉴스기사 분석(Streamlit page)\n\n![](https://i.imgur.com/5JOhJCt.png)\n\n#### 한국어 대화 요약\n\n![](assets/img/한국어_대화_요약_발표자료.pdf)\n\n\n####"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/MinerU - PDF Parser.md",
    "title": "MinerU - 고품질 PDF 변환 및 데이터 추출 도구",
    "description": "MinerU는 PDF 문서를 Markdown과 JSON으로 고품질 변환해주는 오픈소스 데이터 추출 도구이다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> MinerU는 복잡한 PDF 파일을 구조화된 Markdown과 JSON으로 고품질 변환하는 오픈소스 도구다. PDF-Extract-Kit, DocLayout-YOLO, StructEqTable, RapidTable 등 최신 문서 처리 기술을 통합하여 정교한 레이아웃 분석과 요소 추출을 제공한다. PaddleOCR로 텍스트 인식, PyMuPDF로 PDF 처리, layoutreader로 구조 분석, fast-langdetect로 언어 감지, pdfminer.six로 기본 파싱을 수행한다. 복잡한 레이아웃, 표, 수식, 이미지 등을 정확하게 인식하여 변환하며, CPU/GPU/NPU 가속을 지원해 효율적인 처리가 가능하다. AGPL-3 라이센스 제약이 있지만 PDF 파싱 성능은 최고 수준이다.\n\n## MinerU 소개\n\nRAG(Retrieval-Augmented Generation) 시스템 구축을 위해 PDF 파서를 찾던 중 발견한 MinerU는 내가 찾던 대부분의 조건을 충족시키는 도구다. [[RAG용 PDF Loader 비교]] 문서에서 다룬 다른 PDF 로더들과 비교했을 때, 특히 레이아웃 분석과 문서 구조 이해 측면에서 뛰어난 성능을 보여준다. [[LayoutLM]]과 같은 최신 문서 이해 기술을 활용하여 복잡한 문서 구조도 정확하게 처리할 수 있다.\n\nMinerU는 AGPL-3 라이센스를 사용하고 있어 이 점은 주의가 필요하지만, 그 외 모든 요구사항을 매우 뛰어난 품질로 충족시키는 오픈소스 도구다. OpenDataLab에서 개발한 이 도구는 PDF 문서를 Markdown 및 JSON 형식으로 변환하며, 단순한 텍스트 추출을 넘어 문서의 레이아웃, 표, 수식, 이미지 등 복잡한 요소들을 정확하게 인식하고 처리할 수 있다.\n\nMinerU는 아래 라이브러리들은 활용한다:\n- [PDF-Extract-Kit](https://github.com/opendatalab/PDF-Extract-Kit)\n- [DocLayout-YOLO](ht"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/Track Anything: Segment Anything Meets Videos.md",
    "title": "Track Anything: Segment Anything Meets Videos",
    "description": "SAM을 비디오에 적용한 Track Anything Model(TAM)의 특징과 활용 방안을 정리한 글이다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> Track Anything Model(TAM)은 Segment Anything Model(SAM)의 이미지 분할 능력을 비디오에 확장한 모델이다. 최소한의 사용자 상호작용으로 비디오 내 객체를 추적하고 분할할 수 있으며, 별도의 추가 학습 없이도 효과적인 결과를 제공한다.\n\n## 소개\n\nTrack Anything Model(TAM)은 비디오 객체 추적 및 분할에 혁신적인 접근 방식을 제공한다. Segment Anything Model(SAM)의 뛰어난 분할 성능과 비디오의 동적 특성을 결합했다. 최소한의 사용자 상호작용으로 비디오 내 관심 객체를 추적하고 단일 패스 추론으로 만족스러운 결과를 제공한다. 이 모델은 추가 학습이 필요 없으며, 대화형 설계로 비디오 객체 추적 및 분할에서 인상적인 성능을 보여준다.\n\n이 논문은 비디오에서 고성능 객체 추적 및 분할을 위한 효율적인 툴킷을 개발하는 Track-Anything 프로젝트를 소개한다.\n\n**논문 URL:** [https://arxiv.org/pdf/2304.11968v1.pdf](https://arxiv.org/pdf/2304.11968v1.pdf)  \n**코드:** [https://github.com/gaomingqi/Track-Anything](https://github.com/gaomingqi/Track-Anything)\n\n---\n\n## 핵심 주제\n\n상호작용 방식을 통해 비디오에서 고성능 추적/분할을 달성할 수 있을까?\n\nTrack Anything Model(TAM)은 대화형 방법을 통해 비디오에서 고성능 추적 및 분할을 달성할 수 있다. 이는 연구자들을 노동 집약적인 주석 작업과 초기화에서 해방시키고, 비디오 객체 추적 및 분할 분야의 관련 연구를 촉진한다.\n\n**분야:** 컴퓨터 비전 → 비디오 객체 추적(VOT) → 비디오 객체 분할(VOS)\n\n---\n\n## 프로세스\n\nTrack-Anything 프로세스는 네 단계로 나뉜다:\n\n### 1. SAM으로 초기화 \nS"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/LayoutLM.md",
    "title": "LayoutLM",
    "description": "LayoutLM의 발전 과정과 시각적으로 풍부한 문서 이해를 위한 다양한 버전별 특징 및 성능 분석",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> LayoutLM은 시각적으로 풍부한 문서 이해(VrDU)를 위한 멀티모달 프레임워크로, 텍스트뿐만 아니라 레이아웃과 시각적 정보를 함께 활용한다. V1부터 V3까지 발전하면서 문서 이미지에서 정보 추출, 양식 이해, 영수증 분석, 문서 분류 등 다양한 작업에서 우수한 성능을 보이고 있다.\n\n## 개요\n\n시각적으로 풍부한 문서(Visually-rich Document)는 텍스트만으로는 완전히 이해할 수 없는 구조적 정보와 레이아웃을 포함하고 있다. LayoutLM은 이러한 문서에서 텍스트, 시각적 요소, 레이아웃 정보를 모두 활용하여 문서를 이해하는 멀티모달 프레임워크다. 이 문서에서는 LayoutLM의 V1부터 V3까지의 발전 과정과 주요 특징을 살펴본다.\n\n[[문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용 연구]]와 밀접한 관련이 있으며, OCR 기술의 발전과 함께 문서 이해의 핵심 기술로 자리잡고 있다.\n\n---\n\n## 배경\n\n### 시각적으로 풍부한 문서 이해(VrDU)\n\n시각적으로 풍부한 문서 이해(Visually-rich Document Understanding, VrDU)는 다음과 같은 특징을 가진다:\n\n- 스캔된 이미지나 PDF 형태의 비즈니스 문서에서 필요한 정보를 추출하는 과정\n- 텍스트(Text), 시각(Visual), 레이아웃(Layout) 정보를 모두 다루는 멀티모달 접근 방식 필요\n- 전통적인 OCR 기반 방식을 넘어 문서의 구조와 컨텍스트를 이해하는 능력 요구\n\n![VrDU 개념도](https://i.imgur.com/LsfvFEU.png)\n\n---\n\n## 학습 데이터셋\n\nLayoutLM의 개발과 평가에 사용된 주요 데이터셋들을 알아보자.\n\n### 사전학습 데이터셋\n\n#### IIT-CDIP\n- Illinois Institute of Technology Complex Document Information Processing Test Collection\n- 6백만 개의 스캔된 문서와 11백만"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/LangGraph.md",
    "title": "LangGraph",
    "description": "LangGraph 라이브러리의 개념과 다중 에이전트 협업 시스템 구현 방법 설명",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n> [!summary]\n> \n> LangGraph는 LangChain 위에 구축된 상태 유지형 다중 에이전트 애플리케이션을 구축하기 위한 라이브러리다. 주요 특징은 LLM 애플리케이션에 순환(cycle) 기능을 추가하는 것으로, 이는 에이전트가 다음 행동을 결정하는 반복적 프로세스에 중요하다. 다중 에이전트 협업 모델에서는 각 작업이나 도메인에 전문화된 에이전트를 할당하여 \"분할 정복\" 방식으로 복잡한 문제를 해결한다.\n\n## 개요\n\nLangGraph는 LangChain에서 개발한 라이브러리로, 상태 유지 기능과 다중 에이전트 시스템을 구축할 수 있는 프레임워크다. 이 문서에서는 LangGraph의 기본 개념과 다중 에이전트 협업 모델 구현 방법에 대해 알아본다.\n\n### 참고자료\n- **공식 문서**: [LangGraph 문서](https://python.langchain.com/docs/langgraph)\n- **GitHub**: [LangGraph 리포지토리](https://github.com/langchain-ai/langgraph)\n- **유튜브 튜토리얼**: [TeddyNote - LangGraph 소개](https://www.youtube.com/watch?v=1scMJH93v0M)\n\n---\n\n## LangGraph 기본 개념\n\nLangChain 공식 홈페이지에서는 LangGraph를 다음과 같이 정의한다:\n\n> LangGraph는 LLM을 활용한 상태 유지형 다중 에이전트 애플리케이션을 구축하기 위한 라이브러리로, LangChain 위에 구축되었다. LangChain Expression Language를 확장하여 여러 체인(또는 액터)을 순환적인 방식으로 여러 계산 단계에 걸쳐 조정할 수 있는 기능을 제공한다. Pregel과 Apache Beam에서 영감을 받았으며, 현재 인터페이스는 NetworkX에서 영감을 받았다.\n\n### 핵심 특징\n- **순환(Cycles) 지원**: LLM 애플리케이션에 순환 기능을 추가한다.\n- **비 DAG 프레임"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/LLM Compiler for Parallel Function Calling.md",
    "title": "LLM Compiler for Parallel Function Calling",
    "description": "LLM 기능 호출을 병렬로 처리하여 지연 시간과 비용을 줄이는 LLM Compiler 연구에 대한 검토",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 본 문서는 LLM Compiler 연구에 대한 검토로, 함수 호출을 병렬로 처리함으로써 지연 시간과 비용을 크게 줄일 수 있는 방법을 설명한다. 기존 ReAct 방식 대비 최대 3.7배 속도 향상, 6.7배 비용 절감, 9%의 정확도 향상 효과를 제공한다. Function Calling Planner, Task Fetching Unit, Executor의 세 구성요소를 통해 효율적인 병렬 처리를 구현하는 방식을 자세히 다룬다.\n\n- paper: [https://arxiv.org/abs/2312.04511](https://arxiv.org/abs/2312.04511)\n- github: [https://github.com/SqueezeAILab/LLMCompiler](https://github.com/SqueezeAILab/LLMCompiler)\n- youtube: [https://youtu.be/aoLtTIYAafY?si=9d4O99LWEWpX15Oc](https://youtu.be/aoLtTIYAafY?si=9d4O99LWEWpX15Oc)\n\n## Abstract\n\n#### **Problem**: \n현재 LLM 함수 호출 방법은 각 함수에 대해 순차적인 추론과 실행이 필요하여 **높은 지연 시간, 비용, 때로는 부정확한 동작**을 초래할 수 있다.\n\n#### Key Question: \n여러 함수 호출을 통합하는 가장 효과적인 접근 방식은 무엇인가?\n\n#### LLM Compiler\n- 여러 함수 호출을 효율적으로 조정하기 위해 함수를 병렬로 실행한다\n- 세 가지 구성 요소로 이루어진다:\n  1. Function Calling Planner: 함수 호출을 위한 실행 계획 수립\n  2. Task Fetching Unit: 함수 호출 작업 배포\n  3. Executor: 이러한 작업을 병렬로 실행\n\n**ReAct**와 비교한 관찰 결과:\n- 최대 3.7배의 일관된 지연 시간 단축\n- 최대 6.7배의 비용 절감\n- 최대 약 9%의 정"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/T-SNE.md",
    "title": "T-SNE (t-distributed stochastic neighbor embedding)",
    "description": "고차원 데이터를 효과적으로 시각화하는 비선형 차원 축소 기법인 t-SNE의 원리와 활용법을 설명한 글이다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> t-SNE(t-distributed stochastic neighbor embedding)는 고차원 데이터를 2차원이나 3차원으로 축소하는 비선형 차원 축소 기법이다. PCA와 달리 비선형적 관계를 보존하며, 고차원 공간에서 비슷한 데이터 포인트는 저차원에서도 가깝게, 다른 포인트는 멀리 배치한다. 알고리즘은 두 차원 공간 간의 조건부 확률 분포의 KL-divergence를 최소화하는 방식으로 작동하며, 복잡한 데이터 구조의 시각화에 특히 유용하다.\n\n## 개요\n\nt-SNE(t-distributed stochastic neighbor embedding)는 복잡한 고차원 데이터를 시각화하기 위한 강력한 비선형 차원 축소 기법이다. PCA와 같은 선형 차원 축소 방법과 달리, t-SNE는 데이터의 비선형적 관계를 효과적으로 보존할 수 있다.\n\n![t-SNE 차원 축소 예시](https://i.imgur.com/ivLJbS5.png)\n\n---\n\n## 차원 축소(Dimensionality Reduction)의 필요성\n\n수많은 특성(feature)을 가진 데이터셋에서는 다음과 같은 문제가 발생한다:\n\n- 특성들 간의 복잡한 관계를 파악하기 어려움\n- 특성이 너무 많으면 머신러닝 모델의 성능 저하 및 과적합 발생\n- 고차원 데이터의 시각화가 어려움\n\n이러한 문제를 해결하기 위해 차원 축소 기법이 사용된다.\n\n### 차원 축소의 효과\n- 특성들 간의 관계를 단순화\n- 데이터를 2D 또는 3D로 시각화 가능\n- 과적합(overfitting) 방지\n- 모델 훈련 시간 단축\n\n### 차원 축소 방법\n\n1. **특성 제거(Feature Elimination)**\n   - 특성을 단순히 삭제하는 방법\n   - 간단하지만 삭제된 특성의 정보 손실(information loss) 발생\n\n2. **특성 선택(Feature Selection)**\n   - 통계적 방법을 이용하여 특성의 중요도에 순위 부여\n   - 정보 손실 가능성이 있으며, 다른 데이터"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/Knowledge Graphs for RAG.md",
    "title": "Knowledge Graphs for RAG",
    "description": "RAG(Retrieval-Augmented Generation) 시스템에서 지식 그래프 활용 방법과 Neo4j 구현",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n> [!summary]\n> \n> 지식 그래프(Knowledge Graph)는 노드(entities)와 관계(relationships)로 정보를 저장하는 데이터베이스로, RAG 시스템에서 정보 검색과 컨텍스트 제공을 향상시킨다. Neo4j와 같은 그래프 데이터베이스를 통해 구현되며, Cypher라는 쿼리 언어를 사용해 복잡한 관계를 검색할 수 있다. 지식 그래프는 데이터를 구조화하고 관계를 강조하며, 노드와 엣지 모두 속성을 가질 수 있어 풍부한 정보 표현이 가능하다.\n\n## 개요\n\n지식 그래프(Knowledge Graph)는 RAG(Retrieval-Augmented Generation) 시스템에서 정보 검색과 컨텍스트 제공을 향상시키는 데 활용되는 강력한 도구다. 이 문서에서는 지식 그래프의 기본 개념과 Neo4j를 활용한 구현 방법에 대해 알아본다.\n\n### 참고자료\n- [DeepLearning.AI - Knowledge Graphs for RAG](https://learn.deeplearning.ai/courses/knowledge-graphs-rag/lesson/1/introduction)\n\n## 지식 그래프란?\n\n지식 그래프는 노드(nodes)와 관계(relationships)를 사용하여 정보를 저장하는 데이터베이스다.\n\n주요 특징:\n- 데이터 정렬 및 구성 방법 제공\n- 개체 간의 관계 강조\n- 그래프 기반 구조 사용:\n  - 노드: 개체(entity) 표현\n  - 엣지: 노드 간의 관계 표현\n\n![지식 그래프 예시](https://i.imgur.com/v3dXFGn.png)\n\n## 기본 개념\n\n### 노드와 엣지\n\n노드와 엣지는 지식 그래프의 기본 구성 요소다.\n\n![노드와 엣지 예시](https://i.imgur.com/aqQtqhM.png)\n\n표현 방식: (Person) - [Knows] - (Person)\n\n> 노드는 관계 내에 있으며, 속성을 갖는 관계로 연결된다.\n\n![복잡한 관계 예시](https://i.imgur.com/Kmhm0zd"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용.md",
    "title": "문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용",
    "description": "멀티모달 RAG를 활용한 PDF 문서 내 시각 자료와 텍스트 추출 및 활용 기법",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# 1. 문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용\n\n## 1-1. 배경\n\n### 시각 자료의 중요성\n\n- 시각 자료(그래프, 표, 이미지 등)는 문서의 이해와 정보 전달을 돕는 중요한 요소\n- 복잡한 정보를 쉽게 전달하는 수단으로 사용되며, 중요한 정보를 담고 있는 경우가 많음\n\n### 다중 모달 LLM의 등장\n\n- GPT-4V, GPT-4o 등 텍스트와 이미지를 동시에 활용하는 대규모 언어모델(LLM)이 등장\n- RAG(Retrieval-Augmented Generation)에서도 텍스트뿐 아니라 이미지 등 다양한 모달을 함께 활용하는 방향으로 발전 중\n\n---\n\n## 1-2. PDF 문서에서 텍스트 및 시각 자료 추출의 어려움\n\nPDF에서 텍스트 및 이미지를 추출하는 일은 다양한 이유로 쉽지 않다. 아래는 주요 이슈들이다.\n\n- **Paragraphs**\n    - PDF 원본의 줄바꿈 위치를 그대로 가져갈지\n    - 하나의 단락으로 합쳐서 추출할지\n- **Page numbers**\n    - 페이지 번호를 추출물에 포함시킬지\n- **Headers and Footers**\n    - 머리글, 바닥글에 대한 처리 방식\n- **Outlines**\n    - 챕터나 섹션 목록 같은 목차 요소를 추출할지\n- **Formatting**\n    - 굵게(**bold**), 기울임(_italic_) 등의 서식을 유지할지\n- **Tables**\n    - 테이블을 어떻게 추출할지\n    - 테이블 구조(열/행)나 셀 병합 정보를 복원할지\n    - Markdown/HTML 같은 형태로 유지할지\n- **Captions**\n    - 이미지 혹은 테이블 캡션을 어떻게 처리할지\n- **Ligatures**\n    - 'ﬀ' 같은 합쳐진 문자를 ASCII 'ff'로 풀어서 처리할지\n- **SVG images**\n    - 벡터 기반 이미지에서 텍스트가 있으면 추출할지\n- **Mathematical Formulas**\n    - 인덱스나 분수, 중첩 등을 어"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/2025-09-14-학술 -논문-특화-파서-시스템.md",
    "title": "학술 논문 특화 파서 시스템 분석",
    "description": "학술 논문을 위한 전문 문서 파싱 및 RAG 시스템 구축 프로젝트 분석. UPSTAGE Document AI와 LLM을 활용한 고품질 멀티모달 콘텐츠 추출, 벡터 데이터베이스 구축, 그리고 Multi-Query + Reranker 기반 하이브리드 검색 시스템 구현까지 포괄적으로 다룬다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 특정 학회 논문 1,261개를 대상으로 한 전문 문서 파싱 및 RAG 시스템 구축 프로젝트다. UPSTAGE Document AI와 LLM을 결합한 이중 파싱 파이프라인을 통해 멀티모달 콘텐츠(텍스트, 이미지, 테이블)를 정확하게 추출하고, LangChain MarkdownHeaderTextSplitter로 의미적 청킹을 수행한다. 15,818개 벡터 포인트를 Qdrant에 저장하여 Parent-Child Document 구조를 구현했으며, Multi-Query + Reranker 기반 하이브리드 검색으로 검색 정확도를 극대화했다. 학술 논문 처리에 최적화된 완전 자동화 파이프라인으로 RAG 시스템 즉시 활용이 가능하다.\n\n## 프로젝트 개요\n\n학술 연구를 위한 전문적인 문서 처리 시스템을 구축하면서 특정 학회 논문을 대상으로 한 특화 파서를 개발했다. 2019년부터 2024년까지의 학술지 논문 1,261개를 체계적으로 수집, 파싱, 구조화하여 고품질 RAG 시스템의 기반을 마련했다.\n\n[[MinerU - PDF Parser|MinerU]]나 [[문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용|기존 PDF 파서들]]과 차별화되는 점은 학술 논문에 특화된 전처리 파이프라인과 완전 자동화된 메타데이터 추출, 그리고 Multi-Query + Reranker 기반 하이브리드 검색 시스템이다.\n\n> [!info] 프로젝트 핵심 가치\n> 단순한 PDF 텍스트 추출을 넘어서, 학술 논문의 구조적 특성을 완벽히 이해하고 효과적인 연구 정보 검색을 위한 **지능형 문서 검색 시스템**을 구축하는 것이 목표다.\n\n\n\n## 시스템 구성 요소\n\n### 1. **PDF 파서 클라이언트** (`parser-api-client/`)\n\n학술 논문 PDF를 구조화된 마크다운으로 변환하는 핵심 엔진이다. UPSTAGE Document AI의 강력한 레이아웃 분석 능력과 LLM의 텍스트 정제 기능을 결합하여 최고 품질의 파싱 결과를 달성한다.\n\n**"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/Tensorflow Deep-Learning Computer-Vision Guide Notes 2.md",
    "title": "Tensorflow Deep-Learning Computer-Vision Guide Notes 2",
    "description": "컴퓨터 비전에서 객체 탐지(Object Detection)와 위치 찾기(Localization) 개념 및 Region Proposal 방식에 대해 설명한 글이다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 객체 탐지(Object Detection)와 객체 위치 찾기(Localization)의 개념과 차이점을 설명하고, Bounding Box 학습 방법과 Region Proposal 기법을 다룬다. 특히 여러 객체를 동시에 감지하는 방법과 슬라이딩 윈도우 접근법의 원리와 한계에 대해 살펴본다.\n\n## 객체 위치 찾기와 탐지의 이해\n\n컴퓨터 비전 분야에서 객체를 인식하는 두 가지 주요 기술인 객체 위치 찾기(Localization)와 객체 탐지(Detection)에 대해 알아본다.\n\n### 객체 위치 찾기(Object Localization) 개요\n\n객체 위치 찾기는 하나의 이미지에 하나의 주요 객체가 있을 때, 해당 객체의 위치와 클래스를 동시에 예측하는 기술이다.\n\n#### 핵심 개념\n- **FC Layer**: Fully Connected Layer로, 특징 맵에서 추출한 정보를 바탕으로 클래스 분류 및 위치 정보 추출\n- **Annotation 파일**: 라벨과 유사하게 객체 정보를 담고 있는 파일\n  - Bounding Box의 꼭지점 좌표값 포함\n  - YOLO의 경우 Bounding Box의 중앙점 좌표값 사용\n\n#### Bounding Box 학습\n객체 위치 찾기에서는 클래스 분류와 함께 Bounding Box Regression을 동시에 진행한다. 특징 맵에서 특정 특성이 감지되면 해당 위치에 대한 경계 상자 회귀를 수행한다.\n\n<br>\n<p align=\"center\">\n<img width=\"827\" alt=\"Bounding Box 학습 과정\" src=\"https://user-images.githubusercontent.com/99532836/184108231-3712ea60-416d-4895-bf35-b3de4aca67f9.png\">\n</p>\n<br>\n\n- **Class Confidence Score**: 예측된 객체가 특정 클래스에 속할 확률 (예: 객체가 자동차일 확률 0.9)\n\n---\n\n### 객체 탐지(O"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용 연구.md",
    "title": "문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용 연구",
    "description": "멀티모달 RAG를 통한 문서 내 텍스트와 이미지 추출 및 활용 연구",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# Multi-Modal RAG\n\n### 배경:\n- GPT-4V, GPT-4o와 같은 다중 모달 LLM 등장\n- RAG에서 text뿐만 아니라 image도 함께 활용하는 방안\n\n### Why Text Extraction is hard\n\nPDF에서 텍스트를 추출하는 것은 매우 까다로울 수 있다. 여러 경우에 예상되는 결과가 명확하지 않다:\n\n1. **단락**: 원본 PDF에 있던 것과 같은 위치에 줄 바꿈이 있어야 하는지 아니면 하나의 텍스트 블록이어야 하는지?\n2. **페이지 번호**: 추출물에 포함되어야 하는지?\n3. **헤더 및 푸터**: 페이지 번호와 유사하게 - 추출해야 하는지?\n4. **개요**: 개요를 모두 추출해야 하는지?\n5. **서식**: 텍스트가 **굵게** 또는 _기울임꼴_인 경우 출력에 포함되어야 하는지?\n6. **표**: 텍스트 추출이 표를 건너뛰어야 하는지? 단지 텍스트만 추출해야 하는지? 테두리가 Markdown과 같은 방식으로 표시되어야 하는지 아니면 구조가 HTML 테이블로 표시되어야 하는지? 병합된 셀은 어떻게 처리할 것인지?\n7. **캡션**: 이미지와 표 캡션이 포함되어야 하는지?\n8. **합자**: 유니코드 기호 [U+FB00](https://www.compart.com/de/unicode/U+FB00)은 두 소문자 'f'에 대한 단일 기호 ﬀ이다. 유니코드 기호 'ﬀ'로 파싱되어야 하는지 아니면 두 개의 ASCII 기호 'ff'로 파싱되어야 하는지?\n9. **SVG 이미지**: 텍스트 부분을 추출해야 하는지?\n10. **수학 공식**: 추출해야 하는지? 공식에는 인덱스와 중첩된 분수가 있다.\n11. **공백 문자**: 3cm의 수직 공백에 대해 몇 개의 새 줄을 추출해야 하는지? 3cm의 수평 공백이 있는 경우 몇 개의 공백을 추출해야 하는지? 탭과 공백을 언제 추출할 것인지?\n12. **각주**: 여러 페이지의 텍스트를 추출할 때 각주는 어디에 표시되어야 하는지?\n13. **하이퍼링크 및 메타데이터**: 전혀 추출해"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/Multi-Agent Architecture and Large-Scale Implementation Strategies.md",
    "title": "멀티에이전트 아키텍처와 대규모 구현 전략",
    "description": "멀티에이전트 시스템의 핵심 아키텍처 패턴들과 대규모 환경에서의 구현 전략을 분석하고, 최신 통신 프로토콜과 확장성 해결책을 포괄적으로 다룬 가이드",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> [[Agent Architecture Comparison|단일 에이전트 아키텍처]]의 한계를 넘어서는 멀티에이전트 시스템의 핵심 아키텍처 패턴들을 체계적으로 분석한다. 계층적, 네트워크, 중재자, 발행-구독 패턴의 특징과 장단점을 비교하고, 대규모 환경에서의 확장성 문제를 해결하기 위한 실용적 전략들을 제시한다. MCP, A2A, ANP 등 최신 통신 프로토콜의 역할과 함께 샤딩, 로드밸런싱, 내결함성 메커니즘을 포함한 대규모 구현 방법론을 종합적으로 다룬다.\n\n## 1. 서론\n\n현대 AI 시스템이 직면하는 복잡한 문제들은 단일 에이전트로는 해결하기 어려운 경우가 많다. 대규모 데이터 처리, 실시간 의사결정, 다중 도메인 전문성이 요구되는 환경에서 멀티에이전트 시스템(Multi-Agent System, MAS)은 필수적인 해결책으로 부상하고 있다.\n\n### 멀티에이전트 시스템의 필요성\n\n[[Agent Architecture Comparison|단일 에이전트 시스템]]은 다음과 같은 근본적인 한계를 가진다:\n\n1. **순차적 처리 제약**: 한 번에 하나의 작업만 수행 가능\n2. **제한된 컨텍스트 윈도우**: 메모리 용량과 처리 범위의 물리적 한계\n3. **전문성 부족**: 모든 도메인에 대한 깊은 전문 지식을 갖추기 어려움\n4. **단일 장애점**: 에이전트 실패 시 전체 시스템 마비\n5. **확장성 한계**: 복잡성 증가에 따른 성능 저하\n\n멀티에이전트 시스템은 이러한 문제를 다음과 같이 해결한다:\n\n> [!info] 멀티에이전트 시스템의 핵심 이점\n> - **분산 처리**: 여러 에이전트가 동시에 작업을 수행하여 처리 속도 향상\n> - **전문화**: 각 에이전트가 특정 도메인에 특화되어 높은 품질의 결과 생성\n> - **확장성**: 새로운 에이전트 추가로 시스템 기능 확장\n> - **내결함성**: 개별 에이전트 실패가 전체 시스템에 미치는 영향 최소화\n> - **유연성**: 동적 환경 변화에 적응적으로 대응\n\n## 2. 멀"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/2025-10-26-context-engineering-for-ai-agents.md",
    "title": "Context Engineering for AI Agents: With LangChain and Manus",
    "description": "LangChain과 Manus 웨비나에서 배운 AI 에이전트의 컨텍스트 엔지니어링 핵심 전략. 컨텍스트 오프로딩, 축소(압축 vs 요약), 격리(통신 vs 메모리 공유), 계층형 액션 공간 등 실전 검증된 기법과 '덜 구축하고 더 이해하라'는 철학을 다룬다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> LangChain과 Manus가 공동 진행한 웨비나에서 AI 에이전트 개발의 핵심 과제인 컨텍스트 엔지니어링에 대해 깊이 있는 인사이트를 얻었다. 에이전트는 도구를 자유롭게 호출하며 작업을 수행하지만, 매 호출마다 컨텍스트가 무한정 증가하여 성능이 저하되는 역설적 문제에 직면한다. 이 글에서는 Manus가 실제 프로덕션 환경에서 검증한 5가지 핵심 기법(오프로딩, 축소, 검색, 격리, 캐싱)과 계층형 액션 공간 같은 혁신적 해결책을 다룬다. 특히 '덜 구축하고 더 이해하라'는 철학이 인상적이었다.\n\n## 컨텍스트 엔지니어링이 필요한 이유\n\n[[LLM Chain Chatbot + RAG]] 같은 단순한 RAG 시스템과 달리, AI 에이전트는 본질적으로 **컨텍스트 폭증** 문제를 안고 있다.\n\n### 문제의 본질\n\n에이전트가 작동하는 방식은 간단해 보인다:\n\n```\n사용자 질의 → LLM 추론 → 도구 호출 → 결과 반환 → 컨텍스트 추가 → 다음 추론\n```\n\n하지만 이 루프가 반복되면서 컨텍스트는 기하급수적으로 증가한다. Manus의 경우 일반적인 작업에 **약 50회의 도구 호출**이 필요하고, Anthropic은 프로덕션 에이전트가 **수백 턴**에 걸친 대화를 처리한다고 밝혔다.\n\n![](https://i.imgur.com/neKAIu1.png)\n\n\n> [!danger] 컨텍스트 로트 (Context Rot)\n>\n> Chrome 보고서에 따르면 컨텍스트가 증가할수록 에이전트 성능이 저하된다. 대부분의 모델은 하드 제한(예: 100만 토큰)보다 훨씬 일찍 **200K 토큰 전후**에서 성능 저하가 시작된다. 반복, 느린 추론, 품질 저하 등의 현상이 나타나는데, 이를 **Context Rot**이라고 부른다.\n\n컨텍스트 엔지니어링은 바로 이 역설을 해결하기 위한 기술이다.\n\n> 다음 단계를 위해 필요한 정확한 정보로 컨텍스트 윈도우를 채우는 섬세한 기술이자 과학\n\n---\n\n## 왜 파인튜닝이 아닌 컨텍스트 엔지니어링인가?"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/다중공선성 (Multicollinearity).md",
    "title": "다중공선성 (Multicollinearity)",
    "description": "다중공선성의 개념, 탐지 방법, 해결 방법 및 관련 작업들에 대한 포괄적인 가이드",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 다중공선성(Multicollinearity)은 회귀 분석 및 기계 학습에서 독립 변수(설명 변수) 간에 높은 상관관계가 존재하는 현상이다. 이는 계수 추정의 불안정성과 표준 오차 증가 등 여러 문제를 일으킨다. 분산팽창계수(VIF)를 통해 진단할 수 있으며, VIF가 5~10 이상이면 문제가 될 수 있다. 해결 방법으로는 변수 제거, 변수 변환, 주성분 분석(PCA), 정규화 기법(Ridge, Lasso, Elastic Net) 등이 있다. 데이터의 특성과 분석 목적에 따라 적절한 방법을 선택해야 하며, 예측이 주 목적이라면 다중공선성이 반드시 해결해야 할 문제는 아닐 수 있다. 특히 RTIS(공정 시계열 데이터)와 같은 특수한 데이터 유형에서는 도메인 지식과 결합한 체계적인 접근법이 필요하다.\n\n다중공선성(Multicollinearity)은 회귀 분석 및 기계 학습에서 독립 변수(설명 변수) 간에 높은 상관관계가 존재하는 현상을 말한다. 이 현상은 모델의 안정성과 해석 가능성에 심각한 영향을 미칠 수 있으며, 예측 정확도를 저하시킬 수 있다.\n\n> [!INFO] 분산팽창계수(VIF, Variance Inflation Factor)\n>\n> VIF는 다중공선성을 탐지하는 가장 일반적인 지표로, 특정 독립 변수가 다른 모든 독립 변수와 얼마나 강한 선형 관계를 가지는지 측정한다. \n> \n> **계산 공식**: VIF(X_j) = 1 / (1 - R²_j)\n> \n> 여기서 R²_j는 변수 X_j를 다른 모든 독립 변수로 회귀한 모델의 결정계수이다.\n> \n> **해석 기준**:\n> - VIF = 1: 다중공선성 없음\n> - 1 < VIF < 5: 약한 다중공선성\n> - 5 < VIF < 10: 중간 수준의 다중공선성\n> - VIF > 10: 강한 다중공선성 (일반적으로 문제가 될 수 있는 수준)\n>\n> VIF가 높을수록 해당 변수의 계수 추정값이 불안정하고 표준 오차가 커진다. 따라서 통계적 유의성 검정의 신뢰도가 낮아지게 된다.\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/Chainlit.md",
    "title": "Chainlit",
    "description": "빠르게 대화형 AI 애플리케이션을 개발할 수 있는 Chainlit 라이브러리 사용법",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n> [!summary]\n> \n> Chainlit은 빠르게 프로덕션 준비가 된 대화형 AI 애플리케이션을 개발할 수 있는 오픈소스 파이썬 패키지이다. LangChain과의 통합을 통해 문서에서 정보를 추출하고 질문에 답변하는 챗봇을 쉽게 만들 수 있다. 파일 업로드, 벡터 스토어 기반 검색, 대화 기록 관리 등의 기능을 제공하며, 직관적인 UI로 사용자 경험을 향상시킨다.\n\n## 개요\n\nChainlit은 오픈소스 파이썬 패키지로, 빠르게 프로덕션 준비가 된 대화형 AI 애플리케이션을 개발하는 데 도움을 준다. 특히 LangChain과 같은 라이브러리와 통합하여 RAG(Retrieval-Augmented Generation) 기반 챗봇을 쉽게 구현할 수 있다.\n\n## 시스템 설정 및 초기화\n\n### 필요 라이브러리 설치\n\nChainlit과 관련 라이브러리를 설치하는 방법은 다음과 같다:\n\n```bash\npip install chainlit langchain openai chroma\n```\n\n### 기본 코드 구조\n\nChainlit 기반 챗봇의 주요 구성 요소는 다음과 같다:\n\n- **문서 로더**: PDF와 텍스트 파일에서 데이터를 로드\n- **텍스트 분할기**: 긴 텍스트를 일정한 크기로 나눠 처리\n- **임베딩 및 벡터 스토어**: 텍스트 데이터를 벡터화하고 검색 가능한 형태로 저장\n- **대화형 검색 체인**: 사용자 입력에 따라 관련 정보를 검색하고 응답을 생성\n\n### 초기화 코드 예시\n\n```python\nimport chainlit as cl\nfrom langchain.document_loaders import PyPDFLoader, TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langc"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/Imbalanced Data Prediction(Anomaly Detection).md",
    "title": "Imbalanced Data Prediction(Anomaly Detection)",
    "description": "불균형 데이터에서의 이상치 탐지를 위한 다양한 모델과 기법을 비교 분석한 글이다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 불균형 데이터에서 이상치를 탐지하는 다양한 방법론을 비교한다. 지도학습 분류 모델과 비지도학습 이상 탐지 모델의 성능을 평가하고, 샘플링 기법의 효과를 분석한다.\n\n## 이상치 탐지 모델 성능 비교\n\n이상치 탐지(Anomaly Detection)는 데이터셋에서 비정상적인 패턴이나 행동을 식별하는 프로세스다. 특히 금융 사기 탐지, 네트워크 침입 감지, 제조업 결함 검출 등 많은 실제 상황에서 중요한 역할을 한다. 이 글에서는 다양한 이상치 탐지 모델의 성능을 비교한다.\n\n---\n\n## 차원 축소 및 클러스터링\n\n이상치 탐지를 위한 첫 번째 접근법으로 차원 축소와 클러스터링 기법을 살펴볼 수 있다. 고차원 데이터에서는 [[차원 축소 (Dimensionality Reduction) 기법|차원 축소 기법]]이 효과적이다.\n\n### 주요 차원 축소 기법\n\n1. **PCA(Principal Component Analysis)**: 데이터의 분산을 최대화하는 방향으로 차원을 축소한다.\n2. **t-SNE([[T-SNE|T-Distributed Stochastic Neighbor Embedding]])**: 고차원 데이터의 유사성을 보존하며 2D 또는 3D로 시각화한다.\n3. **UMAP(Uniform Manifold Approximation and Projection)**: t-SNE보다 계산 효율성이 높고 글로벌 구조를 더 잘 보존한다.\n\n### 클러스터링 기반 접근법\n\n클러스터링은 데이터 포인트를 유사한 그룹으로 나누며, 이상치는 주요 클러스터에서 멀리 떨어진 포인트로 간주된다:\n\n```python\nfrom sklearn.cluster import DBSCAN\nimport numpy as np\n\n# DBSCAN 클러스터링을 사용한 이상치 탐지\ndbscan = DBSCAN(eps=0.5, min_samples=5)\nclusters = dbscan.fit_predict(X)\n\n# -1로 레이블된 포인트는 이상치로 간주\noutliers "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/Tensorflow Deep-Learning Computer-Vision Guide Notes 1.md",
    "title": "Tensorflow Deep-Learning Computer-Vision Guide Notes 1",
    "description": "딥러닝 기반 컴퓨터 비전의 객체 탐지(Object Detection)와 세그멘테이션(Segmentation)에 대한 기본 개념과 발전 과정을 정리한 글이다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 컴퓨터 비전에서 핵심 기술인 객체 탐지(Object Detection)와 세그멘테이션(Segmentation)의 기본 개념과 주요 구성 요소를 정리했다. 딥러닝 기반 방법론의 발전 과정과 One-stage/Two-stage detector의 특징, 그리고 이 분야가 직면한 주요 난제를 다룬다.\n\n## 서론\n\n딥러닝 기반 컴퓨터 비전은 2012년 AlexNet이 PASCAL VOC 대회에서 CNN 기반으로 우승한 이후 급속도로 발전해왔다. 특히 객체 탐지(Object Detection)와 세그멘테이션(Segmentation) 분야는 실생활 응용 가능성이 높아 많은 연구가 이루어지고 있다.\n\n이 문서에서는 다음 내용을 다룬다:\n1. Object Detection, Segmentation의 이론적 이해\n2. 주요 구현 패키지와 실습 방법\n\n---\n\n## 구현 및 실습 도구\n\n### 구현 패키지\n1. **MMDetection**: 다양한 객체 탐지 알고리즘을 제공하는 오픈소스 프레임워크\n2. **Ultralytics YOLO V3**: 실시간 객체 탐지에 최적화된 YOLO 구현체\n3. **AutoML EfficientDet**: 구글의 EfficientDet 구현체로 효율적인 객체 탐지 모델\n\n### 범용 인터페이스 API\n1. **OpenCV**: 컴퓨터 비전을 위한 오픈소스 라이브러리\n2. **TensorFlow Hub**: 사전 훈련된 모델을 쉽게 활용할 수 있는 TensorFlow 확장\n\n> [!Note]\n> 실습은 Colab이나 Kaggle Kernel과 같은 클라우드 기반 환경에서 진행하면 편리하다.\n\n---\n\n## Object Detection과 Segmentation의 이해\n\n컴퓨터 비전 작업은 복잡도에 따라 다음과 같이 분류할 수 있다:\n**Classification → Localization → Detection → Segmentation**\n\n각 단계별 특징:\n\n### 1. 이미지 분류(Classification"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/LLM이 고유명사를 틀리는 이유와 해결 방법.md",
    "title": "LLM이 고유명사를 틀리는 이유와 해결 방법",
    "description": "헬스케어 챗봇 개발 중 발견한 LLM의 고유명사 오표기 문제의 근본 원인을 분석하고, 다양한 해결 방법을 실험한 과정을 정리한다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 헬스케어 도메인 챗봇을 개발하면서 LLM이 특정 고유명사(약품명, 병원명 등)를 5% 미만이지만 일관되게 틀리는 문제를 발견했다. 초기에는 긴 프롬프트로 인한 Context Engineering 문제로 추정했으나, 실험 결과 토큰화(Tokenization) 과정에서 고유명사가 여러 토큰으로 분리되고 Transformer 모델의 다음 토큰 예측 특성상 학습되지 않은 고유명사를 정확히 생성하기 어렵다는 것을 발견했다. Few-shot, Fine-tuning 등 여러 방법을 시도한 결과, Evaluate + Rewrite 방식으로 문제를 효과적으로 해결할 수 있었다.\n\n## 1. 문제 발견\n\n헬스케어 도메인의 고객 지원 챗봇을 개발하던 중, 특정 고유명사들을 일관되게 틀리는 현상을 발견했다. 전체적으로는 5% 미만의 낮은 오류율이었지만, 특정 약품명과 병원명에서 반복적으로 오표기가 발생했다.\n\n### 문제의 특징\n\n- 오류율: 전체의 5% 미만\n- 특징: **특정 고유명사에 집중**된 오류\n- 도메인: 약품명, 병원명, 거래처명 등\n- 심각도: 헬스케어 도메인 특성상 고유명사 정확도는 매우 중요\n\n> [!example] 실제 사례\n> 사용자: \"토스젯에이에 대해 알려주세요\"\n>\n> 기대 응답: \"토스젯에이는...\"\n> 실제 응답: \"토스젯 에이는...\" 또는 \"토스제트에이는...\"\n\n## 2. 초기 가설: Context Engineering 문제?\n\n처음에는 프롬프트 길이 때문에 발생하는 문제라고 추측했다.\n\n**초기 가설:**\n- 프롬프트에 약품명 리스트, 병원명 리스트 등 많은 컨텍스트를 주입\n- 프롬프트가 길어지면서 LLM이 특정 정보에 집중하지 못함\n- Context Engineering으로 해결 가능할 것\n\n### 가설 검증 실험\n\n간단한 프롬프트로 격리 테스트를 진행했다:\n\n```\nSystem: 당신은 헬스케어 전문가입니다.\nUser: 토스젯에이에 대해 설명해주세요.\n```\n\n**결과:** 짧은 프롬프트에서도 동일한 오류 발"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/LLM Chain Chatbot + RAG.md",
    "title": "LLM Chain Chatbot + RAG",
    "description": "LangChain의 ConversationalRetrievalChain을 활용한 대화형 RAG 시스템 구현 방법과 주요 기능 설명",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> ConversationalRetrievalChain은 LangChain에서 제공하는 대화형 정보 검색 시스템으로, 사용자 질의와 대화 이력을 바탕으로 관련 문서를 검색하고 적절한 응답을 생성한다. 이 시스템은 질문 이해, 정보 검색, 컨텍스트 유지, 응답 생성의 단계를 통합하여 자연스러운 대화형 정보 제공을 가능하게 한다.\n\n## 개요\n\n대화형 시스템에서 사용자 질문에 대한 정확하고 신속한 응답은 필수적이다. `ConversationalRetrievalChain`은 이러한 요구를 충족시키기 위해 개발된 핵심 컴포넌트로, 복잡한 자연어 처리 알고리즘과 데이터 검색 기술을 통합하여 사용자 질문에 가장 관련성 높은 정보를 제공한다. 이 체인은 다양한 소스에서 데이터를 동적으로 추출하고 분석하여, 빠르고 정확한 대답을 가능하게 한다.\n\n[[RAG+Groq]]와 [[Agent 사용 RAG+Tavily]]와 같은 다른 RAG 구현 방식과 비교할 때, ConversationalRetrievalChain은 대화 컨텍스트를 유지하는 데 특화되어 있다.\n\n---\n\n## ConversationalRetrievalChain 기본 구조\n\nConversationalRetrievalChain은 다음과 같은 주요 매개변수를 사용한다:\n\n- **chat_history**: 이전 대화 기록(메시지 리스트)\n- **new_question**: 사용자의 새로운 질문\n\n이 체인은 질문에 대한 답변을 반환하며, 내부적으로 여러 하위 체인을 조합하여 최종 결과를 생성한다.\n\n### 기능 및 구조\n\n`ConversationalRetrievalChain`은 다음과 같은 여러 구성 요소로 이루어져 있다:\n\n1. **질문 이해**: 사용자의 질문을 분석하고 이해하는 첫 단계로, NLP 기술을 활용하여 질문의 핵심 키워드와 의도를 파악\n2. **정보 검색**: 분석된 키워드와 의도를 바탕으로 데이터베이스나 인터넷과 같은 다양한 정보 소스에서 관련 정보를 검색\n3. **정보 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/Agent 사용 RAG+Tavily.md",
    "title": "Agent 사용 RAG+Tavily",
    "description": "LangChain Agent와 Tavily 검색 엔진을 활용한 고급 RAG 시스템 구현 방법과 활용 사례 분석",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> LangChain Agent와 Tavily 검색 엔진을 결합한 RAG 시스템은 PDF 검색, 웹 검색 등 다양한 정보 소스를 통합하여 더 정확하고 신뢰할 수 있는 응답을 생성한다. 에이전트 기반 접근 방식은 복잡한 질의에 대해 단계적 추론과 정보 탐색이 가능하며, 특히 법률, 의학 등 전문 도메인에서 뛰어난 성능을 보인다.\n\n## 개요\n\nRAG(Retrieval-Augmented Generation) 시스템은 LLM의 환각 현상(Hallucination)을 줄이고 최신 정보를 반영할 수 있는 효과적인 방법이다. 여기에 Agent 기반 접근 방식을 도입하면 더욱 강력한 정보 검색 및 추론 시스템을 구축할 수 있다. 이 문서에서는 LangChain Agent와 Tavily 검색 엔진을 결합한 고급 RAG 시스템 구현 방법과 실제 활용 사례를 살펴본다.\n\n[[LLM Chain Chatbot + RAG]]와 [[RAG+Groq]]에서 다룬 기본적인 RAG 시스템보다 더 발전된 접근 방식으로, 복잡한 질의에 대한 정교한 응답을 생성할 수 있다.\n\n---\n\n## Agent 기반 RAG의 개념과 구조\n\n### Agent란 무엇인가?\n\nAgent는 주어진 목표를 달성하기 위해 환경과 상호작용하며 자율적으로 의사결정을 수행하는 AI 시스템이다. LangChain에서 Agent는 다음과 같은 특징을 가진다:\n\n1. **도구 사용 능력**: 다양한 도구(검색, 계산, 코드 실행 등)를 활용할 수 있음\n2. **단계적 추론**: 복잡한 문제를 작은 단계로 나누어 해결\n3. **자율적 의사결정**: 어떤 도구를 언제 사용할지 스스로 결정\n\n### Tavily 검색 엔진\n\nTavily는 AI에 최적화된 검색 API로, 다음과 같은 특징을 가진다:\n\n- 웹 검색 최적화: LLM과의 통합을 위해 설계된 검색 결과 제공\n- 다양한 검색 모드: 키워드 검색, 시맨틱 검색 등 지원\n- 컨텍스트 인식: 질문의 맥락을 이해하여 관련성 높은 결과 제공\n\n### A"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/차원 축소 (Dimensionality Reduction) 기법.md",
    "title": "차원 축소 (Dimensionality Reduction) 기법",
    "description": "데이터의 복잡성을 줄이는 주요 차원 축소 기법인 PCA, t-SNE, UMAP의 개념과 활용법을 정리한 글이다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 차원 축소는 고차원 데이터를 저차원으로 변환하여 데이터의 핵심 정보를 보존하면서 복잡성을 줄이는 기법이다. 선형 방법인 PCA와 비선형 방법인 t-SNE, UMAP의 특징과 활용법을 설명한다.\n\n## 차원 축소의 필요성\n\n고차원 데이터는 분석과 시각화에 어려움을 주고, 계산 비용이 높으며, '차원의 저주'라 불리는 문제를 일으킨다. 차원 축소는 이러한 문제를 해결하면서 데이터의 핵심 패턴을 보존하는 방법이다.\n\n차원 축소는 머신러닝의 전처리 단계에서 중요한 역할을 하며, [[Anomaly Detection|이상 탐지]]와 [[Imbalanced Data Prediction(Anomaly Detection)|불균형 데이터 처리]]에도 효과적으로 활용된다.\n\n---\n\n## PCA (Principal Component Analysis)\n\nPCA는 가장 널리 사용되는 선형 차원 축소 방법이다.\n\n### 작동 원리\n\n- 데이터의 분산을 최대화하는 주성분(Principal Component) 방향으로 데이터를 투영한다.\n- 주성분은 데이터의 공분산 행렬의 고유벡터로부터 얻어진다.\n- 고유값이 큰 순서대로 주성분을 선택하여 차원을 축소한다.\n\n### 활용 분야\n\n- 노이즈 제거\n- 데이터 시각화\n- 특징 추출\n- 데이터 압축\n\n### 코드 예시\n\n```python\nfrom sklearn.decomposition import PCA  \nimport matplotlib.pyplot as plt\n\n# PCA 모델 생성 (2차원으로 축소)\npca = PCA(n_components=2) \n\n# 데이터 변환\nreduced_data = pca.fit_transform(data)\n\n# 설명된 분산 비율 확인\nprint(f\"설명된 분산 비율: {pca.explained_variance_ratio_}\")\n\n# 결과 시각화\nplt.figure(figsize=(10, 8))\nplt.scatter(reduced_data[:, 0], reduced_data[:,"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/2025-06-04-Agent Architecture Comparison.md",
    "title": "LLM 에이전트 아키텍처 비교 - ReAct, Plan-and-Execute, Supervisor",
    "description": "워크플로우와 에이전트의 차이점, 그리고 ReAct, Plan-and-Execute, Supervisor 아키텍처의 특징과 장단점을 체계적으로 비교 분석한 포괄적 가이드",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> LLM 기반 시스템의 두 가지 주요 접근법인 워크플로우와 에이전트의 근본적인 차이점을 설명하고, 에이전트 아키텍처인 ReAct, Plan-and-Execute, Supervisor의 작동 원리와 장단점을 비교 분석한다. 각 아키텍처의 적합한 사용 사례와 함께 사용자 경험 향상을 위한 의사결정 과정 시각화의 중요성, 그리고 MCP와 A2A 같은 표준화 프로토콜의 미래 발전 방향을 알아본다.\n\n> [!info]\n> 이 글은 [[데블챌 데이터 블로그 챌린지]] 참여 글입니다.\n\n## 1. 서론\n\n최근 LLM(Large Language Model) 기술의 발전과 함께 에이전트(Agent) 시스템이 주목받고 있다. LLM 에이전트는 자연어 기반 AI 시스템으로, 사용자의 목표를 달성하기 위해 추론하고, 계획을 세우며, 도구를 사용하는 능력을 갖추고 있다. 에이전트의 성능과 기능은 기반이 되는 아키텍처에 크게 영향을 받으며, 각 아키텍처는 고유한 강점과 약점을 가지고 있다.\n\n### AI 에이전트의 개념\n\n![LLM 활용 방식의 분류](https://i.imgur.com/cXYdfmp.png)\n\n위 다이어그램은 LLM 활용 방식의 근본적인 차이를 보여준다:\n\n**워크플로우(Workflows)와 에이전트(Agent)의 핵심 차이점:**\n\n1. **워크플로우**: LLM이 사전 정의된 코드 흐름 내에서만 작동\n   - LLM은 고정된 프로세스 내에 내장되어 있거나 제한된 경로를 따라 흐름 제어\n   - 프롬프트 체이닝, 병렬화, 오케스트레이션 등 미리 설계된 구조 내에서 실행\n\n2. **에이전트**: LLM이 환경 피드백을 기반으로 자신의 행동을 결정\n   - 도구 선택과 사용을 스스로 결정하고 결과에 따라 다음 행동 조정\n   - 자율적 의사결정과 환경과의 상호작용이 핵심\n\n이 글에서 다루는 ReAct, Plan-and-Execute, Supervisor 아키텍처는 모두 에이전트 범주에 속하며, 각기 다른 방식으로 의사결정과 행동을 수행한다."
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/LangChain.md",
    "title": "LangChain",
    "description": "LangChain 프레임워크의 기본 개념, 활용 방법 및 LLama2와 결합한 실전 프로젝트 구현 과정 설명",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n> [!summary]\n> \n> LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발을 위한 프레임워크로, LLM을 다양한 데이터 소스 및 환경과 연결하는 도구를 제공한다. 이 문서는 LangChain의 기초부터 LLM(OpenAI, Llama2, Gemini Pro)과의 통합, PDF 쿼리 구현, 블로그 생성 애플리케이션 개발까지 실습 중심으로 다룬다. 특히 Llama2의 아키텍처, 훈련 세부사항, 하드웨어 요구사항 및 미세 조정 방법에 대한 연구 내용을 포함한다.\n\n## 개요\n\nLangChain은 대규모 언어 모델(LLM)을 다양한 애플리케이션에 통합하기 위한 프레임워크다. 이 문서에서는 LangChain의 기본 개념부터 실제 프로젝트 구현까지 실습 중심으로 살펴본다.\n\n### 학습 방법\nLangChain 공식 문서는 내용이 방대하여, 처음부터 정독하기보다 먼저 실습 위주로 경험한 후 공식 문서를 체계적으로 학습하는 접근법을 채택했다.\n\n### 참고자료\n- **유튜브 튜토리얼**: [LangChain 입문 가이드](https://www.youtube.com/watch?v=aWKrL4z5H6w)\n\n---\n\n## LangChain 실습 아젠다\n\n실습 중심의 LangChain 학습 계획은 다음과 같다:\n\n1. **환경 설정 및 OpenAI API 연동**\n2. **기본 애플리케이션 구축**\n   - LLM 및 채팅 모델 활용\n   - 프롬프트 템플릿 작성\n   - 출력 파서 구현 (PromptTemplate + LLM + OutputParser)\n\n> [!Note]\n> requirements.txt에 ipykernel을 추가하지 않는 이유는 개발 단계에서만 필요하고 실제 배포 시에는 필요하지 않기 때문이다.\n\n---\n\n## PDF 쿼리 시스템 구현\n\nLangChain을 활용한 PDF 쿼리 시스템 구축에 대해 알아본다.\n\n### Apache Cassandra(Astra DB)\n- 오픈 소스 NoSQL 데이터베이스\n- 확장성과 고가용성 제공\n\n### D"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/MCP(Model Context Protocal).md",
    "title": "MCP(Model Context Protocol)",
    "description": "Anthropic에서 개발한 MCP(Model Context Protocol)의 개념, 구조 및 활용에 대한 설명",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n> [!summary]\n> MCP(Model Context Protocol)는 Anthropic에서 개발한 개방형 프로토콜로, AI 모델과 외부 데이터/도구를 표준화된 방식으로 연결한다.\n> USB-C와 같이 AI 애플리케이션과 다양한 데이터 소스 간의 통합을 단순화하며, 클라이언트-서버 구조를 통해 안전하고 확장 가능한 AI 시스템 구축을 지원한다.\n> Smithery를 통해 3,200개 이상의 MCP 서버에 접근할 수 있으며, Cursor와 Claude에서 쉽게 설정하여 사용할 수 있다.\n\n## 개요\n\n### MCP란?\n\n![](https://i.imgur.com/q4T1fhr.png)\n\n\nMCP(Model Context Protocol)는 AI 모델과 외부 데이터 소스 및 도구를 연결하는 개방형 프로토콜이다. Anthropic에서 개발했으며, LLM 애플리케이션 개발 시 맞춤형 통합 솔루션 대신 표준화된 방식으로 데이터와 도구에 접근할 수 있게 한다.\n\n쉽게 말해, MCP는 AI 모델에게 필요한 컨텍스트(문맥)를 가져오기 위한 표준 프로토콜로, USB-C를 AI 애플리케이션에 적용한 것과 같은 방식으로 이해할 수 있다.\n\n![](https://i.imgur.com/LooAPju.png)\n\n### MCP의 인기 상승 요인\n\n\n![](https://i.imgur.com/lPhU3Vg.png)\n\n\nMCP는 2024년 11월에 처음 발표되었을 때는 큰 반향을 불러일으키지 못했지만, 2025년 초부터 AI 커뮤니티에서 급격한 인기를 얻게 되었다. 이러한 인기 상승에는 여러 요인이 있다:\n\n1. **핵심 채택 장벽 - 호스트 부족 문제 해결**: MCP의 초기 채택이 저조했던 주된 이유는 MCP를 실제로 사용할 수 있는 호스트 애플리케이션이 부족했기 때문이다. 아이디어는 훌륭했지만, Claude Desktop만으로는 개발자 생태계 전체에 영향을 미치기 어려웠다. Cursor, Windsurf, Cline 등 인기 있는 개발자 도구들이 MCP를 지원하기 시작하면서 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/2025-10-13-pgvector-vs-Qdrant-vs-Milvus-Performance-Comparison.md",
    "title": "2025년 pgvector vs Qdrant vs Milvus 상세 성능 비교",
    "description": "2025년 최신 버전을 기준으로 pgvector (PostgreSQL 18), Qdrant 1.15, Milvus 2.6의 실제 성능, 기능, 비용을 상세 비교한다. 데이터 삽입, 검색 속도, 필터링, 확장성, 실전 시나리오별 권장사항을 다룬다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> 2025년 현재 주요 벡터 데이터베이스인 **pgvector (PostgreSQL 18)**, **Qdrant 1.15**, **Milvus 2.6**의 상세 성능 비교다. PostgreSQL 18의 비동기 I/O는 pgvector의 처리량을 11.4배 향상시켰고, Milvus 2.6은 72% 메모리 절약과 4배 QPS 향상을 달성했으며, Qdrant 1.15는 sparse vector 성능을 16배 개선했다. 각 DB는 뚜렷한 강점을 가지며, 사용 사례에 따라 최적 선택이 달라진다.\n\n## 테스트 환경 및 버전\n\n### 비교 대상 버전\n\n| 데이터베이스 | 버전 | 출시일 | 주요 개선 |\n|------------|------|--------|----------|\n| **pgvector** | 0.7.0 + PostgreSQL 18 | 2024년 9월 | 비동기 I/O, SIMD 최적화 |\n| **Qdrant** | 1.15.0 | 2025년 8월 | Sparse vector 16배 개선 |\n| **Milvus** | 2.6.0 | 2025년 6월 | 72% 메모리 절약, BM25 |\n\n### 테스트 사양\n\n**하드웨어:**\n- CPU: 16 코어\n- RAM: 64GB\n- 스토리지: NVMe SSD 1TB\n- OS: Linux (io_uring 지원)\n\n**데이터셋:**\n- 벡터 차원: 1536 (OpenAI text-embedding-3-small)\n- 벡터 수: 1M, 10M, 50M, 100M\n- 메타데이터: JSON (5-10개 필드)\n\n## 1. 데이터 삽입 성능 상세 비교\n\n### 삽입 속도 벤치마크\n\n| 데이터베이스 | 1M 벡터 | 10M 벡터 | 50M 벡터 | 100M 벡터 |\n|-------------|---------|----------|----------|-----------|\n| **Milvus 2.6** | 12.02초 (삽입)<br>+ 0.60초 (인덱싱) | ~2분 | ~11분 | ~20분 (예"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/RAG+Groq.md",
    "title": "RAG+Groq",
    "description": "Groq LPU 모델을 활용한 RAG 시스템 구축 및 성능 특징 설명",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n> [!summary]\n> \n> 이 문서는 RAG(Retrieval-Augmented Generation) 시스템에 Groq의 고성능 LPU(Language Processing Unit)를 결합한 아키텍처를 설명한다. Groq는 GenAI 추론 속도의 새로운 기준을 제시하며, 특히 LPU는 언어 처리와 같은 순차적 특성을 가진 계산 집약적 애플리케이션에 최적화된 처리 유닛이다. 이 조합을 통해 높은 처리 속도와 정확성을 동시에 달성할 수 있는 방법을 소개한다.\n\n## 개요\n\nRAG(Retrieval-Augmented Generation)와 Groq의 고성능 LPU(Language Processing Unit)를 결합하여 빠르고 정확한 정보 검색 및 생성 시스템을 구축하는 방법을 살펴본다.\n\n### 참고자료\n- **YouTube**: [RAG+Groq 소개 영상](https://www.youtube.com/watch?v=p42BzKKAO74&t=20s)\n\n---\n\n## RAG+Groq 아키텍처\n\nRAG와 Groq을 결합한 시스템의 기본 아키텍처는 다음과 같다:\n\n![RAG+Groq 아키텍처](https://i.imgur.com/HDQW885.png)\n\n이 아키텍처는 문서 검색과 생성 모델의 장점을 결합하여 더 정확하고 빠른 응답을 제공한다.\n\n---\n\n## Groq 특징\n\nGroq은 GenAI 추론 속도에 있어 새로운 표준을 제시하는 플랫폼이다.\n\n### LPU (Language Processing Unit)\n- 언어 처리 유닛으로, AI 언어 애플리케이션과 같은 순차적 특성을 가진 계산 집약적 애플리케이션을 위한 최고 속도의 추론을 제공\n- 기존 GPU와 달리 언어 처리에 최적화된 아키텍처 설계\n- 순차적 처리가 필요한 LLM 작업에서 탁월한 성능 발휘\n\n### 성능 장점\n- 낮은 지연 시간: 거의 실시간 응답 가능\n- 높은 처리량: 동시에 많은 요청 처리 가능\n- 비용 효율성: 기존 GPU 기반 솔루션 대비 경제적\n\n---\n\n## RAG+Groq 구현 방법"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/RAG용 PDF Loader 비교.md",
    "title": "RAG용 PDF Loader 비교",
    "description": "LangChain에서 사용 가능한 다양한 PDF Loader 라이브러리들의 특징과 성능을 비교 분석한 문서",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> RAG 시스템의 성능은 PDF 문서에서 얼마나 정확하게 텍스트와 이미지를 추출하는지에 크게 의존한다. PyMuPDF와 PyPDFium2 같은 Loader들은 각각 고유한 장단점을 가지고 있으며, 사용 목적에 따라 적절한 선택이 필요하다.\n\n## 개요\n\nRAG 성능 향상 방법엔 여러가지 기법이 있지만, 기본적으로 자료에서 Document를 얼마나 잘 가져오느냐가 중요하다. 특히, Hallucination 확인, 자세한 출처 표기, 그리고 알맞은 image extraction을 위해, 성능이 좋은 PDF Loader는 필수적이다. [[LangChain]]에서 제공하는 다양한 PDF Loader들의 특징과 성능을 비교해보자.\n\n---\n\n## PDF Loader 비교\n\nRAG 시스템 구축 시 PDF 처리는 중요한 부분을 차지한다. 여기서는 주요 PDF Loader들을 비교한다.\n\n### PyMuPDF\n\n[테디노트 PyMuPDF 개발자 라이브 미팅 유투브](https://www.youtube.com/watch?v=VemLpb1UXRs&t=18s)\n[PyMuPDF for LLM&RAG](https://pymupdf.readthedocs.io/en/latest/rag.html)\n\nPyMuPDF는 다음과 같은 특징을 가진다:\n\n- **주요 고객사**: OpenAI, Notion, Anthropic\n- **라이선스**: 상업목적 사용 시 별도 라이선스 구매 필요\n- **핵심 특징**: \n  - C 기반의 MuPDF 기반으로 매우 빠른 처리 속도 제공\n  - Pdfminer.six 대비 6배 빠른 속도\n  - 정확한 텍스트 및 이미지 추출 지원\n\n![PyMuPDF 성능 비교](https://i.imgur.com/AkluzNm.png)\n\n> [!Note]\n> PyMuPDF는 상업적 사용 시 라이선스 비용이 발생하므로 프로젝트의 성격에 따라 라이선스 조건을 확인해야 한다.\n\n### PyPDFium2Loader\n\nPyPDFium2Loader는 [["
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/Anomaly Detection.md",
    "title": "Anomaly Detection",
    "description": "이상 탐지(Anomaly Detection)의 주요 방법론과 기법을 정리하고 각 접근법의 장단점을 비교한 글이다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 이상 탐지(Anomaly Detection)는 데이터에서 일반적인 패턴과 다른 비정상적인 샘플을 식별하는 기법이다. 지도학습, 준지도학습, 비지도학습 방식으로 나뉘며, 각 방식은 데이터와 문제 상황에 따라 선택적으로 적용할 수 있다.\n\n## 이상 탐지 개요\n\n이상 탐지(Anomaly Detection)는 데이터셋에서 정상적인 패턴과 다른 이상 패턴을 식별하는 기술이다. 제조업의 결함 탐지, 금융 사기 탐지, 네트워크 침입 감지, 의료 진단 등 다양한 분야에서 활용된다.\n\n---\n\n## 데이터셋 예시\n\n### Company Bankruptcy Prediction\n\n[Kaggle의 Company Bankruptcy Prediction 데이터셋](https://www.kaggle.com/datasets/fedesoriano/company-bankruptcy-prediction)은 기업의 파산 여부를 예측하는 데 사용된다. 이는 심각한 불균형 데이터로, 파산 기업(소수 클래스)이 매우 적다.\n\n#### 문제 정의\n\n기업 파산은 기업뿐만 아니라 글로벌 경제에도 부정적인 영향을 미친다. 따라서 기업이 파산의 징후를 보이는지 예측하는 모델을 개발하는 것이 중요하다.\n\n#### 데이터 특성\n\n이 데이터는 1999년부터 2009년까지 대만 경제 저널에서 수집되었으며, 다음과 같은 다양한 재무 비율 열로 구성된다:\n\n- 자산수익률(ROAs)\n- 총이익\n- 영업 및 순이익과 비용\n- 현금 흐름\n- 세금\n- 성장률\n- 부채\n- 매출, 수익, 부채 등\n\n모든 특성은 0에서 1 사이로 정규화되어 있다. 목표 열은 \"Bankrupt?\"(0: 아니오, 1: 예)이다.\n\n이 데이터는 [[Imbalanced Data Prediction(Anomaly Detection)|불균형 데이터 처리]]가 필요한 전형적인 예시다.\n\n---\n\n## 이상 탐지 방법론\n\n이상 탐지 방법론은 크게 세 가지로 나눌 수 있다:\n\n### 1. 지도학습 기반 이상 탐지 (Superv"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/AI/2025-10-13-pgvector-PostgreSQL-Vector-Database-Extension.md",
    "title": "pgvector: PostgreSQL의 벡터 검색 익스텐션",
    "description": "PostgreSQL에서 벡터 검색을 가능하게 하는 pgvector 익스텐션의 개념, 작동 원리, 인덱스 알고리즘(HNSW), 그리고 다른 벡터 데이터베이스와의 비교를 다룬다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> pgvector는 PostgreSQL에서 벡터 데이터를 저장하고 검색할 수 있게 해주는 오픈소스 익스텐션이다. HNSW(Hierarchical Navigable Small World) 알고리즘을 통해 빠른 ANN(Approximate Nearest Neighbor) 검색을 지원하며, PostgreSQL의 모든 기능(트랜잭션, JOIN, 집계)을 벡터 검색과 함께 활용할 수 있다는 점이 최대 강점이다. Qdrant, Milvus 같은 전용 벡터 DB 대비 운영 복잡도가 낮고, Full Text Search와 결합한 Hybrid Search를 SQL 네이티브로 구현할 수 있다.\n\n## pgvector란?\n\n### 개념\n\n**pgvector**는 PostgreSQL에 벡터 데이터 타입과 벡터 연산 기능을 추가하는 익스텐션이다. 기계학습 모델이 생성한 임베딩 벡터(embedding vector)를 데이터베이스에 저장하고, 코사인 유사도나 유클리디안 거리 같은 벡터 연산을 통해 의미적으로 유사한 데이터를 검색할 수 있게 해준다.\n\n**주요 특징:**\n- ✅ PostgreSQL 익스텐션으로 설치 간편\n- ✅ 벡터 데이터 타입 지원 (`vector(n)`)\n- ✅ 다양한 거리 함수 (코사인, L2, 내적)\n- ✅ HNSW 인덱스로 빠른 ANN 검색\n- ✅ SQL 표준 문법으로 벡터 검색\n- ✅ PostgreSQL의 모든 기능과 호환\n\n### 왜 pgvector인가?\n\n**기존 벡터 DB의 한계:**\n\n| 문제 | 설명 | pgvector 해결 |\n|------|------|--------------|\n| **분산된 데이터** | 벡터는 Qdrant, 메타데이터는 RDB | 단일 DB 통합 |\n| **복잡한 쿼리** | JOIN, 집계 제한적 | SQL 모든 기능 활용 |\n| **트랜잭션 부재** | 데이터 일관성 보장 어려움 | ACID 트랜잭션 지원 |\n| **운영 복잡도** | 2개 DB 시스템 관리 | PostgreSQL 하나로 |\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/2024-01-03-Git Blog SSG 비교.md",
    "title": "정적 사이트 생성기(SSG) 비교 - Jekyll vs Hugo vs Hexo",
    "description": "Git 블로그를 위한 정적 사이트 생성기(SSG) 비교 및 선택 가이드",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> GitHub Pages로 배포하는 정적 웹사이트 생성기(SSG) 중 Jekyll, Hugo, Hexo, Gatsby 등의 특징과 장단점을 비교 분석한다. 각 SSG의 성능, 생태계, 학습 곡선, 커스터마이징 난이도를 평가하여 자신에게 맞는 블로그 플랫폼을 선택하는 가이드를 제공한다.\n\n## Intro: \n깃 블로그 리뉴얼을 위해 알아보던 중, Github Pages로 배포하는 정적 웹사이트 생성기 방식 중 기존에 내가 쓰던 Jekyll 외에도 Hexo, Hugo, Gatsby 등 많은 SSG(Static Site Generators)가 있다는걸 알게 되었다. \n\n따라서 이 번 포스트에서는 세 방식의 차이를 비교하고, 나에게 알맞는 방식을 채택하고자 한다.\n\n\n## Github Stars 수\n\n### Star-history를 통한 Github Stars 트랜드 비교\n\n출처: [https://star-history.com/](https://star-history.com/)\n\n\n[![Star History Chart](https://api.star-history.com/svg?repos=jekyll/jekyll,hexojs/hexo,gatsbyjs/gatsby,gohugoio/hugo&type=Date)](https://star-history.com/#jekyll/jekyll&hexojs/hexo&gatsbyjs/gatsby&gohugoio/hugo&Date)\n\n\n### 언어별 SSG Github stars 수\n\n출처: [https://ssg-dataset.streamlit.app/](https://ssg-dataset.streamlit.app/)\n\n![](https://i.imgur.com/lzPCS5D.png)\n\n\n### Jemstars Site Generators Github Stars 순위\n출처: [https://jamstack.org/generators/](https://jamstack.org/generators/)\n\n![]("
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/2024-01-05-Hugo 블로그 생성 연습.md",
    "title": "Hugo 블로그 생성 연습",
    "description": "Jekyll에서 Hugo로 블로그 마이그레이션을 위한 Hugo 학습 노트",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 기존 Jekyll 기반 블로그에서 Hugo 기반 블로그로 전환하기 전, Hugo를 실습하며 익히는 과정을 정리한 노트이다. Hugo 설치, 테마 적용, 설정 방법, 그리고 Jekyll과의 차이점을 다루며 마이그레이션 준비를 한다.\n\n## Intro: \n\n기존 `Jekyll`기반 블로그에서 `Hugo`기반 블로그로 전환 이전에 `Hugo`를 어느정도 다뤄보고 이전하는것이 좋을것 같아 이것저것 만져보려고 한다. \n\n일단은 Hugo 메인 페이지에 있는 Quickstart를 따라해보고, Docs를 읽어보는것으로 시작해보자\n\n\n## Quickstart\n\n### Prerequisites\n1. Hugo\n\t- [https://gohugo.io/installation/](https://gohugo.io/installation/)\n2. Git\n\t- [https://git-scm.com/downloads](https://git-scm.com/downloads)\n\n\n### Hugo extended edition for MacOS\n```sh\nbrew install hugo\n```\n\n\n\n### 시행착오\n\n나는 **[hugoplate](https://github.com/zeon-studio/hugoplate)** 템플렛을 골라서 진행하고자 했었다\n\n> 템플릿 README에도 Quickstart 방법이 설명되어 있지만, `npm`을 사용한 커스텀 스크립트를 사용하길래 일단은 정식 Hugo 시작방법을 따라가보았다. 정석대로 진행해보고 문제가 생긴다면 ReadMe를 따라해볼 생각이다.\n\n```shell\nhugo new site quickstart\ncd quickstart\ngit submodule add https://github.com/zeon-studio/hugoplate\nhugo server\n```\n\n![](https://i.imgur.com/TmDqPqr.png)\n\n> 문제가 생겼지만 일단은 http://localhost:1313/ 에 띄워졌다고 한다. 가"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/2024-08-02-Second-Brain-RAG.md",
    "title": "Second Brain 기반 RAG 시스템 구축",
    "description": "Second Brain 개념을 RAG 시스템에 적용하여 개인화된 AI 에이전트 구축하기",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Second Brain 개념을 RAG(Retrieval-Augmented Generation) 시스템에 적용하는 아이디어를 탐구한다. 개인의 지식 데이터베이스를 체계적으로 구축하고 이를 RAG에 활용하면 성능 향상은 물론, 개인의 경험과 지식을 가진 Multi-Agent 구현이 가능할 것으로 기대한다.\n\n\n## Intro\n\nRAG 공부를 하다보니, 문득 이전에 잠깐 관심 가졌었던 Second Brain 개념을 RAG에 활용하면 성능 향상에 도움이 되지 않을까 생각이 들었다. Second Brain과 note taking 방법 등 공부해봐야 확실해지겠지만, 충분히 가능할것 같고, 이를 응용하고, 나의 지식 데이터베이스가 충분히 쌓인다면, 나의 경험을 가진 Multi-Agent 구현이 가능해질것이라 기대해본다.\n\n#### 목표:\nNote taking 방법부터, Retrieve, Generate, Publish까지의 과정을 반자동화\n\n## 개념\n### Second Brain\n\n- **목적**: 개인의 지식 수집, 저장, 조직, 활용\n- **방식**: 디지털 도구로 정보를 체계적으로 관리\n- **사용 예시**: Notion, Evernote, Obsidian 등으로 자료와 아이디어를 정리하여 창의적인 작업에 활용\n\n### RAG (Retrieval-Augmented Generation)\n\n- **목적**: AI 모델의 정보 생성 능력 향상\n- **방식**: 검색과 생성 기술 결합\n- **특징**: 대규모 데이터베이스에서 정보 검색 후, 이를 바탕으로 언어 모델이 응답 생성\n\n### 두 개념의 통합\n\n- **개인화 정보 관리**: Second Brain에 RAG 적용으로 정보 검색과 콘텐츠 생성 강화\n- **효율적 탐색**: 문맥 기반 정보 검색으로 더 나은 자료 활용\n- **생산성 향상**: RAG AI 비서로 프로젝트 관리와 아이디어 생성 지원\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/바이브코딩과 커서(Cursor).md",
    "title": "바이브코딩과 커서(Cursor)",
    "description": "바이브코딩이란 무엇인지, 그리고 AI 코딩 도구인 Cursor를 활용하는 방법과 사용 후기에 대한 글이다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 바이브코딩은 코딩에 대한 즐거움과 몰입을 중시하는 개발 철학으로, AI 도구를 활용하여 개발 생산성을 높이는 방식이다. Cursor는 이러한 바이브코딩을 지원하는 AI 코딩 도구로, VS Code 기반에 강력한 AI 기능을 더해 개발자 경험을 향상시킨다. 업스테이지에서는 많은 개발자가 Cursor를 활용해 생산성을 높이고 있다.\n\n\n> [!info]\n> 이 글은 [[데블챌 데이터 블로그 챌린지]] 참여 글입니다.\n\n## 바이브코딩이란?\n\n바이브코딩(Vibe Coding)은 단순히 코드를 작성하는 것을 넘어 개발 과정에서의 몰입과 즐거움을 중요시하는 개발 철학이다. 전통적인 코딩 방식에서는 구문 오류, 디버깅, 반복적인 작업 등으로 인해 개발의 흐름이 끊기는 경우가 많았다. 바이브코딩은 이러한 방해 요소를 최소화하고, 개발자가 창의적인 문제 해결과 설계에 집중할 수 있도록 한다.\n\n바이브코딩은 전 Tesla AI 디렉터이자 OpenAI의 설립 멤버인 Andrej Karpathy가 처음 사용한 용어로, \"코딩에 별로 공수를 들이지 않고 LLM에게 다 시켜서 바이브대로 간다\"는 의미를 담고 있다. 이것이 가능해진 이유는 Cursor와 같은 도구가 발전했고, 최근 LLM 모델들의 코딩 능력이 크게 향상되었기 때문이다.\n\n> [!info] Andrej Karpathy: \n> \"There's a new kind of coding I call \"vibe coding\", where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It's possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. Also I just talk to Composer with SuperWhisper so I barely even touch the keyboard. I "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/LangFlow.md",
    "title": "LangFlow - AI 워크플로우 시각적 구축 도구",
    "description": "GitHub trending에서 발견한 MIT 라이센스 오픈소스 도구 LangFlow를 리뷰한 글이다. 노코드 챗봇 개발을 위한 다양한 도구 리서치 과정에서 살펴본 장단점과 실제 사용 경험을 공유하는 글이다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> LangFlow는 AI 워크플로우를 시각적으로 구축할 수 있는 오픈소스 도구로, 68.5k의 GitHub 스타를 받은 인기 프로젝트다. 드래그 앤 드롭 인터페이스와 다양한 AI 컴포넌트를 제공하지만, 실제 사용해보니 생각보다 복잡하고 높은 러닝 커브가 존재한다. MIT 라이센스로 제공되는 점은 매력적이지만, 비슷한 도구인 n8n의 하위호환 같은 느낌이며, 진정한 노코드 경험을 제공하기에는 아직 부족하다. 개발자에게는 유용할 수 있으나 일반 사용자에게 추천하기는 어려운 도구라는 것이 솔직한 평가다.\n\n> [!info]\n> 이 글은 [[데블챌 데이터 블로그 챌린지]] 참여 글입니다.\n\n## 소개\n\n![](https://i.imgur.com/DTM6zKT.png)\n\nGitHub trending 레포를 둘러보다가 발견한 LangFlow를 리뷰한다. 나는 곧 노코드 챗봇 개발이 예정되어 있어서, 다양한 도구를 리서치하고 있는 중이다. LangFlow는 MIT 라이센스로 제공되는 오픈소스 프로젝트로, 완전히 자유롭게 사용, 수정 및 배포가 가능하다는 점이 매력적이다.\n\n## 핵심 기능\n\nLangFlow는 AI 기반 에이전트와 워크플로우를 구축하고 배포하기 위한 강력한 도구다. 주요 기능은 다음과 같다:\n\n1. **시각적 빌더(Visual Builder)** - 드래그 앤 드롭 방식으로 빠르게 워크플로우를 구성하고 반복할 수 있다. 코딩 지식이 부족해도 복잡한 AI 시스템을 설계할 수 있다.\n\n2. **코드 액세스(Access to Code)** - 개발자가 Python을 사용하여 모든 컴포넌트를 세밀하게 조정할 수 있다. 시각적 인터페이스만으로는 불가능한 커스터마이징도 가능하다.\n\n3. **플레이그라운드(Playground)** - 만든 워크플로우를 즉시 테스트하고 단계별로 제어하며 반복 개선할 수 있다. 실시간 디버깅과 결과 확인이 용이하다.\n\n4. **멀티 에이전트(Multi-agent)** - 여러 AI 에이전트 간의 오케스트레이션, "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/2024-08-25-Visual Zettelkasten.md",
    "title": "Visual Zettelkasten - 시각적 지식 관리",
    "description": "Excalidraw를 활용한 시각적 Zettelkasten 시스템 구축",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Excalidraw 플러그인을 활용하여 Zettelkasten 시스템을 시각화하는 방법을 다룬다. 텍스트 기반 노트에 시각적 요소를 추가하여 지식 그래프를 만들고, 아이디어 간의 연결을 더 직관적으로 표현하는 Visual Zettelkasten 구축 방법을 설명한다.\n\n## Intro\n\n![](https://i.imgur.com/57noLAD.png)\n\n\n![](https://i.imgur.com/7eWgP45.png)\n\n\n무의식속에 수많은 그래프를 끄집어내 형상화 시키는 목적을 갖고 있음\n\n\n백문이 불여일견: A picture is worth a thousand words\n\n\n![](https://i.imgur.com/PmtfNae.png)\n\n- 2D PKM: 노트\n- 3D PKM: 옵시디안(Connection of Notes)\n- 4D PKM: 옵시디안 + 그림까지 겸비\n\n\n## Part 1. 생각의 발산\n\n\n![](https://i.imgur.com/4cRkXRB.png)\n\n\n\n==⚠  Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠== You can decompress Drawing data with the command palette: 'Decompress current Excalidraw file'. For more info check in plugin settings under 'Saving'\n\n\n# Excalidraw Data\n## Text Elements\nVisual Zettelkasten ^AMqqvXYo\n\n%%\n## Drawing\n```compressed-json\nN4KAkARALgngDgUwgLgAQQQDwMYEMA2AlgCYBOuA7hADTgQBuCpAzoQPYB2KqATLZMzYBXUtiRoIACyhQ4zZAHoFAc0JRJQgEYA6bGwC2CgF7N6hbEcK4OCtptbErHALRY8RMpWdx8Q1TdIEfARcZgRmB"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Cursor-Project-Rules.md",
    "title": "Cursor Project Rules로 AI 코딩 어시스턴트 맞춤화하기",
    "description": "Cursor에서 Project Rules 기능을 활용하여 AI 응답을 프로젝트별로 맞춤화하는 방법을 알아본다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> Cursor의 Project Rules 기능을 통해 AI 코딩 어시스턴트의 행동을 맞춤 설정할 수 있다. 프로젝트별 규칙, 글로벌 규칙을 통해 AI가 코드를 생성하고 이해하는 방식을 정밀하게 제어할 수 있다.\n\n## Cursor Rules 소개\n\nCursor는 AI 기반 코딩 에디터로, 개발자가 코드를 작성하고 이해하는 과정을 돕는다. Cursor의 핵심 기능 중 하나는 AI의 행동을 사용자의 필요에 맞게 조정할 수 있는 'Rules for AI' 시스템이다. 이 시스템을 통해 사용자는 LLM(대규모 언어 모델)이 코드를 생성하고 이해하는 방식에 대한 지침을 제공할 수 있다.\n\nCursor에서 Rules for AI를 구현하는 방법은 크게 두 가지가 있다:\n\n1. **Project Rules** - 프로젝트 특화 규칙으로, `.cursor/rules` 디렉토리에 저장\n2. **Global Rules** - 모든 프로젝트에 적용되는 전역 규칙\n\n이전에는 프로젝트 루트에 `.cursorrules` 파일을 사용하는 방법도 있었지만, Cursor 팀은 가장 유연하고 강력한 Project Rules 사용을 권장한다.\n\n---\n\n## Project Rules 시스템 이해하기\n\nProject Rules 시스템은 경로별 구성을 통해 강력하고 유연한 시스템을 제공한다. 이 규칙들은 `.cursor/rules` 디렉토리에 저장되며, 프로젝트의 다양한 부분에서 AI 동작을 세밀하게 제어할 수 있게 해준다.\n\n### Project Rules의 주요 특징\n\n- **의미론적 설명**: 각 규칙은 적용되어야 하는 시점에 대한 설명을 포함할 수 있다\n- **파일 패턴 매칭**: glob 패턴을 사용하여 규칙이 적용될 파일/폴더를 지정\n- **자동 첨부**: 매칭되는 파일을 참조할 때 규칙이 자동으로 포함됨\n- **파일 참조**: 규칙이 적용될 때 컨텍스트로 포함될 파일을 `@file`로 참조 가능\n- **여러 규칙 연결**: `@file`을 사용하여 여러"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/2024-07-29-Zettelkasten.md",
    "title": "Zettelkasten 노트 작성 방법론",
    "description": "Zettelkasten 노트 작성 시스템의 원리와 Second Brain 구축 방법",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Zettelkasten은 독일어로 '카드 상자'를 의미하며, 지식을 연결하여 저장하는 강력한 노트 작성 시스템이다. 각 아이디어를 개별 노트로 작성하고 서로 연결하는 방식으로 Second Brain을 구축하며, Obsidian과 같은 도구를 활용하여 효과적인 개인 지식 관리 시스템(PKM)을 만들 수 있다.\n\n## What is Zettelkasten?\n- means \"books of cards\" in German\n- a method to deal with knowledge in your life\n\n\tA Zettelkasten is a personal tool for thinking and writing. It has hypertextual features to make a web of thought possible. The difference to other systems is that you create a web of thoughts instead of notes of arbitrary size and form, and emphasize connection, not a collection.\n\t\n\t제텔카스텐은 사고와 글쓰기를 위한 개인용 도구입니다. 하이퍼텍스트 기능이 있어 생각의 웹을 만들 수 있습니다. 다른 시스템과의 차이점은 임의의 크기와 형식의 노트 대신 생각의 웹을 만들고, 컬렉션이 아닌 연결을 강조한다는 점입니다.\n\n\n## Luhmann’s Zettelkasten: The beginning\n\nNiklas Luhmann: \n- considered godfather of Zettelkasten Method\n- highly productive social scientist\n\nWhat was his Zettelkasten like?\n- a collection of notes on papaer slips with a special twist: surfable *hypertext* that helped him navigate "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/2024-01-01-깃 블로그 생성.md",
    "title": "Jekyll 기반 깃 블로그 생성 가이드",
    "description": "Jekyll Hyde 테마를 활용한 포트폴리오 겸 기술 블로그 생성 가이드",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 포트폴리오용 웹페이지와 기존 깃 블로그를 통합하여 새로 만드는 과정을 정리한 가이드이다. Jekyll 기반의 Hyde 테마를 활용하여 설치, 설정, 커스터마이징, 배포까지 전 과정을 다루며 GitHub Pages로 호스팅하는 방법을 포함한다.\n\n## Intro: \n\n- 포트폴리오용 웹페이지를 만들 겸, 기존에 쓰던 깃 블로그와 합쳐 새로 만들려고 한다\n\n\n기존 theme: [cotes2020/jekyll-theme-chirpy](https://github.com/cotes2020/jekyll-theme-chirpy) \n리뉴얼 theme: [chemistryx/hyde](https://github.com/chemistryx/hyde)\n\n\n### 진행 방식: \n1. chemistry/hyde theme 다운로드\n2. 기본 설정\n3. 추가 customizing\n4. 기존 블로그 post 이동\n\n## 깃 블로그 생성\n\n### Jekyll, Ruby 등 installation\n- [https://jekyllrb.com/docs/installation/](https://jekyllrb.com/docs/installation/)\n- 위 링크의 본인 OS에 따른 가이드대로 설치\n- 확인\n\n![](https://i.imgur.com/xagkBVg.png)\n### chemistry/hyde theme 다운로드\n\n1. [https://github.com/chemistryx/hyde](https://github.com/chemistryx/hyde) 접속\n2. code > download zip 클릭\n3. 압축 풀기\n4. 원하는 폴더 위치로 이동\n\n\n![](https://i.imgur.com/W2xAYMq.png)\n> #### git clone 대신 download zip 하는 이유: \n> - git clone나 fork시 commit 해도 잔디가 안심어지는 문제가 생긴다(원본 레포지로 commit merge시에 잔디가 심어짐)\n> - 처음부터 down"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Ubuntu-Server-Setup.md",
    "title": "Ubuntu 서버 초기 설정 스크립트",
    "description": "Ubuntu 서버 초기 설정을 자동화하는 bash 스크립트와 설치되는 각 패키지의 상세 설명 및 사용법 가이드",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n# Ubuntu 서버 초기 설정 스크립트\n\n> [!summary]\n> Ubuntu 서버를 새로 받을 때마다 반복적으로 설치해야 하는 필수 패키지들이 귀찮아서 한 번에 설치하는 스크립트를 만들어 둔 것이다. Git, Docker, UV, 각종 개발 도구들을 자동으로 설치하고, 각 패키지가 무엇인지 간단히 정리해둔다.\n\n> [!warning] Ubuntu 전용 스크립트\n> 이 스크립트는 **Ubuntu (Debian 계열)** 전용이다. 다른 Linux 배포판에서는 작동하지 않을 수 있다.\n\n## 자동 설치 스크립트\n\n```bash\n#!/bin/bash\n\nset -e\n\necho \"🚀 Ubuntu 서버 초기 설정을 시작합니다...\"\n\necho \"📦 시스템 패키지 업데이트 중...\"\nsudo apt update && sudo apt upgrade -y\n\necho \"🛠️ 기본 개발 도구 설치 중...\"\nsudo apt install -y \\\n    build-essential \\\n    git \\\n    curl \\\n    wget \\\n    unzip \\\n    vim \\\n    htop \\\n    net-tools \\\n    lsof \\\n    tmux\n\necho \"🐍 UV (Python Package Manager) 설치 중...\"\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nsource $HOME/.local/bin/env\n\necho \"🗑️ 기존 Docker 패키지 제거 중...\"\nfor pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do \n    sudo apt-get remove -y $pkg 2>/dev/null || true\ndone\n\necho \"🐳 Docker 공식 버전 설치 중...\"\nsudo apt-get update\nsudo apt-get install -y ca-certificates "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/2024-03-09-Obsidian to Notion 자동화.md",
    "title": "Obsidian to Notion 자동화 가이드",
    "description": "Obsidian에서 작성한 문서를 Notion으로 자동 동기화하는 방법",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Obsidian은 개인 사용에 강력하고 Notion은 협업에 적합한데, 두 도구 모두 Markdown을 기반으로 하기에 상호 호환이 가능하다. Obsidian에서 작성한 개인 문서를 Notion 협업 페이지로 자동으로 동기화하는 방법을 탐색하여 반복 작업을 자동화한다.\n\n## Intro: \n\n개인적으로 Obsidian은 개인적 사용에 있어 매우 강력한 도구로, 반면 Notion은 협업 목적에 더 적합하다고 생각한다. 두 도구는 모두 Markdown 형식을 기반으로 하기 때문에, Obsidian에서 작성한 개인적인 문서를 Notion의 협업 페이지로 쉽게 복사하여 붙여넣을 수 있어, 두 도구를 유연하게 함께 사용할 수 있는 장점이 있다. 이러한 반복 작업을 자동화할 수 있는 방법이 있을지 궁금하여 탐색해보았다.\n\nObsidian을 개인 Github-Git Action과 연동하여 사용하고 있었고, 이번엔 협업용 Notion과 연동을 할 생각이다.\n\n## 탐색\n검색해보니 공감가는 글이 많이 보였다. 대체로 Notion은 협업이나 미디어 임베딩시 유용했고, Obsidian은 그 외 작업에 유용했다는 의견이 많았다. 그리고 extention이 많은 VSCode까지도 같이 사용하는 사람도 가끔 보였다.\n\n- [3 Proven Ways to Use Notion with Obsidian](https://bloggingx.com/use-notion-with-obsidian/) \n\n\n## 설치 방법\n\n### 1. Share to Notion 플러그인 설치\n\nObsidian Community Market에서 [Share to Notion](obsidian://show-plugin?id=obsidian-to-notion) 플러그인 설치\n\n![](https://i.imgur.com/23at9Dw.png)\n\nCommunity Plugin에서 활성화 시켜주는걸 잊지 말자\n\n![](https://i.imgur.com/l3gusTE.png)\n\n\n### 2. N"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Obsidian/Google Search Console - 도메인 vs URL 접두어 속성.md",
    "title": "Google Search Console - 도메인 vs URL 접두어 속성",
    "description": "Google Search Console's Domain property covers all URLs, while URL Prefix tracks only specific URL prefixes, offering different verification methods.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> When registering a website on Google Search Console, users can choose between Domain and URL Prefix property types. Domain properties encompass all URLs within a domain, regardless of protocol or subdomain, verified through DNS authentication, offering comprehensive data collection. URL Prefix properties track only specific URLs, including the designated protocol and subdomain, verifiable through various methods like HTML file uploads or meta tags. Domain properties are recommended for websites with multiple subdomains or both HTTP and HTTPS versions, aiming for comprehensive SEO analysis. URL Prefix properties suit those managing specific subdomains or analyzing only HTTP or HTTPS versions. It's advisable to primarily register as a Domain property and add URL Prefix properties as needed for both comprehensive and granular data insights.\n> \n\n---\n\n\n구글 서치 콘솔(Google Search Console)에 웹사이트를 등록할 때 선택할 수 있는 두 가지 주요 속성 유형인 도메인(Domain)과 URL 접두어(URL Prefix)의 차이점은 다음과 같다.\n\n   ![]"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Obsidian/검색 노출 시키는 방법.md",
    "title": "블로그 검색 노출-Google Search Console 설정, SEO 최적화",
    "description": "Google Search Console 등록부터 robots.txt, sitemap 설정, 그리고 개별 포스트 검색 노출까지 블로그 SEO 완벽 가이드",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 블로그를 검색 엔진에 노출시키기 위한 완벽 가이드다. Google Search Console 등록, robots.txt 설정, sitemap 제출, 그리고 개별 포스트의 검색 노출 방법까지 단계별로 설명한다.\n\n---\n\n## 1단계: Google Search Console 등록\n\n### Google Console에 등록하기\n\n1. [Google Search Console](https://search.google.com/search-console/welcome?utm_source=about-page) 접속\n   ![](https://i.imgur.com/2HtKzxz.png)\n\n2. **URL 접두어** 방식으로 블로그 URL 입력\n   ![](https://i.imgur.com/hrUkwuY.png)\n   \n   > [!note]\n   > 도메인 vs URL 접두어 속성의 차이점: [[Google Search Console - 도메인 vs URL 접두어 속성]]\n\n3. **소유권 확인 방법 선택**\n   \n   다음과 같은 화면이 나타나면 여러 확인 방법 중 하나를 선택한다:\n   ![](https://i.imgur.com/TcdYdSl.png)\n   \n   > [!important]\n   > 소유권 확인은 필수 단계다. 아래 방법 중 가장 쉬운 것을 선택하자.\n\n#### 방법 1: HTML 파일 업로드 (추천)\n\n> [!success] 가장 쉬운 방법\n> Quartz 프로젝트에서는 이 방법이 가장 간단하다.\n\n1. Google에서 제공하는 HTML 파일 다운로드\n2. 파일을 `content/` 폴더 루트에 복사\n3. 사이트 빌드 후 배포\n4. Google Search Console에서 \"확인\" 클릭\n\n#### 방법 2: HTML 태그 추가\n\n> [!warning] 테마 수정 필요\n> Quartz 테마 파일을 직접 수정해야 한다.\n\n1. Google Search Console에서 제공하는 메타 태그 복사\n2. `quartz/com"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Obsidian/Quartz, GitHub Pages 사용하여 Obsidian 노트 배포.md",
    "title": "Quartz, GitHub Pages 사용하여 Obsidian 노트 배포",
    "description": "Obsidian 노트를 Quartz를 사용하여 GitHub Pages에 배포하는 방법을 단계별로 설명",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n> [!summary]\n\n> 이 문서는 Obsidian에서 작성한 Markdown 노트를 Quartz를 사용하여 정적 웹사이트로 변환하고 GitHub Pages에 배포하는 방법을 안내한다. 먼저 Quartz를 클론하고 초기화한 후, GitHub 저장소를 설정하여 Quartz 프로젝트를 자신의 저장소와 연결한다. 배포 자동화를 위해 GitHub Actions 설정 파일을 생성하고, GitHub Pages를 활성화한다. 로컬에서 Quartz 사이트를 빌드하여 확인한 후, 변경사항을 GitHub에 동기화한다. 마지막으로, 사용자 정의 도메인을 설정하는 방법도 안내한다. 이 가이드를 통해 Obsidian 노트를 쉽게 공유하고 관리할 수 있다. \n\n## 개요\n\n이 가이드는 **Obsidian**에서 작성한 Markdown 노트를 **Quartz**를 사용하여 정적 웹사이트로 변환하고 **GitHub Pages**에 배포하는 방법을 설명한다.\n\n### 참고자료\n- **YouTube**: [How to publish your notes for free with Quartz](https://www.youtube.com/watch?v=6s6DT1yN4dw&t=1s)\n- **Quartz 공식 문서**: [Quartz 4.0](https://quartz.jzhao.xyz/)\n\n![](https://i.imgur.com/r5O2hdl.png)\n\n---\n\n## 1. Quartz 로컬 폴더 초기화하기\n\nQuartz를 클론하고, 의존성을 설치한 후 프로젝트를 초기화한다.\n\n```bash\ngit clone https://github.com/jackyzha0/quartz.git\ncd quartz\nnpm i\nnpx quartz create\n```\n\n### 초기화 옵션\n\n- 처음부터 시작하는 경우 **Empty Quartz** 선택\n- 링크 해결 방식은 **Treat links as shortest path** 선택\n\n![](https://i.imgur.com/z1HbfPW.png)\n![]("
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Mac/2025-04-18-맥북 초기 세팅.md",
    "title": "맥북 초기 세팅",
    "description": "새 맥북을 받았을 때 필수적으로 설정해야 할 항목들과 개발 환경 구성, 추천 앱을 정리한 글이다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 새 맥북을 설정할 때 필요한 모든 것들을 정리했다. 주요 내용은:\n> - 필수 유틸리티와 개발 도구들\n> - 시스템 설정 최적화 방법\n> - 개발 환경 구성하기\n> - 생산성 향상을 위한 추천 앱\n> - 한 번에 설치하는 방법\n\n새 맥북을 받았을 때 필수적으로 세팅해야 할 항목들과 추천 앱을 정리했다. 효율적인 작업 환경을 구성하는 데 도움이 될 것이다.\n\n## 추천 앱 리스트\n\n새 맥북을 설정할 때 유용한 앱들을 목적별로 분류했다. 필수 앱과 선택적 앱으로 구분하여 필요에 따라 설치하면 된다.\n\n### 1. 필수 유틸리티\n\n기본 맥북 환경을 크게 개선해주는 필수 앱들이다:\n\n- **Homebrew**: macOS용 패키지 관리자 (모든 앱 설치의 기본)\n- **Raycast**: Spotlight 대체 도구 (런처, 클립보드 관리, 윈도우 관리 등)\n- **Rectangle**: 윈도우 크기/위치 관리 도구\n- **Mos**: 마우스 스크롤 방향 및 속도 조절 도구\n\n### 2. 개발 도구\n\n개발 환경 구성을 위한 필수 도구들:\n\n- **iTerm2**: 터미널 에뮬레이터\n- **Oh My Zsh**: 셸 커스터마이징 프레임워크\n- **Visual Studio Code**: 코드 에디터\n- **Git**: 버전 관리 시스템\n\n### 3. 생산성 도구\n\n작업 효율성을 높여주는 도구들:\n\n- **Obsidian**: 마크다운 기반 노트 앱\n- **Slack**: 팀 커뮤니케이션 도구\n- **Discord**: 커뮤니티 및 팀 협업 도구\n\n### 4. 추가 유용한 유틸리티\n\n필요에 따라 선택적으로 설치할 수 있는 도구들:\n\n#### 시스템 모니터링 (둘 중 하나만 선택)\n- **RunCat**: 메뉴바에서 CPU 사용량을 귀여운 애니메이션으로 표시\n- **Stats**: 시스템 리소스 모니터링 도구\n\n#### 파일 관리\n- **AppCleaner**: 앱 삭제 시 관련 파일을 깔끔하게 제거\n- **Keka**: 다양한 압축 포맷"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Docker/2023-11-09-Docker-실습.md",
    "title": "Docker 기초 실습 가이드",
    "description": "Docker 설치부터 기본 명령어, 컨테이너 생성 및 관리까지 실습 가이드",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Docker를 처음 시작하는 사람을 위한 기초 실습 가이드이다. Docker 설치, 기본 명령어(pull, run, ps, stop, rm), 이미지 관리, 컨테이너 생성 및 삭제, 그리고 실전 예제를 통해 Docker의 핵심 개념과 사용법을 익힌다.\n\n## Docker 설치\n\n다운로드 url: https://www.docker.com/products/docker-desktop/\n\n![](https://i.imgur.com/uggryKi.png)\n\n\n## 실습\n\n### ultralytics/ultralytics\n\nQuickStart url: https://docs.ultralytics.com/quickstart/#conda-docker-image\n\n- **Dockerfile:** GPU image recommended for training.\n- **Dockerfile-arm64:** Optimized for ARM64 architecture, allowing deployment on devices like Raspberry Pi and other ARM64-based platforms.\n- **Dockerfile-cpu:** Ubuntu-based CPU-only version suitable for inference and environments without GPUs.\n- **Dockerfile-jetson:** Tailored for NVIDIA Jetson devices, integrating GPU support optimized for these platforms.\n- **Dockerfile-python:** Minimal image with just Python and necessary dependencies, ideal for lightweight applications and development.\n- **Dockerfile-conda:** Based on Miniconda3 with conda installat"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Docker/2023-05-08-Docker와 VM 차이.md",
    "title": "도커(Docker)와 가상환경(Virtual Machine)의 차이",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n\n## Intro\n오라클을 설치시 윈도우 환경에서는 VM을 사용했는데 검색해보니 맥 m1환경에서는 docker를 사용하는것을 알 수 있었다.\n\nDocker은 들어본적은 많지만 잘 몰라서 이참에 정확히 찾아보고 VM과의 차이점을 정리해보았다.\n\n## 도커(Docker)란?\n- 도커는 컨테이너를 이용한 가상화 기술을 제공하는 오픈소스 프로젝트\n- 컨테이너는 코드와 그 코드가 동작하는 데 필요한 환경을 패키징한 것\n- 여러 개의 컨테이너는 동일한 운영체제 커널을 공유하면서, 격리된 공간에서 동작하며 독립적인 프로세스로 실행됨\n- 컨테이너 이미지는 코드, 라이브러리, 의존성 및 실행 환경 등을 담고 있음\n- 도커 이미지는 레지스트리에서 다운로드 받거나, Dockerfile을 이용하여 직접 빌드 가능\n- 이미지로부터 컨테이너를 생성하여 실행할 수 있음\n- 컨테이너는 가상 머신보다 가벼우며 빠르게 생성되며, 호스트 운영체제와 바로 연결되어 있어 가상 머신보다 직관적이고 간단한 설정 가능\n\n## 도커(Docker)와 가상머신(VM)의 차이\n\n\n도커와 VM은 둘 다 가상화 기술로서, 하나의 서버에서 여러 개의 환경을 동시에 운영할 수 있게 한다. 하지만 그 구현 방식과 가상화 수준에서 차이가 있다.\n\n![](https://velog.velcdn.com/images/syshin0116/post/7f406cd5-e3b9-4f2b-b57a-daa23f8572f3/image.png)\n\nVM은 하이퍼바이저라는 소프트웨어를 이용하여 하나의 물리적 서버를 여러 개의 가상 서버로 분할한다. 각각의 가상 서버는 자체적인 운영체제와 애플리케이션을 가지고 있기 때문에, VM에서 실행되는 애플리케이션은 호스트 컴퓨터의 운영체제와 독립적이다. 이로 인해 VM은 더욱 견고하고 안전한 환경을 제공할 수 있는 장점이 있지만, 운영체제와 애플리케이션을 가상화하기 때문에 더 많은 하드웨어 자원을 소모하고 성능 저하의 가능성이 있는 단점이 있다.\n\n반면에 도커는 애플리케이션을 실행하기 위해 필요한 파일과"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Docker/2024-03-27-Docker Compose에서 Flask와 MySQL 연결 문제.md",
    "title": "Docker Compose Flask-MySQL 연결 문제 해결",
    "description": "Docker Compose 환경에서 Flask와 MySQL 컨테이너 간 연결 문제 진단 및 해결",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> WSL 환경의 Docker Compose에서 Flask 컨테이너가 MySQL 컨테이너에 접속하지 못하는 문제를 해결한 과정이다. 네트워크 설정, 호스트 이름 사용, 컨테이너 간 통신, 그리고 MySQL 권한 설정 등 다양한 측면을 점검하여 문제를 해결했다.\n### 문제 상황\n\n- WSL(Windows Subsystem for Linux) 환경에서 Docker Compose를 사용해 Flask(백엔드), MySQL(DB), Nginx(프록시) 컨테이너 설치\n- MySQL에 `test@%` 계정을 만들고 proposalDB 권한 부여\n- Flask에서 pymysql로 MySQL 접속 시도하지만 실패\n\n### 해결 과정\n\n#### 1. 네트워크 확인\n\n- `docker network ls` 명령으로 생성된 네트워크 확인\n- Flask와 MySQL 컨테이너가 동일 네트워크에 연결되어 있는지 확인\n\n#### 2. MySQL 계정 및 권한 확인\n\n- MySQL 컨테이너에 접속: `docker exec -it <mysql_container_name> mysql -u root -p`\n- `SELECT User, Host FROM mysql.user;` 로 `kadap@%` 계정 존재 확인\n- `SHOW GRANTS FOR 'test'@'%';` 로 proposalDB 권한 확인\n\n#### 3. Flask 코드 확인\n\n- MySQL 연결 정보(호스트, 포트, 사용자, 비밀번호) 올바른지 확인\n- 호스트는 MySQL 컨테이너 이름 또는 Docker 내부 IP 사용\n\n#### 4. 방화벽 확인\n\n- WSL 환경에서 방화벽 활성화 시 MySQL 포트(3306) 열려 있는지 확인\n\n#### 5. 로그 확인\n\n- Flask 애플리케이션 및 MySQL 로그 확인하여 추가 정보 얻기\n\n#### 6. MySQL 계정 확인\n\n- `kadap@%` 계정에 proposalDB 전체 권한 부여되어 있음\n- 네트워크 연결 문제일 가능성 높음\n\n#### 7. 네트워크 확"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Git/2024-11-17-방법-Github CI CD - GCP.md",
    "title": "GitHub Actions와 GCP를 활용한 CI/CD 구축 가이드",
    "description": "GitHub Actions를 활용하여 GCP Compute Engine에 Docker 기반 CI/CD 파이프라인 구축하기",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> GitHub Actions를 활용하여 GCP Compute Engine에 자동 배포 파이프라인을 구축하는 상세 가이드이다. Docker Hub를 통한 이미지 관리, GCP 인스턴스 설정, GitHub Secrets 구성, 그리고 자동화된 빌드/배포 워크플로우 전체 과정을 단계별로 설명한다.\n\n## 사전 준비\n\n1 GCP 계정 및 Compute Engine 인스턴스\n2 Docker Hub 계정\n3 GitHub 계정 및 Repository\n\n\n## CI/CD를 위한 큰 순서\n\n### 1. 초기 환경 준비\n\n- 1-1 GCP Compute Engine 인스턴스 생성 및 설정\n    - GCP에서 VM 인스턴스를 생성하고 Docker, Docker Compose 설치\n    - 필요한 포트(예: 80, 443, 8000, 3306) 열기\n    - SSH 키를 설정해 원격 접속 준비\n- 1-2 Docker Hub 계정 및 레포지토리 준비\n    - Docker 이미지를 저장할 Docker Hub 계정과 Private/Public 레포지토리 생성\n\n### 2. 로컬 환경에서 Docker 이미지 빌드\n\n- 애플리케이션 코드와 Dockerfile을 사용해 로컬에서 Docker 이미지를 빌드\n- 로컬에서 이미지가 정상적으로 작동하는지 확인\n\n### 3. GitHub Actions 설정\n\n- GitHub 저장소에 워크플로우 파일 (`github/workflows/deployyml`) 추가\n- GitHub Secrets에 Docker Hub와 GCP의 민감 정보 등록\n\n### 4. GitHub Actions 워크플로우 파일 작성\n\n- .github/workflows/deploy.yml 파일을 생성\n- Push가 성공적으로 수행되면 GCP에서 사용할 준비가 완료\n\n### 5. 테스트\n- GitHub Actions 실행 확인\n- Docker Hub에서 푸시된 이미지 확인\n- GCP 서버에서 컨테이너 확인\n\n\n## 1. 초기 환경 준비\n### 1-1 G"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Git/2023-12-11-Git Blog Themes.md",
    "title": "깃 블로그 테마 모음",
    "description": "깃 블로그 리뉴얼을 위한 마음에 드는 테마 모음",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 깃 블로그 템플릿을 선정하기 전 마음에 드는 Jekyll 테마들을 정리한 문서이다. 다양한 테마의 디자인, 기능, 특징을 비교하여 블로그 리뉴얼에 가장 적합한 테마를 선택하기 위한 참고 자료이다.\n\n## Intro: \n깃 블로그 템플릿 선정하기 전 마음에 드는 템플릿 정리\n\n\n## Templates:\n\n### **[morethan-log](https://github.com/morethanmin/morethan-log)**\n\n![](https://i.imgur.com/0HnpRTl.png)\n### **[hyde](https://github.com/chemistryx/hyde)**\n\n![](https://i.imgur.com/VJ6I7wS.png)\n\n### 확인용\n\nhttps://github.com/topics/developer-portfolio-template\n\n\n# Jekyll 기반의 GitHub Page 생성\nhttps://www.youtube.com/watch?v=2ClW2LdqP30&list=PL7nkwz9MkASx1wxXK51n7KtwQyXgoNL70\n\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Git/2022-09-08-_Github_Github정리.md",
    "title": "[Github]Github 정리",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# [Github]Github 정리\n\n## Git이란?\n*  2005년 리투스 토르발스에 의해 개발\n*  **분산형 버전관리 시스템 - DVCS (Distributed Version Control System)**\n\t*  컴퓨터 파일의 변경사항을 추적, 기록하는 버전 관리 프로그램\n*  _로컬에 한정됨_\n\n## Github란?\n* **Git을 사용하는 프로젝트를 지원하는 웹호스팅 서비스**\n* 클라우드 서버를 사용해 로컬에서 버전관리한 소스코드를 업로드하여 공유 가능\n\n#### 따라서 Git으로 로컬 저장소에서 관리한 작업물을 Github에 업로드 하는 형식으로 주로 사용하게 된다\n\n<br>\n\n## Github의 장점:\n개인:\n\n- 원하는 시점으로 복원 가능\n\n- 작업한 내역을 타임라인 순으로 확인 가능\n\n- 수정한 내용에 대한 문서화 용이\n\n- 브랜치를 생성하고 병합하는것도 간편\n\n\n팀:\n\n- 여러 사람이 하나의 소스를 작업해도 충돌 방지/해결\n\n- 누가 어떤 작업을 진행했는지 확인 가능\n\n<br>\n## 원리:\n\n<p align=\"center\">\n<img width=\"900\" alt=\"Screen Shot 2022-09-09 at 12 50 10 AM\" src=\"https://t1.daumcdn.net/cfile/tistory/993CCF4B5F17C75211\n\">\n</p>\n\n출처: [https://ux.stories.pe.kr/182 [UX 공작소:티스토리]](https://ux.stories.pe.kr/182)\n\n복잡함으로 대충 보고 밑에글을 읽은 후에 다시 보며 이해하는걸 추천\n\n<br>\n\n## 명령어 정리:\n\n| code                                \t     | description                                                                                                    \t| tips                            "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Git/2024-11-09-정리-Github CI CD - GCP.md",
    "title": "GitHub CI/CD와 GCP 통합 정리",
    "description": "GitHub Actions와 GCP를 연동한 CI/CD 파이프라인 개념 및 구조 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> GitHub Actions와 GCP를 연동하여 CI/CD 파이프라인을 구축하는 개념과 구조를 정리한 문서이다. 지속적 통합(CI)과 지속적 배포(CD)의 원리, GitHub Actions 워크플로우 구성, GCP 서비스 활용, 그리고 전체 시스템 아키텍처를 개념적으로 이해한다.\n\n## Intro:\n\nGCP에 개인 서버를 만들고, 관리하려는데, CI/CD를 만들어놔야 시간 절약을 할 수 있을것 같아 공부해보려 한다.\n\n## CI/CD란?\n\n- **CI/CD**는 Continuous Integration과 Continuous Deployment의 약자로, 소프트웨어 개발 과정에서 코드 변경 사항을 자동으로 빌드, 테스트, 배포하는 일련의 프로세스를 의미\n- 코드 수정 후 수동으로 배포하는 번거로움 없이 자동화된 시스템으로 빠르고 안정적으로 업데이트를 진행할 수 있다\n\n### Continuous Integration (CI)\n\n- **지속적 통합**: 여러 개발자가 작업한 코드 변경 사항을 정기적으로 중앙 리포지토리에 병합하고, 이 병합된 코드를 자동으로 빌드하고 테스트하는 과정\n- 코드 충돌을 최소화하고, 문제를 조기에 발견하여 품질을 유지하는 데 도움이 된다\n\n### Continuous Deployment (CD)\n\n- **지속적 배포**: CI 과정을 거친 코드가 자동으로 프로덕션 환경에 배포되는 것을 의미\n- 새로운 기능이나 수정 사항을 사용자에게 신속하게 제공\n- 배포 과정에서 발생할 수 있는 인적 오류를 줄일 수 있다\n\n### CI/CD의 장점\n\n- **자동화된 프로세스**: 빌드, 테스트, 배포 과정을 자동화하여 효율성 향상\n- **빠른 피드백 루프**: 코드 변경에 대한 즉각적인 피드백으로 빠른 문제 해결\n- **높은 코드 품질**: 지속적인 테스트와 검증으로 안정적인 소프트웨어 제공\n- **협업 개선**: 여러 개발자가 동시에 작업해도 통합 과정이 원활하여 팀 생산성이 향상\n\n### GCP에서의 CI/CD 적용\n\n- G"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Tools/Git/2024-01-15-Github Action google-protobuf 오류.md",
    "title": "GitHub Actions google-protobuf 오류 해결",
    "description": "GitHub Actions에서 발생한 google-protobuf 의존성 오류 진단 및 해결 방법",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> GitHub Actions 워크플로우에서 발생한 google-protobuf 의존성 오류를 진단하고 해결한 과정이다. 오류 메시지 분석, 원인 파악(패키지 버전 충돌), 그리고 requirements.txt 수정을 통한 해결 방법을 포함한다.\n\n## 오류:\n\n\nGithub Actions에 다음과 같은 오류가 났다:\n\n![](https://i.imgur.com/K6npfCb.png)\n\n\n```shell\nAn error occurred while installing google-protobuf (3.25.2), and Bundler cannot\ncontinue.\n\nIn Gemfile:\n  jekyll-theme-chirpy was resolved to 5.6.1, which depends on\n    jekyll-archives was resolved to 2.2.1, which depends on\n      jekyll was resolved to 4.3.3, which depends on\n        jekyll-sass-converter was resolved to 3.0.0, which depends on\n          sass-embedded was resolved to 1.69.7, which depends on\n            google-protobuf\nError: The process '/opt/hostedtoolcache/Ruby/3.3.0/x64/bin/bundle' failed with exit code 5\n```\n\n\n\n## 해결 방법:\n\nruby 버전과 호환이 안되서 발생하는 오류다.\n\n.github/workflows/pages-deploy.yml 에서\n\nruby version을 3 에서 3.2로 변경해주자 해결되었다\n\n\n```yml\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: act"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-07-10-마키나락스가 AI를 활용해 최적 제어 로직을 도출하는 방법.md",
    "title": "마키나락스의 AI 기반 최적 제어 로직 도출 방법",
    "description": "마키나락스의 AI를 활용한 현장 최적 제어 로직 도출 방법론 세미나 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 마키나락스의 AI 기반 최적 제어 로직 도출 방법을 다룬 세미나 내용이다. 현장 최적 제어의 어려움(복잡한 시스템, 실시간 변수, 불확실성), AI를 활용한 해결 방안(강화학습, 시뮬레이션 기반 학습, 디지털 트윈), 실제 산업 현장 적용 사례, 그리고 AI 제어 시스템의 안전성 검증 방법을 포함한다.\n\n유튜브 URL: [https://www.youtube.com/watch?v=iD4hy6UXTYA](https://www.youtube.com/watch?v=iD4hy6UXTYA)\n\n### 현장 최적 제어의 어려움\n\n- **산업의 복잡성**\n    - 장비 내외부 환경 조건과 조건 및 결과의 복잡한 인과 관계\n- **변화와 편차**\n    - 변동하는 제품, 공정, 레시피와 장비 유지보수로 인한 조건 변화, 작업 숙련도에 따른 품질 차이\n- **사람의 한계**\n    - 인간의 능력으로는 복잡한 조건과 변화에 대한 최적의 제어를 항상 보장하기 어려움\n\n![https://i.imgur.com/5Vt1skZ.png](https://i.imgur.com/5Vt1skZ.png)\n\n### 문제 해결을 위한 두 가지 기술\n\n- **Digital Twin**\n    - 주어진 조건과 상태에서 특정 제어가 이루어졌을 때 다음 상태 변화를 예측\n    - 머신러닝 기반\n- **Explorer**\n    - Digital Twin과 연계한 최적화 알고리즘\n\n![https://i.imgur.com/RPt71Ou.png](https://i.imgur.com/RPt71Ou.png)\n\n### 마키나락스의 제어 최적화 방법론\n\n1. **문제 정의**\n    - 현황 파악\n    - 현재 제어의 문제 및 원인 파악\n    - 제어 목표와 제약사항 합의\n2. **시뮬레이션 환경 구축**\n    - 변수 유형 분류\n    - 시스템과 데이터 특성을 고려한 모델 구조 설계\n    - 시뮬레이션을 위한 모델 학습 전략 수립\n3. **최적 제어 로직 도출**\n    -"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-05-27-백엔드 개발자 학습 가이드 웨비나.md",
    "title": "백엔드 개발자 학습 로드맵 웨비나",
    "description": "백엔드 개발자가 되기 위한 종합 학습 가이드 - 언어 선택부터 포트폴리오, 면접 준비까지",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 백엔드 개발자 커리어를 위한 종합 학습 가이드 웨비나 내용이다. 프로그래밍 언어 선택(Java, Python, JavaScript/Node.js, Go), 프레임워크(Spring Boot, Django, Express.js), 데이터베이스(MySQL, PostgreSQL, MongoDB, Redis), API 개발(REST, GraphQL), 배포(Docker, Kubernetes, CI/CD), 포트폴리오 작성 전략, 면접 준비, 그리고 지속적인 학습 방법을 포괄적으로 다룬다.\n\n### 개요\n\n이 가이드는 백엔드 개발자가 되기 위한 다양한 정보를 제공합니다. 프로그래밍 언어 선택부터 프레임워크, 데이터베이스, API 개발, 배포, 포트폴리오 작성, 면접 준비, 지속적인 학습까지 포괄적으로 다룹니다. 자신의 흥미와 맞는 도구를 선택하고, 이를 통해 성장하는 것이 중요합니다.\n\n### 프로그래밍 언어\n\n- **Java**: 안정성과 성능이 뛰어나며, 대규모 프로젝트에 적합하지만 복잡한 문법과 긴 개발 시간이 단점\n- **Python**: 간결한 문법과 빠른 개발 속도가 장점. 데이터 분석, 웹 개발, AI 등 다양한 분야에서 사용되나, 대규모 프로젝트 유지보수가 어려울 수 있음\n- **JavaScript (Node.js)**: 프론트엔드와 백엔드에서 모두 사용 가능하며, 빠른 개발 속도를 제공. 다만, 동적 타이핑으로 인한 런타임 에러 가능성이 있음\n\n### 데이터베이스\n\n- **관계형 데이터베이스 (RDBMS)**: MySQL, PostgreSQL\n- **NoSQL 데이터베이스**: MongoDB, Redis\n\n### 프레임워크 및 라이브러리\n\n- **Java**: Spring, Spring Boot\n- **Python**: Django, FastAPI\n- **Node.js**: Express.js, Next.js\n\n### API 개발 및 문서화\n\n- **RESTful API**와 **GraphQL**을 통해 API 설계 및 개발"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-01-22-데이스쿨 랭커 특강 정리.md",
    "title": "데이콘 대회 전략 - 데이스쿨 랭커 특강 정리",
    "description": "데이콘 대회 상위 랭커의 대회 접근 전략 및 노하우 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 데이콘 대회 상위 랭커가 전수하는 대회 전략과 노하우를 정리한 특강 노트이다. 대회 주제 파악 방법(목적 분석, SOTA 모델 찾기, 코드 존재 여부 확인), 데이터셋 분석 체크리스트(데이터 포맷, 분포, 클래스 불균형 해소), 모델 선택 및 튜닝 전략(Baseline 설정, 하이퍼파라미터 튜닝, Ensemble), 그리고 실전 팁(Papers with Code 활용, Huggingface 모델 활용)을 포함한다.\n### 대회 주제 파악\n\n대회 목적에 맞는 모델을 찾기 위한 체크 리스트\n1. 대회의 목적\n2. 대회 목적에 맞는 tast는 무엇인가?\n\t- 모르는 task라면 review 논문을 읽으며 이해\n3. 해당 task의 SOTA모델은 무엇인가?\n4. 해당 SOTA 모델의 코드가 존재하는가?\n\t- 없으면 다른 모델은 코드가 있는지 확인\n\t- 있으면 코드에서 모델을 가져와서 적용할 수 있는지 확인\n\t- 해당 모델이 Huggingface에 존재하는지 확인\n\n> paperswith code에서 SOTA모델을 인용한 논문을 찾으면 더 좋은 성능의 초신 모델 논문을 더러 발견할 수 있다\n\n### 데이터셋 분석\n데이터 분석을 통한 모델 적용 가능성 확인 및 특징 확인 체크리스트\n1. 대회에서 제공한 데이터셋은 어떠한 format으로 구성되어 있는가?\n\t- 찾은 모델을 그래도 사용 간으한지 혹은 output layer에 변경이 필요한지 확인 \n2. 데이터들의 분포가 어떻게 되어 있는가?\n\t- Target data의 분포를 확인하여 다양한 클래스 불균형 해소 방법 적용 가능\n3. EDA를 통해 어떠한 특징을 도출해냏 수 있는가?\n\t- EDA를 통해 결측치 등 확인하여 데이터 전처리\n\n> 주로 tuning하는 부분은 output layer\n\n### 다양한 학습 기법 적용\n\n성능 고도화를 위한 전략\n1. \\[대회주제 파악]을 통해 주사한 모델 적용\n2. 성능을 올리기 위한 다양한 augmentation, feature engineering방법 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-03-02-LangChain for LLM Application Development.md",
    "title": "LangChain for LLM Application Development 강의 노트",
    "description": "LangChain을 활용한 LLM 애플리케이션 개발 강의 전체 내용 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> DeepLearning.AI의 LangChain 강의 전체 내용을 정리한 노트이다. LangChain의 핵심 컴포넌트(Models, Prompts, Indexes, Chains, Agents), 프롬프트 템플릿 활용법, 출력 파서, 메모리 관리, RAG 구현, Document Loaders와 Text Splitters, Vector Stores와 Embeddings, Question Answering, Evaluation, Agents와 Tools 활용까지 LLM 애플리케이션 개발의 전 과정을 포괄한다.\n\n\n[https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)\n\n## Components\n\nModels\n- LLMs: 20+ integrations\n- Chat Models\n- Text Embedding Models: 10+ integrations\n\nPrompts\n- Prompt Templates\n- Output Parsers: 5+ implementations\n- Retry/fixing logic\n- Example Selectors: 5+ implementations\n\nIndexes\n- Document Loaders: 50+ implementations\n- Text Splitters: 10+ implementations\n- Vector stores: 10+ integrations\n- Retrievers: 5+ integrations/implementations\n\nChains\n- Prompt + LLM + Output parsing\n- Can be used as building blocks for longer chains\n- More application specific chains:"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-07-17-AI시대, 기록을 잘하는 방법.md",
    "title": "AI시대, 기록을 잘하는 방법",
    "description": "AI 시대에 효과적으로 기록하고 지식을 관리하는 방법론 세미나 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> AI 시대에 효과적인 기록 방법을 다룬 세미나 내용이다. 디지털 시대의 노트 테이킹 전략, AI 도구를 활용한 지식 관리, 정보 구조화 방법, 제텔카스텐과 같은 지식 연결 시스템, 그리고 실무에서의 효율적인 문서화 팁을 포함한다.\n\n## 인트로, 사전 인터뷰\nCMDS-Class: https://slashpage.com/cmds-class/dk58wg2ej5dw6mnqevxz\n박준님 데모 사이트: [https://llm-project-joon.site/](https://llm-project-joon.site/)\n### 옵시디안의 장점\n\n- **Second Brain**: 생각과 방식을 저장하고 다시 사용할 수 있음.\n- **노션에 비한 옵시디안**:\n    - 마크다운 에디터의 최강자\n    - 로컬 기반이라 느려지지 않음\n    - 가능성이 무한하지만 쉽지는 않음\n\n## 사람과 조직은 무엇을 남기는가?\n\n- 발표자: 요한님, CMDSpace 대표\n\n![](https://i.imgur.com/q5Hc23e.png)\n\n![](https://i.imgur.com/5XuL7Lq.png)\n\n### Knowledge Worker\n\n- 기록이 되어 있어야 지식으로 활용할 수 있음\n\n![](https://i.imgur.com/C4m0qgX.png) ![](https://i.imgur.com/6hxOC88.png)\n\n> 내 기록을 검색해주는 에이전트를 만들면 재미있을 것 같다\n\n![](https://i.imgur.com/GMgCJlS.png)\n\nMonkey, Banana, Panda를 분류하자면?\n\n- 동물, 음식으로 묶을 수 있지만 방법은 여러 가지\n- 같은 사물이라도 비교 대상에 따라 맥락이 달라짐\n\n![](https://i.imgur.com/AELUIDi.png)\n\n옵시디안의 기능 중 하나: Metadata\n\n- 폴더로 정리하는 개념은 한계가 있음\n    - 어떤 폴더로 어떻게 분리할지 정하기 어려움\n\n![](https://i.imgur.c"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2025-01-26-Inflearn-UIUX.md",
    "title": "Inflearn - UX/UI 시작하기: UI 디자인",
    "description": "Inflearn UX/UI 디자인 강의 정리 - UI 디자인 기초부터 실습까지",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Inflearn의 UX/UI 시작하기 강의에서 UI 디자인 부분을 정리한 노트이다. UI 디자인의 기본 원칙(일관성, 계층구조, 피드백), 디자인 도구 사용법, 컬러/타이포그래피/레이아웃 설계, 반응형 디자인 구현, 그리고 실제 인터페이스 디자인 프로젝트 실습을 포함한다.\n\n## 어떤것들을 배워야 할까요?\n1. UI/UX 배경지식\n2. 디자인 프로세스\n3. 사용자 공감\n4. 개발환경에 대한 이해\n\n\n\n## 커리큘럼\n\n1. UI/UX 디자인 시작하기\n2. UI/UX 디자인 기초쌓기\n3. UI/UX 디자인 실무\n4. UI/UX 디자인 맛보기\n5. UI/UX 디자인 TIP & 포트폴리오\n\n\n## UI/UX 디자인 \n\n### 사례: Airbnb UI/UX 개선\n\n#### 설문 조사\n\n\n1. airbnb 사용 이유 및 불편한 기능\n   - airbnb를 사용하신 이유는 무엇인가요?\n   - 속소를 예약하시면서 경험했던 불편함은 무엇인가요?\n2. Field Research\n   - 일반사용자와 헤비 유저 선정하여 각각 1시간 가량 직접 만나서 리서치 진행\n3. Rearch 시나리오\n   - 숙소 검색 단계 → 속소 안내 단계 → 지도 및 필터 → 보관함 및 리뷰 → 번역기로 나누어 관찰조사 & in-depth 인터뷰 병행\n4. Resaech 결과 → Key Findins\n   - 이슈 - Key Findings로 정리\n   - ex) 이슈: 메인 화면의 배치 및 구성 적절성, Key Findings: 예약 전-후 과정에 필요에 따라 두 그룹으로 분리해서 사용하는 경향을 보임\n5. To-Be\n6. Flow-Chart\n   - 화면별 기능들 정의\n7. Lo-Fi Protype\n   - Sketch, Powerpoint, 등등\n   - \n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-04-05-원디트 프리온보딩 백엔드-Docker-1일차.md",
    "title": "원디트 프리온보딩 백엔드 - Docker 1일차",
    "description": "원티드 프리온보딩 백엔드 과정 Docker 실습 1일차 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 원티드 프리온보딩 백엔드 과정의 Docker 교육 1일차 내용을 정리한 노트이다. Docker의 기본 개념과 아키텍처, 이미지와 컨테이너의 차이, Dockerfile 작성법, Docker Compose를 활용한 멀티 컨테이너 관리, 그리고 실제 백엔드 애플리케이션 컨테이너화 실습을 포함한다.\n\n- ## 전체 과정 설명\n    \n    - 과정 설계 - 이론 + 실습시연 + 실제 면접 질문 + QnA(대규모 강의-질문 대응)\n        - 4회동안 compact 하게 큰 그림을 그려봅시다 - 세부 사항 학습 자습 병행 (mac os / windows)\n        - 20% 핵심\n    - 포트폴리오에 어떻게 적용되는지 - 서비스 운영환경에 대한 경험\n        - 소프트웨어 개발에서 빠진 경험\n            - ![SDLC_BWC.png](https://bigwater.consulting/wp-content/uploads/2019/04/SDLC_BWC.png)\n- ### 사전 과제 이유\n    \n    - [https://github.com/siyoungoh/docker-ci-cd/blob/main/README.md](https://github.com/siyoungoh/docker-ci-cd/blob/main/README.md)\n    - 1. [https://docs.docker.com/guides/walkthroughs/run-a-container/](https://docs.docker.com/guides/walkthroughs/run-a-container/)\n        \n        - Docker 공식문서 읽기 + 환경설정 완료하기\n    - 2. Github 가입 - Github action\n        \n        - GitHub Actions은 GitHub에서 제공하는 CI/CD(지속적 통합 및 지속적 배포) 서비스이다. 이를 사용하면 소프트웨어 개발 워크플로우를 자동화할 수 있다. 예를 들"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-04-13-GenAI Hack for Public Good in Korea.md",
    "title": "GenAI Hack for Public Good in Korea 해커톤",
    "description": "생성형 AI로 공공부문 업무혁신을 실현하는 해커톤 참가 기록",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 생성형 AI 기술로 공공부문의 업무혁신을 실현할 수 있는 아이디어를 창출하고 솔루션을 개발하는 해커톤 행사 참가 기록이다. 공공 서비스 개선을 위한 GenAI 활용 방안, 팀 구성 및 프로젝트 기획, 기술 스택 선정, 그리고 실제 솔루션 개발 과정을 포함한다.\n\n## Hack for Public Good in Korea 해커톤\n\n- 생성형 AI 기술로 공공부문 업무혁신을 실현 할 수 있는 아이디어 창출 및 솔루션을 개발하는 해커톤 행사\n\n\n### 행사 일정\n\n![](https://i.imgur.com/LKOMPFU.jpeg)\n\n### 주제\n- 공공 서비스의 혁신과 국민의 공공 서비스 이용 향상에 기여하는 아이디어 개발에 관한 네 가지 주제\n\n![](https://i.imgur.com/BKmzs6h.png)\n\n\n\n## 후기\n\n  \n갑작스럽게 하루 전에 친구와 참가하게 된 첫 해커톤이었고, 평소 기대했던 해커톤이 아니라 실망이 크지 않을까 걱정했다. 걱정만큼 좋은 결과를 내진 못했지만, 오히려 생각외로 좋은 자극을 얻은것 같다.\n\n**Day 1**: 오티와 AOAI 활용 교육을 진행했으며, Streamlit을 이용해 기본 챗봇을 구현하는 시간도 있었다. 이 내용은 유튜브 영상에서 쉽게 찾아볼 수 있는 수준이었다. AI 분야에 종사하는 나로서는 다소 기초적이었지만, AI에 익숙하지 않은 참가자들에게는 필요한 교육이었다고 인정한다. 이후 Azure 클라우드를 활용하는 방법에 대한 교육은 나에게도 유익했다. 저녁 식사 전까지 교육을 마치고 팀빌딩을 하라는 안내를 받았지만, 쉬는 시간마다 팀빌딩 경쟁률이 높았다. 저녁 시간 전에 팀이 없는 참가자들은 집으로 가거나 두 명씩 짝을 지어 남아있는 경우가 많았다. 대부분 백엔드나 AI 개발자여서 프론트 엔드 개발자나 기획자가 부족한 상황이었다.\n\n그러다 친구와 함께 프론트 엔드 개발자를 찾고 있을 때, 마침 남아있는 백엔드와 프론트 개발자 두 분을 발견하고 얼른 가서 팀을 이루었다. 친구와 나 그"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-02-24-LLM 강의 정리.md",
    "title": "LLM 개발 및 학습 강의 정리",
    "description": "LLM(대규모 언어 모델)의 사전 학습, 파인튜닝, 도메인 적응 전략 강의 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> LLM 개발 및 학습 전략에 대한 강의 내용을 정리한 노트이다. 사전 학습(Pretrain)과 파인튜닝(Fine-tuning)의 차이, 추가 사전 학습이 필요한 경우(도메인 특화, 새로운 언어), 효율적인 파인튜닝 기법(LoRA, QLoRA), Transfer Learning 전략, 그리고 실무에서 LLM을 적용할 때의 고려사항을 다룬다.\n\n![](https://i.imgur.com/OwheGkg.png)\n\n\n![](https://i.imgur.com/cpXoCYf.png)\n\n\n![](https://i.imgur.com/5QCtzpx.png)\n\n![](https://i.imgur.com/2LARpuo.png)\n\n![](https://i.imgur.com/o3tpqgX.png)\n\n\n## Pretrian을 더 시켜야 하는 경우\n\n![](https://i.imgur.com/QSUEIFh.png)\n\n![](https://i.imgur.com/0EkqSvi.png)\n\n+ 한국어 추가 학습\n\n\n![](https://i.imgur.com/n7Cz5UG.png)\n\n![](https://i.imgur.com/jaWHNiN.png)\n\n![](https://i.imgur.com/oEuWV4a.png)\n\n\n### RLHF (Reinforcement Learning with Human Feedback)\n![](https://i.imgur.com/Bvx5WOO.png)\n\n리워드 모델을 통해 평가\n- ex) 이 답변이 다른 답변보다 좋은 답변일 확률이 0.2\n\n#### 두가지 문제접\n- Reward Model 학습이 어려움\n- 강화학습을 이용했을대 생기는 불안정성\n\n\n### DPO(Direct Preference Optimization)\n![](https://i.imgur.com/9CDIYGK.png)\n\n#### RLHF에서 보완된 방식\n- Reward Model을 없앰\n- 강화학습 불안전성 완화\n\n### 프롬프트 엔지니어링\n\n![](https://i.im"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-05-30-LlamaIndex 온라인 세미나.md",
    "title": "LlamaIndex 활용 가이드 온라인 세미나",
    "description": "LlamaIndex의 장점과 실무 활용 방법을 다룬 온라인 세미나 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> POSCO E&C 조우철 연구원의 LlamaIndex 활용 세미나 내용을 정리한 노트이다. LlamaIndex의 주요 장점(쉽고 간결한 코드, 빠른 프로토타이핑), LangChain과의 비교, Document Loaders와 Readers 활용, Indexing 전략, Query Engine 구성, 그리고 실무에서의 활용 사례와 팁을 포함한다.\n\n# Why I use LlamaIndex\n- 조우철님 발표 \n- Applied AI Researcer @POSCO E&C\n\n## LlamaIndex 장점\n\n- 코드가 쉽고 간결하다\n\n\n![](https://i.imgur.com/AQVmP1u.png)\n\n![](https://i.imgur.com/g6mdctg.png)\n\n- 기본 RAG는 5 line code로 구현 가능할 정도로 간결하다\n- Well Documented\n- Well Maintained\n- 빠른 업데이트\n\n![](https://i.imgur.com/UZkzVgj.png)\n\n# LLM-as-a-Judge: A Futuristic Way of Evaluation Foundational Models\n- Jamin (Jay) Shin\n\n## Background: Standard Methods of Text Evaluation\n\n### Lexical-based Metrics\n- reference의 단어가 얼마나 겹쳤는가\n- semantic information을 고려하지 않음\n- ex) Accuracy, ROUGE, BLUE, CiDER, METEOR\n\n![](https://i.imgur.com/JIpK8QK.png)\n\n\n### Embedding-based Metrics\n- Cosine Similarity 비교\n- Expressiveness Bottlenect\n- ex) BERT-score, BART-score\n\n![](https://i.imgur.com/Zd4g1Zm.png)\n\n## Motivation: Why Evaluation "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-12-04-프롬프트엔지니어링2탄.md",
    "title": "TeddyNote - 실무를 위한 프롬프트 엔지니어링 2탄",
    "description": "실무에서 활용하는 고급 프롬프트 엔지니어링 기법 세미나 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> TeddyNote의 실무 중심 프롬프트 엔지니어링 2탄 세미나 내용이다. LLM as a Judge 패턴, Few-shot Learning 활용법, Chain-of-Thought 프롬프팅, 시스템 프롬프트 최적화, 에러 핸들링 전략, 그리고 실무 프로젝트에서의 프롬프트 설계 사례를 포함한다.\n\n## LLM as a Judge\n\n![](https://i.imgur.com/kgqdrXv.png)\n\nAI의 Output을 LLM이 평가하는 방식\n\n### Pairwise comparison\n- A가 좋니 B가 좋니\n### Single answer grading\n- 인간의 만족도가 기준이 됨\n### Reference-guided grading\n\n\n![](https://i.imgur.com/3z3IFqf.png)\n\n![](https://i.imgur.com/fNZKW06.png)\n\n#### Chatbot Arena\n\n![](https://i.imgur.com/stNHtlF.png)\n\n\n![](https://i.imgur.com/St0JFR3.png)\n\n\n>한국어로 물어보면 한국어를 잘하는 모델이 승리를 함 → 한국어 잘하는 모델 판단 가능\n\n\n\n\n\n![](https://i.imgur.com/QFpDnuj.png)\n\n## Discussion\n\n![](https://i.imgur.com/0jf7BGD.png)\n\n- LLM은 연속적인 범위 평가에 약한 모습을 보임 → 분류 평가 사용\n\n\n## Research\n\n### Methodology\n\n![](https://i.imgur.com/W8Fg7U9.png)\n\n- 정성적 평가와 정량적 평가를 합침\n\n| 항목             | 일반 LLM 평가 방법                           | 현재 사용자 중심 연구                              |\n|------------------|---------------------------------------------|--"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-06-03-김동규 연구원님.md",
    "title": "AUTO-RAG 김동규 연구원 세미나",
    "description": "AUTO-RAG 시스템에 대한 김동규 연구원 세미나 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 김동규 연구원의 AUTO-RAG(자동화된 RAG 시스템) 세미나 내용을 정리한 노트이다. RAG 파이프라인 자동 구성, 최적 파라미터 자동 탐색, 성능 평가 및 튜닝 자동화, 실제 적용 사례와 성능 비교를 포함한다.\n\n\n### 모든 문서에 완벽하게 적용되는 RAG는 없다\n\n![](https://i.imgur.com/J7oVndX.png)\n\n\n## 개선 방법\n\n- RAG 성능 개선을 위한 방법론 너무 많음\n- Langchain이나 LlamaIndex에 구현되어 있는것들은 빙산의 일각, 실제론 더 많은 모듈과 방법론 존재\n\n![](https://i.imgur.com/wFBc2ru.png)\n\n- 모든 데이터에 공통적으로 작동하는 방법은 없다 → 실험 필수 → 실험할 방법이 너무 많고 체계적이지 않다 → AUTO RAG 사용 권장\n\n## AutoRAG 개념\n- 많은 실험들을 효율적으로 자동화\n- YAML파일 사용하여 RAG모듈 자동 테스트\n- pdf등 raw 평가용 문서 생성 가능\n- 자동으로 찾은 RAG 파이프라인을 api 서버, streamlit으로 사용 가능\n\n![](https://i.imgur.com/U8P1qRY.png)\n\n\n### RAG 평가 방법\n- 질문 → 단락 → 생성(LLM)\n\n단락:\n- Retrieveal 평가\n- Retrieve된 단락 A, B, C가 retrieval gt A와 일치하는가?\n\n생성:\n- 생성한 답변 평가\n- 생성한 답변 A가 generation gt B(모법 답안)와 유사한가?\n\n> gt를 어떻게 만드는가?\n> - GPT, RAGAS 사용\n## RAG 평가 데이터 만들기\n\n### 좋은 평가 데이터 만들기\n좋은 방법 순서대로:\n1. 실제 유저 데이터 활용\n2. 도메인 전문가와 함께 생성\n3. human-in-the-loop 전략(LLM+사람)\n4. llm만 사용\n\n![](https://i.imgur.com/Q7HnnWy.png)\n\n> 평가 데이터셋을 만들때엔 가장 똑똑한 LLM을 사용해야 한다\n\n> "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-03-05-RAG 우리가 절대 쉽게 결과물을 얻을 수 없는 이유 노트.md",
    "title": "RAG 구현의 어려움과 해결 방법 - TeddyNote 세미나",
    "description": "RAG 시스템 구현 시 마주하는 실전 문제와 해결 방안 세미나 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> TeddyLee의 RAG 구현 난제와 해결책을 다룬 세미나 내용이다. RAG가 실무에서 어려운 이유(문서 품질, 청크 크기, 검색 정확도, 환각 문제), 최적화 전략(하이브리드 검색, Reranking, 프롬프트 튜닝), 평가 방법론, 그리고 langchain-kr 라이브러리를 활용한 실전 구현 사례를 포함한다.\n\nTeddyLee님의 langchain-kr 깃허브: [https://github.com/teddylee777/langchain-kr](https://github.com/teddylee777/langchain-kr)\n\n### 목차\n\n1. 지난 1년간 (2023) 6개 기업의 10여개 프로젝트에서 얻은 RAG 경험담\n2. 마주한 도전들\n3. 실패 사례, 극복 시도\n4. Vector Store, Prompt Engineering, LLM Fine-tuninggi\n\n### 용어정리\n\nRAG: Retrieval Augmented Generation\n\n### RAG 프로세스\n\n자체 정의한 RAG 프로세스 과정\n\n### 1. 전처리 작업\n\n1. Load Document: 처리할 문서를 시스템에 불러옵\n2. Chunk(Split): 문서를 더 작고 관리하기 쉬운 조각으로 나눈다(llm은 한번에 읽을 수 있는 단어는 few thousands 이기 때문)\n3. Embedding: 이 조각들을 내용의 본질을 포착하는 숫자 표현으로 변환\n4. Store: 임베딩들을 데이터베이스에 저장\n\n![https://i.imgur.com/yUgGrWZ.png](https://i.imgur.com/yUgGrWZ.png)\n\n### 2. 서비스 단계에서 이뤄지는 작업\n\n- llm 서비스 구동중인 상태에서 이뤄지는 작업\n\n1. 유저 질문을 받아 Embedding 처리\n2. Retrieve(발췌)\n    - 실시간으로 이루어짐\n3. 프롬프트 엔지니어링후 LLM에 전달\n4. output\n\n![https://i.imgur.com/6nPNirw.png](https:/"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/데블챌 데이터 블로그 챌린지.md",
    "title": "데블챌 데이터 블로그 챌린지",
    "description": "데블챌 데이터 블로그 챌린지에 참여하여 데이터 관련 블로그 글을 작성하는 기록.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 데블챌은 14일간 진행되는 데이터/AI/커리어 분야 블로그 챌린지. 매일 선택한 주제에 관한 글을 작성하고 SNS나 블로그에 공유하는 활동. 데이터 분석, AI 기술, 커리어 성장에 관심 있는 사람들이 함께 글쓰기 습관을 기르고 전문성을 키우는 기회임.\n\n# 데블챌 데이터 블로그 챌린지\n\n## 데블챌이란?\n\n14일간 진행되는 데이터/AI/커리어 분야 블로그 챌린지. 참가자는 이 기간 동안 선택한 주제에 대해 SNS나 블로그에 생각과 경험을 공유하는 활동임.\n\n![](https://i.imgur.com/1qyW1Jb.png)\n\n\n## 챌린지 일정\n\n- 오리엔테이션: 2025년 6월 1일\n- 챌린지 기간: 2025년 6월 2일 ~ 6월 15일 (14일간)\n\n## 참여 방법\n\n1. 작성한 글을 매일 SNS/Blog에 게시.\n2. 개인 프로필에서 글을 먼저 작성한 후,\n3. SNS/Blog 중 하나를 선택하여 맞춤형 글을 매일 게시.\n4. 참고 가능한 블로그/채널 가이드 제공받음. (글쓰기 도움 Resource 제공)\n   - 참고글 없이 자신 생각 작성 가능\n   - 참고글에 대한 요약+인사이트 작성 가능\n5. AI 활용한 전문적 글쓰기도 새로운 목표로 설정 가능.\n\n## 챌린지 규칙\n\n오픈 카톡방에서 당일 자정 12시까지 블로그/포스트 링크를 제출\n\n\n## 주요 주제\n\n데블챌의 세 가지 주요 주제:\n\n1. DATA\n\t- 데이터 분석 방법론\n\t- 프로젝트 분석 사례\n\t- IT 실무 적용 방안\n\t- 통계 / 머신러닝 기법\n2. AI\n\t- AI 활용법\n\t- 프롬프트 엔지니어링\n\t- 생산성 향상 방법\n\t- 최신 논문 및 연구 동향\n3. CAREER\n\t- 취업 준비 전략\n\t- 성장 방법\n\t- 코딩/프로그래밍 공부법\n\t- 면접 꿀팁\n\t- 네트워킹/커뮤니케이션\n\n\n\n## 챌린지 진행 상황\n\n1. [[바이브코딩과 커서(Cursor)|Day1 - 바이브코딩과 커서(Cursor)]] - 2025.06.02\n2. [[LangFlow|Day2 - Lang"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2022-12-07-_AWS_ SAA-C03 notes.md",
    "title": "Architect Associate Certification SAA-C03 Notes",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n# Architect Associate Certification SAA-C03 Notes\n\nAWS: Amazon Web Services\n\nServices covered in this course:\n\n* EC2\n* CVR\n* ECS\n* Elastic Beanstalk\n* Lambda\n* Auto Scaling\n* IAM\n* KMS\n* S3\n* SES\n* RDS\n* Aurora\n* DymamoDB\n* ElastiCache\n* SQS\n* SNS\n* Step Functions\n* CloudWatch\n* CloudFormation\n* CloudTrail\n* API Gateway\n* Elastic Load Balancing\n* CloudFront\n* Kinesis\n* Route 53\n\n### How to choose an AWS Region?\n\nQuestion: If you need to launch a new application, where should you do it?\n\n1. Compliance with data governmance and legal requirements:\n\t* ex) if you want your data to leave a specific region\n2. Proximity to customers(close to target users):\n\t* reduced latency\n3. Available Services witin a region:\n\t* new services and new feature aren't available in very Region\n4. Pricing: \n\t* pricing varies region to region and is transparent in the sevice pricing page \n\n### AWS Availability Zones\n\n* Each region has multiple ZA(availability zones) example:\n\t* ap-southeast-2a\n\t* ap-southeast-2b"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2025-01-25-월간 옵시디안-25년 1월.md",
    "title": "월간 Obsidian - 2025년 1월: Web Clipper, Smart Composer, Templater with AI",
    "description": "Obsidian의 최신 플러그인 Web Clipper, Smart Composer, Templater with AI 활용법 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 2025년 1월 월간 Obsidian 업데이트에서 소개된 주요 플러그인들을 정리한 노트이다. Web Clipper를 활용한 웹 콘텐츠 저장 자동화, Smart Composer의 AI 기반 노트 작성 지원, Templater with AI로 템플릿에 AI 기능 통합하기, 그리고 이들을 결합한 효율적인 지식 관리 워크플로우 구축 방법을 포함한다.\n# Obsidian에서 활용할 수 있는 세 가지 유용한 기능\n\nObsidian을 보다 효율적으로 사용하기 위해 다음 세 가지 도구를 소개\n\n1. **Web Clipper**\n2. **Smart Composer**\n3. **Templater with AI**\n\n본 블로그는 CMDS의 요한님 강의 내용 정리입니다:\n- 슬래쉬 페이지 링크: [https://slashpage.com/cmds-class](https://slashpage.com/cmds-class)\n\n---\n\n## 1. Web Clipper\n\n웹페이지나 블로그 글 등을 쉽게 저장하고, 원하는 형식으로 편집해 Obsidian에 옮길 수 있는 크롬 확장 프로그램입니다\n\n[**Web Clipper Google Extension Link**](https://chromewebstore.google.com/detail/obsidian-web-clipper/cnjifjpddelmedmihgijeibhnjfabmlf?hl=en-US&utm_source=ext_sidebar&pli=1)\n\n### 주요 기능\n\n- 원하는 웹 콘텐츠를 Markdown 형식으로 저장\n- Note Content, Interpreter Content 등의 템플릿을 활용해 자동 요약 및 태그 처리\n\n### 설정 화면\n\n![](https://i.imgur.com/dNbOYTr.png)\n\n### Note Content 템플릿 예시\n\n![](https://i.imgur.com/UfrdWuy.png)\n\n{% raw %}\n```markdown\n## Summary \n{{\"summarize"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-07-13-TeddyNote LangGraph.md",
    "title": "TeddyNote LangGraph 세미나",
    "description": "TeddyNote의 LangGraph를 활용한 에이전트 워크플로우 구축 세미나 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> TeddyNote의 LangGraph 세미나 내용을 정리한 노트이다. LangGraph의 개념과 LangChain과의 차이, 그래프 기반 워크플로우 설계, State Graph 구조, 노드와 엣지 정의, 조건부 라우팅, 에이전트 간 협업 구현, 그리고 실제 복잡한 AI 워크플로우 구축 사례를 포함한다.\n\n## TeddyNote LangGraph \n\n### LangGraph 개발 단계\n\n1. 문서 검색, 답변 생성\n2. 답변을 평가 -> 정보가 부족할 시 웹 검색\n\n![](https://i.imgur.com/yNo87W4.png)\n\n\n### Conventional RAG의 문제점\n\n- 기본 RAG의 모든 점( chuck size, query, 검색 방법 등등)이 고정되어있다. 유연하지 않다\n   - 따라서 모든 단계를 한번에 다 잘해야 함\n   - 이전 단계로 되돌아가기 어려움\n\n\n### LangGraph 제안\n\n![](https://i.imgur.com/ogutiIB.png)\n\n![](https://i.imgur.com/ilY8gVk.png)\n\n![](https://i.imgur.com/0CnfDdc.png)\n\n\n### LangGraph \n- Node, Edge, State를 통해 LLM을 활용한 워크플로우에 순환(Cycle) 연산 기능을 추가하여 손쉽게 흐름 제어\n   - Conditional Edge: 조건부(if문)와 같은 흐름 제어\n   - Human in the loop: 필요시 사람이 중간 개입하여 다음 단계를 결정\n   - Checkpointer: 과거 실행 과정에 대한 수정 & 리플레이\n\n\n#### State\n\n![](https://i.imgur.com/pVe0k8T.png)\n\n![](https://i.imgur.com/186KzNJ.png)\n\n- 모든 값을 채울 필요 없음\n- 이전 노드에서 가져온 값들을 유지, 필요시 추가 or 덮어쓰기\n\n\n![](https://i.imgur.com/YaZqBzy.png)\n\n- 평"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-06-24-ai-talk-show-2024.md",
    "title": "AI Talk Show 2024",
    "description": "AI Talk Show 2024 이벤트 프레젠테이션 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> AI Talk Show 2024 이벤트에서 발표된 다양한 AI 관련 프레젠테이션을 정리한 노트이다. 최신 AI 트렌드, 실제 활용 사례, 기술 동향, 산업 적용 방안 등 AI 업계의 현재와 미래를 조망하는 발표 내용들을 포함한다.\n### AI 이벤트 프레젠테이션 요약\n\n#### 연사:\n\n- Richard Socher, You.com CEO\n- Sung Kim, Upstage CEO\n- 주최: Upstage 및 SoftBank Ventures Asia\n\n---\n\n### 소개\n\n**이벤트 개요:**\n\n- Upstage의 Sung Kim과 SoftBank Ventures Asia가 주최\n- AI 검색 엔진의 발전과 혁신에 중점\n- You.com의 접근 방식이 부정확성과 환각 같은 AI 모델의 일반적인 문제를 어떻게 극복하는지에 대한 특별한 강조\n\n---\n\n### You.com의 주요 기능\n\n**개인화된 AI 검색 엔진:**\n\n- You.com은 개인화된 검색 경험을 제공하는 것을 목표로 함\n- Perplexity 및 ChatGPT-4와 같은 다른 AI 모델과 경쟁\n\n#### 주요 기능 및 혁신\n\n1. **Longer Snippets of Context:**\n    \n    - Google SerpAPI의 단순 통합만으로는 부족\n    - You.com은 더 많은 양의 입력 데이터를 사용하여 더 정확한 검색 결과를 제공\n    - **개인적 인사이트:**\n        - 질문: 더 긴 컨텍스트가 비용 효율적인가?\n        - 답변: 비용과 시간이 증가하지만, 품질이 크게 향상됨\n2. **Best Model for the Job:**\n    \n    - 사용자의 질문에 따라 다른 LLM 모델을 사용\n    - **예시:**\n        - 코딩 작업에는 GPT-4\n        - 법률 해석에는 Claude\n    - **개인적 인사이트:**\n        - 질문: 이로 인해 응답 시간이 증가하는가?\n        - 답변: 그"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-12-01-메타코드 강의 후기_1강_소프트웨어 설계.md",
    "title": "정보처리기사 필기 - 메타코드 1강 소프트웨어 설계",
    "description": "정보처리기사 필기 메타코드 강의 1강 소프트웨어 설계 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 메타코드의 정보처리기사 필기 강의 1강 소프트웨어 설계 파트를 정리한 노트이다. 소프트웨어 생명주기 모델(폭포수, 애자일, 나선형), 요구사항 분석 기법, UML 다이어그램, 디자인 패턴, 모듈화 및 응집도/결합도 개념, 그리고 시험에 자주 나오는 핵심 개념들을 포함한다.\n# 1. 소프트웨어 *설계*\n\n![](https://i.imgur.com/gMEqzNJ.png)\n\n## 1-1. 소프트웨어 설계 - 요구사항 확인\n\n\n- 현행 시스템 분석\n- 요구사항 확인\n- 분석 모델 확인\n\n\n#### 요구사항 예시\n![](https://i.imgur.com/f56Dn3h.png)\n요구사항은 단순하게 아이디어에서 시작된다.\n\n![](https://i.imgur.com/oaDISMU.png)\n\n단순히 메신저 앱에 멘션 기능을 넣어달라는 말은 개발자 입장에서 구현하기 애매하기 때문에 명확한 요구사항 명세서가필요하다.\n\n### 1-1-1. 현행 시스템 분석\n\n#### 플랫폼\n: 애플리케이션이나 서비스를 개발하고 실행할 수 있는 기반 환경\n\n플랫폼 성능 분석 시 고려 항목:\n\n| 경과 시간(Turnaround Time) | 작업이 완료될 때까지의 시간                 |\n| ---------------------- | ------------------------------- |\n| 사용률(Utilization)       | 작업이 진행될 동안의 자원 사용률(CPU, Memory) |\n| 응답시간(Response Time)    | 작업 요청에 대한 응답이 올 때까지의 시간         |\n| 가용성(Availability)      | 얼마나 안정적인가?(장애 가능성)              |\n\n#### 시스템\n: 특정 기능을 수행하기 위해 다양한 구성 요소들이 상호작용하는 통합된 구조(주로 스포트웨어 + 하드웨어)\n\n\n### 1-1-2. 요구사항 확인\n\n#### 요구사항 분석\n- 요구사항 명세 작성\n- 사용자 요구 추출, 목표 결"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-07-24-​MLOps Now — LLM in Production.md",
    "title": "MLOps Now - LLM in Production 세미나",
    "description": "프로덕션 환경에서의 LLM 운영을 위한 MLOps 전략 세미나 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 모두의연구소 주최 MLOps Now 세미나에서 다룬 프로덕션 환경에서의 LLM 운영 방법론이다. VESSL의 LLM 파이프라인 관리, Weaviate의 벡터 데이터베이스 활용, 삼성SDS의 엔터프라이즈 LLM 운영 사례, Liner의 실시간 LLM 서비스 최적화 전략 등 실무에서의 LLMOps 구현 경험과 노하우를 포함한다.\n\n## ​발표 내용 및 연사\n\n- ​**Building AI-native applications with Weaviate**\n    \n    -  [Bob van Luijt](https://www.linkedin.com/in/bobvanluijt/), Co-founder & CEO, Weaviate\n        \n- ​**LLMOps에서 AGI까지 — 산업별 2024년 최신 사례**\n    \n    - ​[안재만](https://www.linkedin.com/in/jaeman-an/), Co-founder & CEO, VESSL AI\n        \n- **What if...? 처음부터 다시 LLM 어플리케이션을 개발한다면**\n    \n    - ​[허훈](https://www.linkedin.com/in/huffonism/), Tech Lead, Liner\n        \n- ​**AI 연구를 위한 GPU Platform 기술 소개**\n    \n    - ​[하승훈](https://www.linkedin.com/in/seunghoon-ha/), 삼성 SDS, 컴퓨팅시스템연구Lab장\n        \n\n## Building AI-native applications with Weaviate\n- 발표자:[Bob van Luijt](https://www.linkedin.com/in/bobvanluijt/), Co-founder & CEO, Weaviate\n- Daglo: https://daglo.ai/share/2wbCV9mtDEfN6XZN\n\n### 3줄 요약\n- Weaviate는 벡터 데이터베이스와 AI 네이티브"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-03-22-초거대 AI 확산 생태계 조성 사업 설명회.md",
    "title": "초거대 AI 확산 생태계 조성 사업 설명회",
    "description": "정부 주도 초거대 AI 확산 생태계 조성 사업 설명회 참석 기록",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 정부 주도의 초거대 AI 확산 생태계 조성 사업에 대한 설명회 내용이다. 사업 추진 방향, 유의사항, 추진 과제 소개, 구축 예정 데이터의 품질 관리 방안, 헬프데스크 FAQ, Q&A 세션을 통해 AI 생태계 구축을 위한 정부 지원 정책과 참여 방법을 다룬다.\n## 진행 순서\n1. 추진방향, 유의사항, 추진과제 등 소개\n2. 구축 예정 데이터 품질 관리방안 안내\n3. 헬프데스크 FAQ에 대한 설명 등\n4. Q&A\n\n인사말: \n- 지능데이터본부 신신애 본부장님\n- NIA 문준석 수석님\n## 추진방향, 유의사항, 추진과제 등 소개\n### 1. 추진 의의 및 현황\n- 챗 GPT의 등장 → AI 기술의 활용 일상화 → 기존의 분류형 중심 기술 → 생성형 AI로 대전황\n\n- 핵심은 코딩이 아닌 데이터\n- 보고 듣고 말할 수 있는 LLM 데이터 구축(신규)\n- 다양한 분야의 합성 데이터 구축 활성화\n\n4. 데이터 구축 방향\n\t- 산업에 특화된 sLLM 개발용 말뭉치 데이터 구축\n\t\t- 법률\n\t\t- 의료\n\t\t- 교육 행정사무\n\t\t- 교통 물류\n\t\t- 제조로보틱스 콘텐츠\n\t\t- 재난, 안전 환경\n\t\t- 국방 농림축수산\n5. 초거대 AI확산 생태계 조성 사업 데이터 구축 현황\n\t- 많이했다~\n\n\n### 2. 2024년 사업 개요\n\n1. 사업 범위\n\t- 사업 목적: AI 제품 서비스 및 기술 개발에 활용 가치가 높은 초거대 모델 \n2. 공고 현황\n\t- 2차 예정\n\t\t- 분야: 2차 7종\n\t\t- 비고(공고, 마감일): 미정\n3. 사업 지원내용\n\t- 지원기간: 협약일로부터~12월 31일\n\t\t- 과제의 협야일 시작일은 협약이 완료되는 월의 1일로 소급 적용하여 협약체결 예정\n\t- 선정규모: 지정공무 41개 분야, 자유공모7개 데이터\n\t- 지원예산: 정보지원금 6억원~18억원\n\t- 참여 범위: 주관 또는 참여기관 자격으로 최대 5개(주관기관 자격으론 최대 3개)\n4. 참여범위\n\t- 동일 분야 중복 참여 불가\n\t- 총괄책임자는 사업 수행 중에 참여 불가, "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-05-26-위코 웨비나 노트.md",
    "title": "개발자 이직 전략 웨비나 - 위코",
    "description": "개발자 이직을 위한 실전 전략과 노하우 웨비나 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 위코의 개발자 이직 전략 웨비나 내용을 정리한 노트이다. 개발자의 정의와 역할, 이력서 작성 전략, 포트폴리오 구성 방법, 기술 면접 준비, 연봉 협상 팁, 그리고 성공적인 이직을 위한 실전 노하우를 포함한다.\n## 개발자란?\n\n- **정의**: 코딩 기술을 통해 솔루션을 만들어내는 사람\n- **필요 역량**: 기술 스택을 잘 설명하고 효과적으로 사용하는 능력\n\n## 작성 팁\n\n- **이력서/포트폴리오 작성**:\n    - 인사팀과 개발자 모두를 고려하여 작성\n    - 프로젝트 나열 전에 기술 스택을 프롤로그처럼 미리 작성\n    - 당연한 것도 작성할 것 (개발자에겐 당연하지만 인사팀에겐 아닐 수 있음)\n\n## 본 프로젝트 작성 팁\n\n- **필수 정보**:\n    \n    - 기간\n    - 회사명, 팀명, 직책\n    - 성과 및 결과\n    - 프로젝트 투입 인원\n    - 사용 언어\n    - 개발 환경\n    - 주요 업무 및 상세 역할\n    - 개선 경험 (질문 대비도 필요)\n- **참고**: 잡코리아 양식을 참고\n    \n    - 학력/경력/자격증 간단히 나오지만 순서 변경 어려움\n    - 개발 스택을 태그할 수 있는 게 장점\n- **신입 vs 경력**:\n    \n    - 신입: 자기소개서 3페이지 정도\n    - 경력: 자기소개서 1-2페이지 정도\n    - 기획자/마케터 직무보다는 자기소개서 중요성 낮음\n- **포트폴리오**:\n    \n    - 깃허브 포트폴리오 매우 중요\n\n## 팁\n\n- 이력서는 최대 5페이지 넘지 않게 작성\n\n## 사용 플랫폼\n\n- **잡코리아**:\n    - 이력서 오픈 시 헤드헌터나 기업에게 연락 옴\n    - 이력서 작성 후 PDF 내보내기 가능\n- **원티드**:\n    - 지원하기 쉬우나 서류 합격률 낮음\n- **사람인**:\n    - 추천\n\n## 포트폴리오\n\n- **구성**:\n    - 노션보다는 5페이지 내외의 잘 쓴 PDF 이력서와 깃허브 포트폴리오면 충분\n\n## 코딩 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-09-07-TeddyNote-Agentic RAG.md",
    "title": "TeddyNote - Agentic RAG 세미나",
    "description": "Agentic RAG의 개념과 구현 방법을 다룬 TeddyNote 세미나 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> TeddyNote의 Agentic RAG 세미나 내용을 정리한 노트이다. Agent의 정의와 경계, Tool Calling의 개념, RAG와 Agent의 결합인 Agentic RAG의 특징, LangGraph를 활용한 복잡한 워크플로우 구현, 그리고 실제 구현 예시와 사례 연구를 포함한다. Agent가 도구를 능동적으로 선택하고 활용하여 더 정확한 답변을 생성하는 과정을 다룬다.\n테디노트 유튜브 링크 [https://www.youtube.com/watch?v=J610NhUrj-s&t=2236s](https://www.youtube.com/watch?v=J610NhUrj-s&t=2236s)\n\n\n## Agent란?\n- 경계가 명확하지 않아 쉽게 정의 내리기 어렵다\n- Tool을 사용한다면 Agent인가?\n\n\t\t→ Tool Calling이 아니더라도 Tool이지 않나?\n\t\t- ex) RAG를 Tool Calling으로 호출하지 않아도 RAG는 도구지 않나?\n\n![](https://i.imgur.com/tbTh6Vg.png)\n\n### Agentic 함이란?\n- 뒤에 일어날 많은 로직들을 어떻게, 어떤 순서로 실행할지를 LLM에게 맡김\n\n### Tips\n\n- 계획을 짜주는 LLM을 둠으로써 전체 로직 컨트롤\n\t- 두지 않을 시, Agent끼리 원하지 않는 티키타카 현상 발생\n\n\n### Agent Frameworks\n\n![](https://i.imgur.com/pihyqzQ.png)\n\n최근에 N8N(?) - No Code tool 이지만 생각보다 Customizing을 많이 할 수 있다\n\n> LangGraph 왜 배웠지 회의감 든다고 하신다ㅋㅋ\n\n\n그럼에도 코드가 필요한 이유가 존재:\n- 입출력 설정\n- 기존 시스템과 결합\n\n\n\n### CrewAI\n- LangChain 기반 프레임워크 → 기존에 쓰던 LangChain과 호환성이 높음\n- AutoGen이나 LangGraph에 비해 Code를 쓴다기 보다 명세서를 작성하는 느낌이 큼(반 노코드"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/2024-01-18-통계 기초의 모든것.md",
    "title": "통계 기초의 모든 것",
    "description": "통계학의 기초 개념부터 확률분포, 가설검정까지 종합 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 통계학의 기본 개념과 방법론을 정리한 자격증 준비 노트이다. 모집단과 표본, 모수와 통계량의 개념, 자료의 종류(질적/양적 자료), 척도의 수준(명목/서열/등간/비율), 확률분포(정규분포, t분포, 카이제곱분포, F분포), 기술통계(중심경향치, 산포도), 추론통계(점추정, 구간추정, 가설검정)의 핵심 내용을 다룬다.\n\n# 통계 기초의 모든것\n\n### 통계\n- 데이터의 수집, 분석, 추론, 요약 등의 방법론\n- Fields\n\t- Design(설계/ 계획)\n\t- Description(요약): 데이터를 요약 표현하기 위한 시각적(Graphical), 수치적(numerical) 방법\n\t- Inference(추론) : 표본에 기반한 모집단에 대한 추론/예측\n\n\n- 모집단(Population): 통계학에서 관심/조사의 대상이 되는 개체의 전체 집합\n- 모수(Parameter): 모집단에 대한 수치적 요약\n- 표본(Sample): 모집단을 적절히 대표하는 모집단의 일부\n- 통계량(Statistics): 표본에 대한 수치적 요약\n\n> sample statistics를 통해 population parameter을 추론하고 파악하는것이 통계학의 개념!!\n\n### 자료의 종류\n\n1. 범주형 자료: 속성의 범주화, 상대적 서열도 표현\n\t- 명목형 자료: 단순히 속성을 분류하기 위함(혈액형)\n\t- 순서형 자료: 상대적인 크기 비교(만족도, 최종학력)\n2. 양적 자료: 자료자체가 **숫자**로 표현됨\n\t- 이산형 자료: 셀 수 있는 자료(빈도수, 불량품의 수),  countable\n\t- 연속형 자료: 셀 수 없는 자료(길이, 시간), 범주화 했기 때문에 countable하지만 원래는 불가능\n\n\n### 통계량 - 중심\n\n1. 최빈값(mode)\n\t- 발생빈도가 가장 높은 값\n\t- 극단값에 영향을 받지 않음\n\t- 주로 범주형 자료에 대한 대표값\n\t- 2개 이상 존재 가능\n2. 중앙값(mdeian)\n\t- 크기 순으로 정렬된 자료에서 가운데에 위치하는 값\n\t- 관"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/항해99 1일 1아티클 챌린지/아티클 리뷰 - 성공적인 애플리케이션 현대화를 위한 12가지 기본 원칙.md",
    "title": "아티클 리뷰 - 성공적인 애플리케이션 현대화를 위한 12가지 기본 원칙",
    "description": "클라우드 네이티브 환경에서 성공적인 애플리케이션 현대화를 위한 12가지 기본 원칙을 알아보고, 디지털 전환 시대에 필요한 애플리케이션 개선 전략을 정리한다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> 이 글은 삼성SDS의 Andrew Min이 작성한 \"성공적인 애플리케이션 현대화를 위한 12가지 기본 원칙\" 아티클에 대한 리뷰다. 원문은 기업이 레거시 시스템을 현대화할 때 고려해야 할 12가지 핵심 원칙을 제시하며, 점진적 접근법과 비즈니스 가치 중심의 전략을 강조하고 있다. 특히 \"애플리케이션 현대화의 여정은 마라톤이지 단거리 경주가 아니다\"라는 표현에 깊이 공감했다. 나 역시 금융 서비스 마이그레이션 프로젝트를 진행하며 단계적 접근과 비즈니스 우선순위 설정의 중요성을 경험했다. 이 리뷰에서는 원문에서 제시한 원칙들을 정리하고, 각 원칙을 실제 프로젝트에 적용했던 경험과 교훈을 함께 공유한다.\n\n> [!info]\n> 이 글은 [[항해99 1일 1아티클 챌린지|항해99 1일 1아티클 챌린지]] 참여 글입니다.\n> - [챌린지 페이지 바로가기](https://99clubarticle.vercel.app/)\n> - [챌린지 소개 페이지](https://hanghae99.spartacodingclub.kr/99club-1day1study)\n> - 원본 아티클: [성공적인 애플리케이션 현대화를 위한 12가지 기본 원칙](https://www.samsungsds.com/kr/insights/successful-application-modernization.html)\n\n\n## 아티클 내용\n\n### 들어가며\n\n이 글은 삼성SDS의 Andrew Min이 작성한 애플리케이션 현대화에 관한 글로, 기존 애플리케이션을 클라우드 네이티브 환경에 맞게 개선하는 방법과 원칙을 소개한다. 단순히 레거시 애플리케이션을 클라우드에 배포하는 것이 아니라, 클라우드의 이점을 최대한 활용할 수 있도록 애플리케이션의 아키텍처, 코드, 데이터, 보안, 개발 및 운영 방식 전반을 개선하는 과정에 대해 설명한다.\n\n특히 애플리케이션 현대화가 AI/ML, 빅데이터, 블록체인, IoT, 메타버스 등 디지털 전환의 핵심 기술들을 쉽게 활용할 수 있는 기반을 마련한다는 점"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/항해99 1일 1아티클 챌린지/아티클 리뷰 - 7개월간의 자바스프링 독학 회고.md",
    "title": "아티클 리뷰 - 7개월간의 자바스프링 독학 회고",
    "description": "비전공자가 7개월 동안 자바와 스프링을 독학하며 겪은 경험과 성장 과정, 그리고 효과적인 학습 방법에 대한 회고를 통해 개발자 학습 경로의 교훈을 정리한다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> 이 글은 @backfox의 \"7개월간의 자바스프링 독학 회고\" 아티클에 대한 리뷰다. 원문은 비전공자가 자바와 스프링을 독학하며 생활코딩, 자바의 정석, 김영한의 스프링 강의 등을 활용해 객체지향 원리, JPA, MVC 패턴, 스프링 부트를 단계적으로 학습한 여정을 담고 있다. 특히 '직접 실행해보기'와 '내 글로 정리하기'를 통한 학습 방법론과 완벽한 이해를 바탕으로 한 단계적 접근법이 인상적이었다. 나 역시 자바로 개발을 시작해 파이썬으로 전환한 경험이 있어, 저자의 객체지향적 사고방식과 체계적 학습법에 크게 공감했다. 이 리뷰에서는 원문의 핵심 내용과 함께 프로그래밍 독학에 필요한 체계적인 로드맵 구축, 이해 중심의 능동적 학습, 실습과 기록 병행의 중요성에 대한 나의 견해를 담았다.\n\n> [!info]\n> 이 글은 [[항해99 1일 1아티클 챌린지|항해99 1일 1아티클 챌린지]] 참여 글입니다.\n> - [챌린지 페이지 바로가기](https://99clubarticle.vercel.app/)\n> - [챌린지 소개 페이지](https://hanghae99.spartacodingclub.kr/99club-1day1study)\n> - 원본 아티클: [7개월간의 자바스프링 독학 회고 (2021.11-2022.07)](https://velog.io/@backfox/7%EA%B0%9C%EC%9B%94%EA%B0%84%EC%9D%98-%EC%9E%90%EB%B0%94%EC%8A%A4%ED%94%84%EB%A7%81-%EB%8F%85%ED%95%99-%ED%9A%8C%EA%B3%A0-2021.11-2022.07)\n\n\n## 아티클 내용\n\n### 들어가며\n\n이 글은 @backfox 님이 작성한 7개월간의 자바와 스프링 독학 여정에 관한 회고록이다. 비전공자이자 개발 입문자로서 자바와 스프링을 처음부터 어떻게 공부했는지, 어떤 어려움을 겪었는지, 그리고 어떻게 극복했는지에 대한 상세한 경험담을 담고 있다.\n\n저자는 전공자가 아님에도 불구하"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/항해99 1일 1아티클 챌린지/아티클 리뷰 - 주니어 개발자의 복수.md",
    "title": "아티클 리뷰 - 주니어 개발자의 복수",
    "description": "Steve Yegge의 \"주니어 개발자의 복수\" 아티클을 통해 AI 코딩 시대에서 주니어 개발자와 시니어 개발자의 역학 관계 변화에 대한 통찰을 정리한다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> 이 글은 Steve Yegge의 \"Revenge of the Junior Developer\" 아티클에 대한 리뷰다. 원문은 AI 코딩의 발전 단계를 6개의 파도로 분석하고, 'vibe coding'으로 대표되는 AI 활용에 빠르게 적응하는 주니어 개발자들과 변화에 저항하는 시니어 개발자들 간의 역학 관계 변화를 다루고 있다. 특히 \"AI가 당신보다 뛰어나다는 것을 증명하는 것은 AI의 일이 아니다. AI를 활용해 더 나아지는 것은 당신의 일이다\"라는 구절에 크게 공감했다. 나 역시 일상적으로 AI 코딩 도구를 활용하며 코드 작성자에서 에이전트 관리자로 역할이 변화하는 과정을 경험하고 있다. 이 리뷰에서는 원문의 핵심 내용과 함께 AI 코딩 시대에 개발자가 어떻게 적응하고 성장해야 하는지에 대한 나의 실천 경험과 견해를 담았다.\n\n> [!info]\n> 이 글은 [[항해99 1일 1아티클 챌린지|항해99 1일 1아티클 챌린지]] 참여 글입니다.\n> - [챌린지 페이지 바로가기](https://99clubarticle.vercel.app/)\n> - [챌린지 소개 페이지](https://hanghae99.spartacodingclub.kr/99club-1day1study)\n> - 원본 아티클: [Revenge of the Junior Developer](https://sourcegraph.com/blog/revenge-of-the-junior-developer)\n\n\n## 아티클 내용\n\n### 들어가며\n\n이 글은 Steve Yegge가 Sourcegraph 블로그에 게시한 글로, AI 코딩의 급격한 발전과 이로 인한 개발자 생태계의 변화에 대해 다루고 있다. 특히 'vibe coding'이라는 새로운 코딩 패러다임의 등장과 함께, 이에 빠르게 적응하는 주니어 개발자들이 AI를 거부하는 시니어 개발자들보다 우위를 점하게 된다는 흥미로운 관점을 제시한다. 기술 변화의 속도와 적응의 필요성에 대한 날카로운 통찰이 담긴 글이다.\n\n### 인상"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/항해99 1일 1아티클 챌린지/아티클 리뷰 - 법대생이었던 내가 일어나보니 개발자가 된 건에 대하여.md",
    "title": "아티클 리뷰 - 법대생이었던 내가 일어나보니 개발자가 된 건에 대하여",
    "description": "법대생 출신 개발자의 커리어 전환 과정과 성장 이야기를 읽고 느낀 점을 정리한다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> 이 글은 Joshua_Kim의 \"법대생이었던 내가 일어나보니 개발자가 된 건에 대하여\" 아티클에 대한 리뷰다. 원문은 법학을 전공한 저자가 30대에 개발자로 커리어를 전환하고 성장해온 과정을 담고 있다. 특히 '세상을 변화시키는 힘'을 찾아 법학에서 프로그래밍으로 전환한 일관된 가치관과 \"배수진을 치고 선택한 것이었으니 재미있어야만 했다\"는 절박한 동기부여 방식이 인상적이었다. 비전공자인 나 역시 개발자로 전환하며 비슷한 과정을 겪었기에 더욱 공감했다. 이 리뷰에서는 원문의 주요 내용과 함께 Comfort Zone을 벗어나 성장하기 위한 용기, 비전공자로서 느끼는 impostor syndrome, 그리고 꾸준한 기록의 중요성에 대한 나의 경험과 생각을 담았다.\n\n> [!info]\n> 이 글은 [[항해99 1일 1아티클 챌린지|항해99 1일 1아티클 챌린지]] 참여 글입니다.\n> - [챌린지 페이지 바로가기](https://99clubarticle.vercel.app/)\n> - [챌린지 소개 페이지](https://hanghae99.spartacodingclub.kr/99club-1day1study)\n> - 원본 아티클: [법대생이었던 내가 일어나보니 개발자가 된 건에 대하여](https://velog.io/@joshuara7235/%EB%B2%95%EB%8C%80%EC%83%9D%EC%9D%B4%EC%97%88%EB%8D%98-%EB%82%B4%EA%B0%80-%EC%9D%BC%EC%96%B4%EB%82%98%EB%B3%B4%EB%8B%88-%EA%B0%9C%EB%B0%9C%EC%9E%90%EA%B0%80-%EB%90%9C-%EA%B1%B4%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC)\n\n\n## 아티클 내용\n\n### 들어가며\n\n이 글은 법대생 출신 조슈아님이 대학 동문 개발자 커뮤니티에서 발표한 자신의 커리어 이야기를 담고 있다. 조슈아님은 이제 막 3년차가 된 개발자로, 자신이 법대생에서 어떻게 개발자가"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/항해99 1일 1아티클 챌린지/아티클 리뷰 - 자바 클래스 설계의 다섯 가지 SOLID 원칙.md",
    "title": "아티클 리뷰 - 자바 클래스 설계의 다섯 가지 SOLID 원칙",
    "description": "SOLID 원칙에 관한 CodeGym 아티클을 읽고, 객체지향 설계에서 이 원칙들의 중요성과 실제 적용 방법에 대해 리뷰한다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> 이 글은 CodeGym의 \"SOLID: 자바 클래스 설계의 다섯 가지 기본 원칙\" 아티클에 대한 리뷰이다. 원문은 객체지향 설계에서 중요한 SOLID 원칙(단일 책임, 개방-폐쇄, 리스코프 치환, 인터페이스 분리, 의존성 역전)을 설명하고 자바 코드 예제를 통해 실제 적용 방법을 보여준다. 특히 단일 책임 원칙과 의존성 역전 원칙이 실제 코드에서 어떻게 구현되는지 상세한 예시를 통해 명확하게 설명한 점이 인상적이었다. 이 리뷰에서는 각 원칙의 핵심 내용과 함께 실무에서의 적용 경험, 그리고 원칙을 적용할 때 발생할 수 있는 오버엔지니어링의 위험성에 대한 생각을 담았다.\n\n> [!info]\n> 이 글은 [[항해99 1일 1아티클 챌린지|항해99 1일 1아티클 챌린지]] 참여 글이다.\n> - [챌린지 페이지 바로가기](https://99clubarticle.vercel.app/)\n> - [챌린지 소개 페이지](https://hanghae99.spartacodingclub.kr/99club-1day1study)\n> - 원본 아티클: [SOLID: 자바 클래스 설계의 다섯 가지 기본 원칙](https://codegym.cc/ko/groups/posts/ko.232.solid-jaba-keullaeseu-seolgyeui-daseos-gaji-gibon-wonchig)\n> - 관련 리뷰: [[아티클 리뷰 - 프론트엔드와 SOLID 원칙|프론트엔드와 SOLID 원칙]]\n\n## 아티클 내용\n\n### 들어가며\n\n이 아티클은 로버트 마틴이 제안하고 마이클 페더스가 약어화한 객체지향 설계의 다섯 가지 기본 원칙인 SOLID에 대해 설명한다. 아티클은 Java 코드 예제를 통해 각 원칙의 의미와 실제 적용 방법을 보여주며, 특히 OrderProcessor 클래스를 사용한 일관된 예시를 통해 원칙들이 어떻게 실제 코드에 적용되는지 설명한다.\n\n> [!note]\n> 어제 리뷰한 [[아티클 리뷰 - 프론트엔드와 SOLID 원칙|카카오엔터테인먼트의 스티"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/항해99 1일 1아티클 챌린지/아티클 리뷰 - 주니어 개발자가 면접을 앞두고 준비한 것들.md",
    "title": "아티클 리뷰 - 주니어 개발자가 면접을 앞두고 준비한 것들",
    "description": "네이버 블로그에 게재된 \"주니어 개발자가 면접을 앞두고 준비한 것들\"에 대한 리뷰로, 개발자 면접 준비 과정과 접근 방법에 대한 실질적인 조언을 담고 있다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> 이 글은 네이버 블로그에 게재된 \"주니어 개발자가 면접을 앞두고 준비한 것들\"에 대한 리뷰이다. 원문은 비전공자 출신 주니어 개발자가 면접을 준비하며 경험한 과정과 접근법을 다루고 있다. 특히 기술 면접과 컬쳐핏 면접을 효과적으로 준비하는 방법, 답변을 연습하는 실용적인 접근법에 대한 내용이 인상적이었다. 자바스크립트, 네트워크, 운영체제 등의 기술적 질문부터 자기소개, 지원 동기, 갈등 해결 경험 같은 컬쳐핏 관련 질문까지 체계적인 준비 방법을 제시하고 있어, 취업 준비생들에게 실질적인 도움이 될 만한 내용이다.\n\n> [!info]\n> 이 글은 [[항해99 1일 1아티클 챌린지|항해99 1일 1아티클 챌린지]] 참여 글이다.\n> - [챌린지 페이지 바로가기](https://99clubarticle.vercel.app/)\n> - [챌린지 소개 페이지](https://hanghae99.spartacodingclub.kr/99club-1day1study)\n> - 원본 아티클: [주니어 개발자가 면접을 앞두고 준비한 것들](https://blog.naver.com/jinzao77/223796473176)\n\n## 아티클 내용\n\n### 들어가며\n\n이 아티클은 이직을 위해 준비하는 과정에서 면접 스터디를 통해 경험한 내용과 최종적으로 원하는 회사에 합격하기까지의 여정을 담고 있다. 글쓴이는 면접에 운이 작용하는 것을 인정하면서도, 준비 과정에서 어떤 요소들이 긍정적으로 작용했는지 분석하고 이를 공유함으로써 취직이나 이직을 준비하는 사람들에게 도움을 주고자 했다.\n\n아티클은 크게 기술 면접과 컬쳐핏 면접 두 가지 영역으로 나누어 각각의 준비 방법과 접근법을 상세히 설명하고 있다.\n\n### 인상 깊었던 한 줄\n\n> \"머릿속에 그림이 그려지는 게 더 좋은 습득 방식이라 생각한다. 면접장에서 매번 똑같이 외운 문장을 떠올리려고 하면 기억이 잘 나지 않을 수도 있고, 답변이 부자연스러워서 감점 요인이 될 수도 있다. 하지만 머릿속에 그린 그림을 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/항해99 1일 1아티클 챌린지/아티클 리뷰 - NextJS 선택 전 알아야 할 것들.md",
    "title": "NextJS 선택 전 알아야 할 것들",
    "description": "\"You should know this before choosing Next.js\" 아티클 리뷰로, Next.js 프레임워크의 거버넌스 및 오픈소스 특성에 관한 고려사항을 다루고 있다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> 이 글은 \"You should know this before choosing Next.js\"에 관한 리뷰이다. 원문은 Next.js 프레임워크와 Vercel 간의 관계, 오픈소스 프로젝트로서의 투명성과 상호운용성 이슈를 다루고 있다. 특히 Next.js가 Vercel에 최적화된 비공개 코드 경로를 가지고 있고, 다른 클라우드 제공업체에서 완전히 지원되지 않는 문제, 최근 보안 취약점 처리 방식의 문제점 등을 상세히 설명한다. 이 아티클은 기술 스택 선택 시 단순히 기능뿐 아니라 프레임워크의 거버넌스와 지속 가능성도 중요한 고려 사항임을 상기시킨다.\n\n> [!info]\n> 이 글은 [[항해99 1일 1아티클 챌린지|항해99 1일 1아티클 챌린지]] 참여 글이다.\n> - [챌린지 페이지 바로가기](https://99clubarticle.vercel.app/)\n> - [챌린지 소개 페이지](https://hanghae99.spartacodingclub.kr/99club-1day1study)\n> - 원본 아티클: [You should know this before choosing Next.js](https://eduardoboucas.com/posts/2025-03-25-you-should-know-this-before-choosing-nextjs/)\n\n## 아티클 내용\n\n### 들어가며\n\n이 아티클은 Netlify에서 근무하는 Eduardo Bouças가 작성한 글로, Next.js 프레임워크를 선택하기 전에 알아야 할 중요한 고려사항들을 다루고 있다. 글쓴이는 Netlify와 Vercel이 경쟁사 관계임을 먼저 밝히면서, 자신의 의견이 이해관계에 영향을 받을 수 있음을 투명하게 공개하고 있다.\n\n아티클은 오픈소스 소프트웨어의 중요한 가치인 투명성, 상호운용성, 그리고 독립성의 관점에서 Next.js가 가진 문제점들을 세 가지 주요 사실로 설명한다:\n\n1. 어댑터 시스템 부재: 대부분의 현대 웹 프레임워크와 달리 Next.js는 다"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/항해99 1일 1아티클 챌린지/아티클 리뷰 - CAP 이론과 분산 시스템의 이해.md",
    "title": "아티클 리뷰 - CAP 이론과 분산 시스템의 이해",
    "description": "CAP 이론의 핵심 개념과 분산 시스템에서의 트레이드오프에 대한 아티클을 읽고 리뷰한다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> 이 글은 IBM의 \"What is the CAP theorem?\" 아티클에 대한 리뷰이다. 원문에서는 분산 시스템에서 일관성(Consistency), 가용성(Availability), 분할 허용성(Partition tolerance) 중 동시에 두 가지만 제공할 수 있다는 CAP 이론의 핵심 개념과 실제 데이터베이스 시스템에서의 적용을 설명하고 있다. 이 리뷰에서는 특히 \"Cheap, Fast, and Good: Pick Two\"라는 비유를 통해 복잡한 개념을 이해하기 쉽게 설명한 접근 방식을 높이 평가하고, CP 데이터베이스인 MongoDB와 AP 데이터베이스인 Cassandra의 특성을 비교하며, 마이크로서비스 아키텍처에서의 데이터베이스 선택에 대한 저자의 관점을 공유한다.\n\n> [!info]\n> 이 글은 [[항해99 1일 1아티클 챌린지|항해99 1일 1아티클 챌린지]] 참여 글입니다.\n> - [챌린지 페이지 바로가기](https://99clubarticle.vercel.app/)\n> - [챌린지 소개 페이지](https://hanghae99.spartacodingclub.kr/99club-1day1study)\n> - 원본 아티클: [What is the CAP theorem?](https://www.ibm.com/think/topics/cap-theorem)\n\n\n### 들어가며\n\n이 리뷰에서는 IBM에서 발행한 CAP 이론에 관한 기술 아티클을 살펴본다. 원문은 분산 시스템이 가진 세 가지 주요 특성(일관성, 가용성, 분할 허용성) 간의 불가피한 트레이드오프를 설명하고 있으며, 특히 클라우드 기반 애플리케이션을 개발할 때 이 이론을 이해하는 것이 얼마나 중요한지를 강조하고 있다.\n\n### 인상 깊었던 한 줄\n\n> \"Cheap, Fast, and Good: Pick Two\"(저렴하고, 빠르고, 좋은 품질: 둘을 선택하세요)\n\n이 문구는 리뷰하는 아티클에서 CAP 이론을 소개하는 부분에 사용된 비유이다. 일상에서 볼 수 있"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/항해99 1일 1아티클 챌린지/항해99 1일 1아티클 챌린지.md",
    "title": "항해99 1일 1아티클 챌린지",
    "description": "항해99의 1일 1아티클 챌린지에 참여하여 매일 기술 아티클을 읽고 리뷰하는 기록이다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 항해99의 1일 1아티클 챌린지는 10일간 매일 한 편의 기술 아티클을 읽고 리뷰하는 프로그램. 개발자의 지속적인 성장과 학습을 목표로 하며, 기술 트렌드 파악과 글쓰기 능력 향상에 도움이 됨. 주요 내용으로 인상 깊은 부분, 경험과 연관 분석, 핵심 내용 요약을 작성하는 활동.\n\n> [!info]\n> - [챌린지 페이지 바로가기](https://99clubarticle.vercel.app/)\n> - [챌린지 소개 페이지](https://hanghae99.spartacodingclub.kr/99club-1day1study)\n\n## 참여 배경\n\n지인의 소개로 항해99의 1일 1아티클 챌린지를 알게 되었다. 처음에는 매일 기술 아티클을 직접 작성하는 것으로 오해했었는데, 실제로는 매일 제공되는 좋은 퀄리티의 기술 아티클을 읽고 리뷰하는 방식이었다. \n\n항해99에는 면접반과 아티클반이 있는데, 나는 아티클반에 참여하게 되었다. 매일 아침 공개되는 아티클들을 보니 개발자의 성장 스토리부터 최신 기술 트렌드까지 다양한 주제의 좋은 글들이 많아 기대가 된다. 이 챌린지를 통해 개발 지식도 넓히고 글쓰기 실력도 향상시킬 수 있을 것 같다.\n\n## 챌린지 소개\n\n항해99의 1일 1아티클 챌린지는 개발자의 지속적인 성장과 학습을 위한 프로그램이다. 매일 한 편의 기술 아티클을 읽고 리뷰하면서, 개발자로서의 시야를 넓히고 새로운 인사이트를 얻는 것을 목표로 한다.\n\n### 챌린지 규칙\n- 기간: 2024.04.09 ~ 2024.04.22 (주말 제외 10일)\n- 매일 오전 9시에 새로운 아티클이 공개된다\n- 아티클을 읽고 다음 내용을 포함하여 리뷰를 작성한다:\n  1. 인상 깊었던 부분과 그 이유\n  2. 본인의 경험 및 고민과 연관 지어 분석\n  3. 아티클의 핵심 내용 요약 (3-5개 포인트)\n\n### 참여 방법\n1. 매일 공개되는 아티클을 확인한다\n2. 아티클을 꼼꼼히 읽고 이해한다\n3. 정해진 양식에 따라 리뷰를 작성한다\n4. 다른 참여자들"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/항해99 1일 1아티클 챌린지/아티클 리뷰 - 프론트엔드와 SOLID 원칙.md",
    "title": "아티클 리뷰 - 프론트엔드와 SOLID 원칙",
    "description": "카카오엔터테인먼트 임성묵님의 '프론트엔드와 SOLID 원칙' 아티클을 읽고, 프론트엔드 개발에서 SOLID 원칙의 적용 방법과 그 중요성에 대해 리뷰한다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> 이 글은 카카오엔터테인먼트 FE 개발자 임성묵(steve)님의 \"프론트엔드와 SOLID 원칙\" 아티클에 대한 리뷰이다. 원문은 객체지향 설계의 5가지 기본 원칙인 SOLID를 프론트엔드 관점에서 재해석하고, 실제 적용 방법을 제시한다. 특히 SOLID가 단순한 코딩 기법이 아닌 '원칙(Principle)'이라는 점과 프론트엔드 특성에 맞게 이를 어떻게 적용할 수 있는지에 대한 통찰이 돋보인다. 이 리뷰에서는 아티클의 핵심 내용과 함께 SOLID 원칙이 현대 프론트엔드 개발에 가져다주는 가치, 그리고 리액트와 같은 컴포넌트 기반 개발에 어떻게 적용할 수 있는지에 대한 생각을 담았다.\n\n> [!info]\n> 이 글은 [[항해99 1일 1아티클 챌린지|항해99 1일 1아티클 챌린지]] 참여 글이다.\n> - [챌린지 페이지 바로가기](https://99clubarticle.vercel.app/)\n> - [챌린지 소개 페이지](https://hanghae99.spartacodingclub.kr/99club-1day1study)\n> - 원본 아티클: [프론트엔드와 SOLID 원칙](https://fe-developers.kakaoent.com/2023/230330-frontend-solid/)\n\n## 아티클 내용\n\n### 들어가며\n\n이 아티클은 카카오엔터테인먼트의 FE 개발자인 임성묵(steve)님이 객체지향 설계의 5가지 기본 원칙인 SOLID를 프론트엔드 개발 관점에서 어떻게 적용할 수 있는지 설명한 글이다. 기존에 백엔드 중심으로 설명되어 온 SOLID 원칙을 프론트엔드, 특히 React 환경에서 어떻게 적용할 수 있는지 구체적인 예시와 함께 제시하고 있다.\n\n### 인상 깊었던 한 줄\n\n> \"SOLID는 원칙입니다. 기법(Technique)이 아니라 원칙(Principle)이기 때문에 기법으로 접근하면 범위와 목적 설정도 어긋날 수밖에 없습니다.\"\n\n이 문구는 아티클의 핵심을 담고 있는 부분이다. 스티브님은 SOLID를 단순한 코"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Events/항해99 1일 1아티클 챌린지/아티클 리뷰 - 시니어 개발자로 성장하기 위한 핵심 역량.md",
    "title": "아티클 리뷰 - 시니어 개발자로 성장하기 위한 핵심 역량",
    "description": "시니어 개발자가 되기 위해 필요한 핵심 역량들을 다룬 '육각형 개발자' 책 리뷰를 통해 개발자로서의 성장 방향을 고찰한다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> 이 글은 '개발자의 Memoization' 블로그의 \"시니어 개발자로 성장하기 위한 핵심 역량 - '육각형 개발자' 책 리뷰\" 아티클에 대한 리뷰다. 원문은 시니어 개발자가 갖춰야 할 핵심 역량 중 특히 설계 역량에 관한 내용을 다루고 있다. 책에서 강조하는 \"높은 응집도와 낮은 결합도를 추구해야 한다\"는 설계 원칙과 다양한 결합도 유형들, 그리고 \"상속보다는 조립(Composition over inheritance)\" 원칙이 특히 인상적이었다. 또한 리팩토링의 중요성과 테스트 코드 작성을 통해 코드의 품질을 높이는 방법도 실무적인 관점에서 매우 유용했다. 이 리뷰에서는 원문의 핵심 내용과 함께 내가 프로젝트를 진행하면서 경험한 코드 설계의 어려움, 응집도와 결합도 개선을 위한 노력, 그리고 테스트 코드 작성의 중요성에 대한 나의 생각을 담았다.\n\n> [!info]\n> 이 글은 [[항해99 1일 1아티클 챌린지|항해99 1일 1아티클 챌린지]] 참여 글입니다.\n> - [챌린지 페이지 바로가기](https://99clubarticle.vercel.app/)\n> - [챌린지 소개 페이지](https://hanghae99.spartacodingclub.kr/99club-1day1study)\n> - 원본 아티클: [시니어 개발자로 성장하기 위한 핵심 역량 - '육각형 개발자' 책 리뷰 - 2](https://haley-memo.tistory.com/entry/%EC%8B%9C%EB%8B%88%EC%96%B4-%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A1%9C-%EC%84%B1%EC%9E%A5%ED%95%98%EA%B8%B0-%EC%9C%84%ED%95%9C-%ED%95%B5%EC%8B%AC-%EC%97%AD%EB%9F%89-%EC%9C%A1%EA%B0%81%ED%98%95-%EA%B0%9C%EB%B0%9C%EC%9E%90-%EC%B1%85-%EB%A6%AC%EB%B7%B0-2)\n\n## 아티클 내용\n\n### 들어가며\n\n이"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2025-05-08-CICD 툴 비교.md",
    "title": "CI/CD 툴 비교",
    "description": "다양한 CI/CD 솔루션들의 특징과 장단점을 비교하여 프로젝트 특성에 맞는 최적의 도구를 선택하는 방법을 알아본다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 이 문서에서는 GitHub Actions, GitLab CI/CD, CircleCI, Jenkins, Azure DevOps 등 주요 CI/CD 도구들의 특징, 장단점을 비교 분석한다. Docker, FastAPI, NextJS, React 기술 스택에 최적화된 CI/CD 솔루션과 VPN 환경에서의 구성 방법도 다룬다. 소규모 프로젝트에는 GitHub Actions, 엔터프라이즈 환경에는 GitLab CI/CD, 빠른 빌드가 필요하면 CircleCI, 온프레미스나 높은 커스터마이징이 필요하면 Jenkins가 적합하다.\n\n## CI/CD란 무엇인가?\n\nCI/CD(Continuous Integration/Continuous Deployment)는 현대 소프트웨어 개발에서 핵심적인 개념으로, 개발자가 코드를 지속적으로 통합하고 배포할 수 있게 해주는 프로세스를 말한다. CI는 개발자들이 코드 변경사항을 중앙 저장소에 자주 병합하고 자동 테스트를 실행하는 것을 의미하며, CD는 이러한 변경사항을 자동으로 프로덕션 환경에 배포하는 과정을 말한다.\n\n효과적인 CI/CD 파이프라인을 구축하면 다음과 같은 이점이 있다:\n\n- 빠른 피드백 루프로 버그를 조기에 발견\n- 코드 품질 향상\n- 배포 프로세스 자동화로 인적 오류 감소\n- 개발 속도 향상\n- 더 안정적인 소프트웨어 릴리스\n\n현재 시장에는 다양한 CI/CD 도구들이 있으며, 각 도구마다 특화된 기능과 장단점이 있다. Docker, FastAPI, NextJS, React와 같은 기술 스택에 최적화된 CI/CD 솔루션을 찾는 것은 개발 워크플로우를 효율적으로 만드는 데 중요한 요소다.\n\n---\n\n## 주요 CI/CD 솔루션 비교\n\n### GitHub Actions\n\nGitHub Actions는 GitHub에 직접 통합된 CI/CD 도구로, 코드 저장소와 긴밀하게 연동된다. 특히 GitHub를 기본 저장소로 사용하는 팀에게 매우 효과적인 선택이다. 실제 GCP 환경에서의 활용 예시는 [["
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2024-04-26-Ceph.md",
    "title": "Ceph 분산 스토리지 시스템 정리",
    "description": "Ceph 분산 스토리지 플랫폼의 아키텍처와 RADOS, RBD, CephFS, Object Storage 컴포넌트 설명",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Ceph는 여러 스토리지를 클러스터로 묶어 하나로 보이게 하는 오픈소스 분산 스토리지 플랫폼이다. RADOS 기술을 기반으로 데이터 복제, 자동 복구, 확장성을 제공하며, RBD(Rados Block Device), CephFS(파일 시스템), Object Storage(S3/Swift API) 등 다양한 인터페이스를 지원한다. 분산 저장으로 복구가 용이하고 하나의 클러스터로 접근이 편리하다는 장점이 있다.\n\n## Intro: \n\n## Ceph란?\n\n- 오픈 소스 스토리지 플랫폼\n\n- 여러 스토리지들을 클러스터로 묶어 하나로 보이게 하는 분산형 스토리지\n\n  \n  \n\n장점:\n\n  \n\n- 분산으로 저장하여 복구에 용이\n\n- 하나의 클러스터로 묶어 접근 용이\n\n\n\n### RADOS(Reliable Automatic Distributed Object)\n\n  \n\n- 분산 스토리지 클러스터를 구성하기 위한 기초 기술\n\n- 주로 Ceph에서 사용\n\n- 데이터의 복제, 장애 조치(failover) 및 자동 복구 등을 자동화 -> 고가용성, 확장성 제공\n\n  \n\n#### RADOS의 주요 특징:\n\n  \n\n1. **분산 처리 및 스토리지**: 데이터를 여러 서버에 걸쳐 분산시켜 저장함으로써, 단일 장비의 실패가 전체 시스템에 미치는 영향을 최소화\n\n2. **확장성**: 클러스터의 크기를 쉽게 조정할 수 있어, 소규모 시스템에서부터 수천 대의 서버를 포함하는 대규모 시스템까지 확장 가능\n\n3. **자동 복구**: 장비의 실패가 발생하면 RADOS는 다른 장비에 데이터의 복사본을 자동으로 재배치하여 데이터의 내구성 유지\n\n4. **데이터 복제 및 일관성**: 데이터는 여러 서버에 복제되어 저장되므로, 어느 하나의 서버에 문제가 생겨도 데이터의 안전성과 접근성 보장\n\n5. **오버헤드 감소**: 데이터를 저장하거나 접근할 때 발생하는 네트워크 오버헤드와 디스크 I/O를 최소화하여, 전체적인 성능 향상 도모\n\n6. **모니터링 및 관리**: 상태 모니터"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/JS 함수 최적화.md",
    "title": "JS 함수 최적화",
    "description": "자바스크립트 함수 최적화 방법과 실제 코드 개선 사례를 분석하고, 코드 가독성과 성능을 향상시키는 기법 소개",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 자바스크립트 함수를 최적화하는 방법을 실제 코드 사례를 통해 알아본다. var/let/const의 적절한 사용, 불필요한 변수 제거, 간결한 조건문 작성 등의 기법을 적용하여 코드 가독성과 성능을 모두 향상시키는 방법을 소개한다. 추가로 자바스크립트의 동등 비교 연산자(===, ==)와 값 비교 방식에 대한 심층 분석도 다룬다.\n\n## 개요\n\n코드 개선은 소프트웨어 개발에서 중요한 부분이다. 특히 자바스크립트와 같은 동적 언어에서는 작은 문법적 개선이 가독성과 성능에 큰 영향을 미칠 수 있다. 이 문서에서는 실제 코드를 분석하고 개선하는 과정을 통해 자바스크립트 함수 최적화 방법을 살펴본다.\n\n---\n\n## 원본 코드 분석\n\n다음은 최적화가 필요한 원본 코드이다:\n\n```javascript\nvar setFirstEmptyInput = function(new_value) {\n\tvar found = false;\n\tvar i = 1;\n\tvar elem = document.getElementById('input' + i);\n\twhile (elem !== null) {\n\t   if (elem.value === '') {\n\t\t  found = true;\n\t\t  break;\n\t   }\n\t   i++;\n\t   elem = document.getElementById('input' + i);\n\t}\n\tif (found) elem.value = new_value;\n\treturn elem;\n};\n```\n\n이 함수는 `input1`, `input2`, ... 형식의 ID를 가진 입력 요소들을 순차적으로 검사하여 값이 비어있는 첫 번째 입력 요소를 찾고, 해당 요소에 새 값을 설정한다.\n\n### 코드의 문제점\n\n1. **불필요한 변수 사용**: `found` 변수는 실제로 필요하지 않다\n2. **비효율적인 로직**: 조건을 만족할 때 바로 반환하지 않고 루프를 계속 진행\n3. **오래된 변수 선언 방식**: ES6에서 도입된 `let`과 `const`"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2022-09-04-_Spring_Spring Security.md",
    "title": "Spring Security 기초",
    "description": "Spring Security의 기본 개념과 인증, 인가 메커니즘 설명",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Spring Security는 스프링 기반 애플리케이션의 보안을 담당하는 프레임워크로, 인증(Authentication)과 인가(Authorization)를 제공한다. 서블릿 필터와 필터 체인을 통해 작동하며, 개발자가 보안 로직을 일일이 작성하지 않아도 되도록 체계적인 옵션을 제공한다. 로그인/비로그인 사용자 구분, Role/Permission 기반 접근 제어, Thymeleaf와의 통합 등 핵심 기능을 다룬다.\n\n# [spring]spring security\n\n## spring security란\n\n#### 스프링 시큐리티는 스프링 기반의 애플리케이션 보안(인증, 권한, 인가 등)을 담당하는 스프링 하위 프레임워크이다.\n\n즉, 인증(**Authenticate**, 누구인지) 과 인가(**Authorize**, 어떤것을 할 수 있는지)를 담당하는 프레임워크를 말한다.\n\n \n\n스프링 시큐리티에서는 주로 서블렛 필터(Filter)와 이들로 구성된 필터체인, 그리고 필터체인들로 구성된 위임모델을 사용한다. 보안과 관련해서 체계적으로 많은 옵션을 제공해주기 때문에 개발자 입장에서는 일일이 보안관련 로직을 작성하지 않아도 된다는 장점이 있다.\n\n#### 보안 용어:\n접근 주체(Principal) : 보호된 리소스에 접근하는 대상\n\n인증(Authentication) : 보호된 리소스에 접근한 대상에 대해 이 유저가 누구인지, 애플리케이션의 작업을 수행해도 되는 주체인지 확인하는 과정(ex. Form 기반 Login)\n\n인가(Authorize) : 해당 리소스에 대해 접근 가능한 권한을 가지고 있는지 확인하는 과정(After Authentication, 인증 이후)\n\n권한 : 어떠한 리소스에 대한 접근 제한, 모든 리소스는 접근 제어 권한이 걸려있다. 즉, 인가 과정에서 해당 리소스에 대한 제한된 최소한의 권한을 가졌는지 확인\n\n## spring security의 기능:\n\n1. 로그인/비로그인 사용자 별로 show/hide할 content를 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2022-09-04-_Spring_DAO vs DTO vs VO.md",
    "title": "Spring - DAO vs DTO vs VO",
    "description": "Spring 프레임워크에서 사용되는 DAO, DTO, VO의 개념과 차이점 설명",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Spring 개발에서 자주 사용되는 DAO, DTO, VO의 개념과 차이점을 설명한다. DAO는 데이터베이스 접근을 전담하는 객체로 커넥션 효율성과 보안을 제공하고, DTO는 계층 간 데이터 전달을 위한 가변 객체이며, VO는 불변의 값 객체로 읽기 전용 특성을 가진다. 각 객체의 목적과 사용 사례를 이해하면 효율적인 애플리케이션 아키텍처를 설계할 수 있다.\n\n# [Spring]DTO vs DAO vs VO\n## DAO\n### : Data Access Object\n#### 실질적으로 DB에 접근하는 객체를 말한다. 효율적인 커넥션 관리와 보안성 때문에 사용한다.\n\n#### 정의: \n한마디로 Database의 data에 access하는 트랜잭션 객체이다.(일종의 객체) DAO는 저수준의 Logic과 고급 비즈니스 Logic을 분리하고, domain logic으로부터 persistence mechanism을 숨기기 위해 사용한다.(적절히 디자인하면 모든 domain logic을 바꾸는 대신에 DAO를 바꾸기만 하면 됨)\n(persistence mechanism: DB에 데이터를 CRUD하는 계층)\n\n#### 설명:\n웹서버는 DB와 연결하기 위해서 매번 컨넥션 객체를 생성하는데, 이것을 해결하기 위해 나온 것이 ConnectionPool.\n\n(ConnectionPool: connection 객체를 미리 만들어 놓고 그것을 가져다 쓰는 것. 또 다 쓰고 난 후 반환해 놓는 것)\n\n하지만 유저 한 명이 접속하여 한번에 하나의 커넥션만 일으키지 않고 게시판 하나만 봐도 목록 볼 때 한 번, 글 읽을 때 한 번, 글 쓸때 한 번 등,, 엄청나게 많은 커넥션이 일어난다. 커넥션풀은 커넥션을 또 만드는 오버헤드를 효율적으로 하기 위해 DB에 접속하는 객체를 전용으로 하나만 만들고, 모든 페이지에서 그 객체를 호출하여 사용한다. ➡️ 이렇게 커넥션을 하나만 가져오고 그 커넥션을 가져온 객체가 모든 DB와의 연결을 하는 것이 바로 DAO 객체이다.\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2024-04-24-개발 서버 네트워크 문제.md",
    "title": "개발 서버 네트워크 문제",
    "description": "개발 서버에서 발생한 Keycloak 인증 연결 실패 문제의 진단과 해결 과정",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 로컬 환경에서는 정상 작동하던 Keycloak 인증이 개발 서버에서 connection timeout으로 실패하는 문제를 체계적으로 진단하고 해결한 사례이다. nmap과 curl을 활용한 네트워크 테스트로 443 포트 접근 문제를 식별했으며, 호스트 파일 설정과 네트워크 구성 차이를 확인하여 해결했다. 배포 환경과 개발 환경 간 차이를 인식하고 체계적으로 접근하는 디버깅 프로세스의 중요성을 보여준다.\n\n#### 문제 상황\n\n프로젝트를 진행하면서 로컬 환경에서는 문제없이 작동하던 키클락(Keycloak)을 이용한 로그인 테스트가 개발 서버에서는 연결 실패로 작동하지 않는 문제가 있었다. 로컬에서는 키클락 인증이 문제없이 통과되었지만, 개발 서버에서는 `connection timeout` 오류가 발생하였다.\n\n#### 환경 설정\n\n- **로컬 환경**: 내부 네트워크\n- **의뢰측 서버 환경**: VPN을 통해서만 접근 가능\n- **개발 서버**: 특정 URL을 통해 80포트 열림\n\n#### 진단 과정\n\n1. **로컬 서버 테스트**:\n    \n    - POSTMAN과 코드로 구현된 키클락 인증 모두 성공.\n2. **개발 서버 테스트**:\n    \n    - 동일한 코드에서 `connection timeout`.\n3. **추가 네트워크 테스트**:\n    \n    - 로컬에서 `nmap`을 사용하여 키클락 요청 주소 `키클락 인증 url'의 443포트: 성공.\n    - 개발 서버에서 동일 주소의 443포트: 실패\n    - agent 서버에서 443포트: 성공\n4. **컬(curl) 명령어 테스트**:\n    \n    - 개발 서버에서 `curl https://www.naver.com`: 성공\n    - 개발 서버에서 `curl 키클락 인증 url`: 실패. 이는 네트워크 문제로 확인\n\n#### 해결 조치\n\n- **네트워크 전문가와 협업**: `키클락 인증 url`로의 접속 실패를 캡처하여 의뢰측에 문제를 보고하고 해결을 요청.\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2025-05-02-웹 인증과 보안.md",
    "title": "웹 인증과 보안 완벽 가이드",
    "description": "웹 인증(Authentication), 인가(Authorization), OAuth 2.0, 보안 위협(CORS, CSRF, XSS)과 Next.js/NextAuth.js 구현 방법",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 웹 인증과 보안은 사용자 신원 확인과 권한 관리를 통해 디지털 자산을 보호하는 핵심 요소다. 세션 기반 인증과 JWT 토큰 기반 인증은 각각 상태 유지 방식과 무상태 방식으로 접근하며, OAuth 2.0은 사용자가 제3자 앱에 자신의 계정 접근 권한을 안전하게 위임할 수 있게 한다. CORS, CSRF, XSS 등 웹 보안 위협에 대한 적절한 방어 기법을 구현하는 것이 중요하며, Next.js와 NextAuth.js 같은 현대적인 프레임워크와 라이브러리는 안전한 인증 시스템 구축에 도움을 준다.\n\n## Intro\n\n최근 SKT와 알바몬 등 대형 서비스들의 개인정보 유출 사건이 잇따라 발생하면서 웹 보안의 중요성이 다시 한번 강조되고 있다. 나 역시 새로운 프로젝트를 진행하면서 사용자 인증(Authentication)과 인가(Authorization) 시스템을 구현해야 할 필요가 생겼고, 이 기회에 관련 개념들을 정리해보고자 한다. 보안은 개발자가 항상 염두에 두어야 할 부분이지만, 실제 구현 과정에서는 종종 간과되기도 한다. 이 글을 통해 웹 보안의 기본 개념부터 실제 구현까지 체계적으로 정리해보려 한다.\n\n## 1. 인증과 인가의 기본 개념\n\n### 인증(Authentication)과 인가(Authorization)의 차이\n\n인증과 인가는 웹 보안의 핵심 개념이지만 종종 혼동되곤 한다. 쉽게 말해 인증은 \"당신이 누구인지\" 확인하는 과정이며, 사용자의 신원을 검증하는 단계다. 반면 인가는 \"당신이 무엇을 할 수 있는지\" 결정하는 과정으로, 이미 인증된 사용자에게 특정 리소스나 기능에 대한 접근 권한을 부여하는 것을 의미한다.\n\n일상에서 비유하자면, 건물에 들어갈 때 ID 카드로 자신을 확인받는 과정이 '인증'이라면, 그 ID 카드에 따라 건물의 특정 층이나 방에 접근할 수 있는지를 결정하는 것은 '인가'라고 볼 수 있다.\n\n### 인증의 종류\n\n인증 방식은 크게 네 가지로 나눌 수 있다. \n1. 비밀번호나 PIN, 보안 질문 같"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2025-08-30-API-사용량-추적-시스템-설계.md",
    "title": "API 사용량 추적 시스템 설계 - Redis 하이브리드 접근법과 성능 최적화 전략",
    "description": "OpenAI API를 활용한 서비스에서 사용자별 월별 사용량을 효율적으로 추적하고 관리하기 위한 Redis 하이브리드 아키텍처 설계와 성능 최적화 전략을 체계적으로 분석한다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> OpenAI API 기반 서비스에서 매 요청마다 발생하는 사용량 추적으로 인한 성능 병목 문제를 해결하기 위한 Redis 하이브리드 아키텍처를 제안한다. AWS, Stripe, GitHub 등 주요 서비스의 사례를 분석하고, 전통적인 DB 직접 업데이트 방식 대비 80% 이상의 응답 시간 개선과 10배의 처리량 증가를 달성할 수 있는 설계 방안을 제시한다. 실시간 Redis 캐싱과 주기적 DB 동기화를 결합한 하이브리드 접근법을 통해 데이터 일관성을 유지하면서도 높은 성능을 확보하는 구체적인 구현 방법과 운영 가이드를 포함한다.\n---\n\n## 1. 문제 상황\n\n현대의 API 기반 서비스에서 사용량 추적과 관리는 필수적인 요소가 되었다. 특히 OpenAI와 같은 외부 API를 활용하는 서비스에서는 사용자별 사용량을 정확하게 모니터링하고 제한을 적용하는 것이 비즈니스 모델의 핵심이다. 하지만 매 요청마다 데이터베이스를 조회하고 업데이트하는 전통적인 방식은 높은 트래픽 환경에서 심각한 성능 병목을 야기할 수 있다.\n\n### 서비스 구조\n\n본 글에서 다루는 시나리오는 OpenAI API를 활용한 챗봇과 보고서 생성 서비스로, 다음과 같은 구조를 가진다:\n\n- **기본 크레딧 제공**: 서비스에서 제공하는 API 크레딧을 우선 사용\n- **개인 키 지원**: 크레딧 부족 시 사용자의 OpenAI API 키로 전환\n- **통합 사용량 추적**: 어떤 키를 사용하든 모든 사용량을 추적하여 통계 및 과금에 활용\n\n### 성능 병목의 발생\n\n서비스 규모가 커지면서 사용량 추적 과정에서 심각한 성능 저하가 발생하기 시작했다. 매 요청마다 사용량을 확인하고 업데이트하는 과정이 전체 시스템의 병목이 되었다.\n\n```mermaid\ngraph TD\n    A[사용자 요청] --> B[OpenAI API 호출]\n    B --> C[사용량 계산]\n    C --> D[사용량 추적/저장]\n    D --> E[응답 반환]\n```\n\n### 전통적 접근법의 문제"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2024-03-25-Linux 환경 구축하기.md",
    "title": "Linux 환경 구축 방법 비교",
    "description": "Docker, VM, WSL, 멀티부팅 등 다양한 Linux 환경 구축 방법의 장단점 비교",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Linux 개발 환경을 구축하는 4가지 주요 방법(Docker, 가상 머신, WSL, 멀티부팅)의 장단점을 비교 분석한다. Docker는 이식성과 경량성이 뛰어나고, VM은 완전한 격리를 제공하며, WSL은 Windows에서 Linux를 편리하게 사용할 수 있고, 멀티부팅은 시스템 자원을 최대로 활용한다. 각 방법의 특성을 이해하고 프로젝트 요구사항에 맞는 최적의 환경을 선택할 수 있다.\n\n## 리눅스 구축 방법\n#### 도커(Docker)\n\n- **장점**: 이식성 높음, 경량성, 개발-테스트-프로덕션 간 일관성\n- **단점**: 진입장벽이 있음, 시스템 요구사항 높을 수 있음\n\n#### 가상 머신(VM)\n\n- **장점**: 완전한 격리, 다양한 운영 체제 및 리눅스 배포판 지원\n- **단점**: 자원 사용 많음, 부팅 시간 길음\n\n#### WSL (Windows Subsystem for Linux)\n\n- **장점**: 윈도우에서 리눅스 명령어 및 애플리케이션 사용 용이, 성능 좋음\n- **단점**: 윈도우 한정, 일부 리눅스 기능 제한\n\n#### 멀티 부팅\n\n- **장점**: 리눅스와 다른 OS 간 완벽한 분리, 시스템 자원 최대 활용\n- **단점**: 재부팅 필요, 파티션 관리 필요, 데이터 공유 불편할 수 있음\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2023-07-13-AWS RDS 생성.md",
    "title": "AWS RDS MySQL 데이터베이스 생성 가이드",
    "description": "AWS RDS를 사용하여 MySQL 데이터베이스를 생성하고 설정하는 단계별 가이드",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> AWS RDS를 활용하여 팀 프로젝트에서 MySQL 데이터베이스를 공유하기 위한 설정 가이드이다. 계정 생성부터 데이터베이스 인스턴스 생성, 파라미터 그룹 설정(한국 시간대, UTF8MB4 인코딩), 인바운드 보안 그룹 규칙 설정까지 전 과정을 다룬다. 터미널과 DBeaver를 통한 접속 확인 방법도 포함하여 실무에서 바로 활용 가능한 완전한 가이드를 제공한다.\n\n# Intro\n프로젝트중 AWS RDS를 사용해 팀원들끼리 원활하게 데이터베이스를 공유하고자 한다.\n\n\n# AWS RDS 생성\n## 1. 계정 생성\n\n### 1-1. AWS에 접속 후 회원가입 진행\n[https://aws.amazon.com/](https://aws.amazon.com/)\n- 신용카드 인증\n- 핸드폰 인증\n등이 필요한데 굉장히 귀찮다,,\n\n\n### 1-2. 계정 생성 후 첫화면\n![](https://velog.velcdn.com/images/syshin0116/post/c371214a-7e1c-4ced-b67d-4a98213fc47b/image.png)\n\n### 1-3. 지역 변경\n\n최초 계정이 생성되면 지역이 N.California로 설정되있다. 우리에게 가까운 Seoul지역으로 변경하자.\n\n![](https://velog.velcdn.com/images/syshin0116/post/144f2f56-9524-47ff-b14a-7c573773af50/image.png)\n\n## 2. 데이터베이스 생성\n### 2-1. RDS Service로 이동\n\n![](https://velog.velcdn.com/images/syshin0116/post/071bd6c5-5fe8-4ea2-87b8-dbfb7a31bd68/image.png)\n\n### 2-2. 데이터베이스 생성 클릭\n\n![](https://velog.velcdn.com/images/syshin0116/post/1739ef17-7df6-4b4e-8bdf-f9eb62528aa1/image.png)\n\n\n### 2-3"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2024-12-25-DuckDB.md",
    "title": "DuckDB",
    "description": "DuckDB는 분석 작업에 최적화된 경량형 임베디드 데이터베이스로, 강력한 성능과 사용 편의성을 제공한다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> DuckDB는 분석 작업을 위한 경량형 임베디드 데이터베이스로, SQL 쿼리를 통해 대규모 데이터를 효율적으로 처리한다. 컬럼 지향 저장 방식과 병렬 처리를 통해 단일 머신에서도 뛰어난 성능을 제공한다.\n\n## DuckDB란?\n\nDuckDB는 OLAP(Online Analytical Processing) 작업을 위해 설계된 경량형 임베디드 데이터베이스로, \"분석을 위한 SQLite\"라고 불린다. C++로 작성되어 고성능 쿼리 처리를 지원하며, 단일 파일 기반으로 별도의 설치나 설정 없이 사용할 수 있다. SQL 표준을 준수하며 직관적이고 강력한 SQL 쿼리 언어를 제공한다.\n\nDuckDB는 데이터 과학자와 분석가들이 대용량 데이터를 효율적으로 처리하기 위한 도구로, 특히 [[데이터 분석]] 워크플로우를 간소화하는 데 큰 도움이 된다.\n\n---\n\n## DuckDB의 주요 특징\n\n### 로컬 기반 데이터베이스\n\nDuckDB는 in-process 데이터베이스로 단일 파일 기반(SQLite와 비슷)이다.\n\n- 외부 의존성이 없어 별도의 설치나 설정 없이 바로 사용 가능하다\n- 클라이언트-서버 모델([[PostgreSQL]] 등)과 달리 네트워크 연결이나 추가 설정이 필요하지 않다\n- 데이터베이스가 애플리케이션 내부에 포함되어 있어 로컬 데이터 분석에 최적화되어 있다\n- 데이터 전송이 불필요하여 로컬 설치 환경에서 더 빠르게 작동한다\n\n### 고성능 분석 처리\n\nDuckDB는 OLAP 작업을 위해 고도로 최적화되어 있다.\n\n> [!Note]\n> OLAP(Online Analytical Processing)는 대량의 데이터를 분석하고 집계하는 데 최적화된 데이터 처리 방식이다. 비즈니스 인텔리전스와 데이터 분석에 주로 사용된다.\n\n- 컬럼 지향 저장 방식을 사용해 집계, 조인, 읽기 작업을 빠르게 처리한다\n- 벡터화된 쿼리 실행 방식을 통해 CPU 활용을 극대화하며, 다중 CPU 코어를 병렬로 활용할 수 있다\n- [[Pandas]]와 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2024-03-28-통합 프로젝트 기술.md",
    "title": "통합 프로젝트 기술 스택 및 아키텍처",
    "description": "Redis, ChromaDB, Nginx, Docker, Flask 등을 활용한 통합 프로젝트의 기술 스택 구성과 흐름",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 실제 통합 프로젝트에서 사용한 기술 스택들을 데이터 관리, 웹 서버, 애플리케이션 배포, 개발 및 협업 도구로 분류하여 정리한다. Redis를 캐싱에, ChromaDB를 벡터 데이터베이스로, Nginx를 리버스 프록시로, Docker를 컨테이너화에 활용하며, Flask로 웹 애플리케이션을 개발하고 Jenkins와 GitLab으로 CI/CD를 구축한다. 코드 개발부터 배포까지의 전체 흐름을 체계적으로 설명한다.\n\n## 기술 스택 정리\n\n#### Redis\n- 인메모리 데이터 구조 저장소\n- 캐싱, 메시지 브로커, 세션 관리 등에 활용\n#### ChromaDB\n- 벡터 데이터베이스\n- 자연어 처리 모델 관련 대규모 데이터 저장 및 검색\n#### Nginx\n- 웹 서버 및 리버스 프록시\n- 클라이언트 요청 처리 및 백엔드 애플리케이션 전달\n#### Docker\n- 컨테이너 기술\n- 애플리케이션 패키징 및 배포\n#### Flask\n- Python 웹 프레임워크\n- 백엔드 API 및 웹 애플리케이션 개발\n#### Jenkins\n- 지속적 통합/배포(CI/CD) 도구\n- 빌드, 테스트, 배포 프로세스 자동화\n#### GitLab\n- 소스 코드 관리 및 버전 관리\n- Git 기반 저장소 및 협업 도구\n#### Gunicorn\n- Python WSGI HTTP 서버\n- Flask 애플리케이션 실행 및 Nginx 연동\n#### MySQL\n- 관계형 데이터베이스\n- 구조화된 데이터 저장 및 관리\n#### LangChain\n- 대규모 언어 모델 프레임워크\n- 언어 모델 쉽게 활용 가능\n\n\n## 기술 스택 분류\n### 개발 및 데이터 관리\n\n- **Redis**: 인-메모리 데이터 저장소, 주로 캐싱과 메시지 브로킹에 활용\n- **MySQL**: 관계형 데이터베이스 관리 시스템, 데이터 저장과 관리 담당\n- **ChromaDB**: 가정된 데이터베이스, 특화된 데이터(예: 컬러 정보, 이미지 데이터) 관리\n\n### 웹 서버 및 애플리케이션 배포\n\n- "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2024-03-31-Supervisord.md",
    "title": "Supervisord를 활용한 프로세스 관리",
    "description": "Supervisord를 사용한 Flask, Celery, Redis 등 다중 프로세스 관리 및 문제 해결",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Supervisord는 UNIX 시스템에서 여러 프로세스를 모니터링하고 제어하는 도구로, 웹 서버나 백그라운드 작업 등 지속 실행 프로세스의 자동 시작, 재시작, 로깅을 관리한다. 프로젝트에서 Flask, Celery, Redis를 Docker 컨테이너 내에서 효율적으로 관리하기 위해 Supervisord를 도입했으며, Celery-Redis 연결 문제와 로깅 문제를 supervisord.conf 설정을 통해 해결했다. 웹 인터페이스와 CLI를 제공하여 편리한 프로세스 관리가 가능하다.\n\nSupervisord는 UNIX 계열 운영 시스템에서 여러 프로세스를 모니터링하고 제어하는 클라이언트/서버 시스템으로, 주로 긴 실행 시간을 요하는 프로세스들의 시작, 유지 관리 및 로깅을 관리하는 데 사용된다\n\n## 프로세스 관리의 필요성\n\n웹 서버, 작업 큐, 백그라운드 작업 등 지속적으로 실행되어야 하는 프로세스들의 관리를 자동화함으로써, 수동으로 서비스를 재시작하는 번거로움 없이 항상 실행 상태를 유지할 수 있다\n\n### 설정 파일\n\n`supervisord.conf` 설정 파일을 통해 각 프로세스의 시작 방법, 로그 파일 위치, 프로세스가 충돌했을 때의 대응 방식 등을 정의한다 이를 통해 사용자는 세밀한 제어와 함께 효율적인 프로세스 관리를 할 수 있다\n\n### 자동 시작 및 재시작\n\nSupervisord는 설정에 따라 자동으로 프로세스를 시작할 수 있으며, 예상치 못한 종료 후에는 자동으로 재시작한다 이는 시스템의 안정성을 크게 향상시킨다\n\n### 로깅\n\n프로세스에서 발생하는 stdout과 stderr 출력을 캡처하여 파일로 로깅할 수 있으며, 이는 디버깅과 모니터링에 매우 유용하다\n\n### 웹 인터페이스\n\n설정을 통해 활성화할 수 있는 웹 기반 인터페이스를 통해 사용자는 프로세스 상태를 확인하고, 프로세스를 시작/중지할 수 있으며, 로그 파일을 직접 읽을 수 있다\n\n### 커맨드라인 인터페이스\n\nSupervisorctl은 Supervi"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/Monkey Patching.md",
    "title": "Monkey Patching",
    "description": "몽키 패칭(Monkey Patching)의 개념, 장단점, 활용 사례를 설명하고 런타임에 코드를 수정하는 기법의 실제 적용 방법 소개",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 몽키 패칭(Monkey Patching)은 프로그램 실행 중에 코드를 동적으로 수정하거나 확장하는 강력한 기법이다. 라이브러리나 모듈의 함수를 직접 수정하지 않고도 그 동작을 변경할 수 있어 버그 수정, 기능 추가, 테스트 등에 유용하지만, 코드 가독성과 유지보수성을 해칠 수 있어 신중하게 사용해야 한다.\n\n## 개요\n\n[google-play-scraper](https://github.com/JoMingyu/google-play-scraper) 사용법을 익히다가 해당 라이브러리의 문제점을 유저들이 `Monkey Patching` 기법을 사용해 피해가는 걸 보았다. 최근 진행중인 프로젝트에서도 라이브러리에서 제공하지 않는 기능들을 직접 추가해야 했는데, 몽키 패치를 사용하면 좀 더 간단하게 추가할 수 있었을 것 같다. 이 문서에서는 몽키 패칭의 개념, 사용법, 장단점을 살펴본다.\n\n---\n\n## Monkey Patch란?\n\n몽키 패치(Monkey Patch)란 런타임에 기존의 코드를 수정하거나 확장하는 기법이다. 이를 통해 라이브러리나 모듈의 함수, 메서드, 속성 등을 직접 수정하지 않고도 동적으로 변경할 수 있다. \n\n### 몽키 패칭의 정의와 유래\n\n'몽키 패치'라는 용어는 원래 'Guerrilla Patch'(게릴라 패치)에서 파생되었다. 이는 정규 업데이트 채널을 통하지 않고 코드를 변경하는 것을 의미했다. 시간이 지나면서 'Guerrilla'가 'Gorilla'로 잘못 발음되었고, 결국 'Monkey'로 변경되어 현재의 용어가 되었다.\n\n### 언어별 지원 현황\n\n몽키 패칭은 주로 동적 타입 언어에서 가능하며, 다음과 같은 언어들이 이를 지원한다:\n\n- **Python**: 가장 널리 사용되며 런타임에 모든 객체를 수정할 수 있다\n- **JavaScript**: 프로토타입 기반 언어로 객체와 함수를 쉽게 수정할 수 있다\n- **Ruby**: 메타프로그래밍 기능을 통해 클래스와 메서드를 동적으로 수정할 수 있다\n- **"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2025-05-24-Supabase-NextJS.md",
    "title": "Supabase-NextJS",
    "description": "Supabase와 NextJS를 활용한 풀스택 웹 애플리케이션 개발 완전 가이드",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> Supabase와 NextJS는 현대적인 풀스택 웹 애플리케이션 개발을 위한 이상적인 조합이다. Supabase는 PostgreSQL 기반 오픈소스 Firebase 대안으로 실시간 데이터베이스, 인증, 스토리지를 제공하며, NextJS는 React 기반 프로덕션 프레임워크다. `npx create-next-app -e with-supabase` 템플릿을 사용하면 Cookie-based 인증, TypeScript, Tailwind CSS가 사전 구성된 프로젝트를 즉시 시작할 수 있다. 이 템플릿에는 모든 기본 설정이 포함되어 있어 복잡한 설정 없이 바로 개발에 집중할 수 있으며, 필요한 부분만 기존 프로젝트에 이식하는 것도 가능하다.\n\n## Supabase + NextJS 소개\n\n[[Hostit]]이라는 사이드 프로젝트를 효율적으로 빠르게 진행할겸, 최신 유행하는 기술들을 사용해보려는 취지로 리서치하던 중 이 조합을 찾게 되었다. [[Hostit 개요|Hostit]]은 LangChain의 Model Context Protocol(MCP)을 활용한 AI 도구 관리 플랫폼으로, 사용자 인증, 서버 관리, 실시간 데이터 동기화 등 복잡한 백엔드 기능이 필요한 프로젝트였다.\n\nSupabase와 NextJS의 조합이 매력적인 이유는 복잡한 설정 없이도 강력한 풀스택 애플리케이션을 빠르게 구축할 수 있기 때문이다. 특히 `with-supabase` 템플릿을 사용하면 모든 기본 설정이 이미 완료된 상태로 시작할 수 있어 매우 편리하다.\n\n> [!info] 핵심 장점\n> - **즉시 사용 가능**: 템플릿으로 5분 안에 프로젝트 시작\n> - **PostgreSQL**: 강력한 SQL 데이터베이스와 실시간 기능\n> - **인증 완료**: 이메일/비밀번호, 소셜 로그인 사전 구성\n> - **타입 안전성**: TypeScript와 자동 타입 생성 지원\n> - **Zero Config**: 복잡한 백엔드 설정 불필요\n\n[[Hostit 구조|Hosti"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2024-09-23-GCP VSCODE SSH 연결 방법.md",
    "title": "GCP VM과 VS Code SSH 연결 설정 가이드",
    "description": "Google Cloud Platform VM 인스턴스에 SSH 키를 생성하고 VS Code로 원격 연결하는 방법",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> GCP(Google Cloud Platform) VM 인스턴스에 SSH 키 페어를 생성하고 등록하여 VS Code에서 원격 접속하는 전체 과정을 설명한다. ssh-keygen으로 로컬에서 키를 생성하고, GCP Console에서 공개 키를 VM에 등록한 후, VS Code의 Remote Explorer 설정을 통해 편리하게 원격 개발 환경을 구축할 수 있다. 터미널과 VS Code 두 가지 방법으로 접속을 확인한다.\n\n### Metadata-managed SSH connections\nhttps://cloud.google.com/compute/docs/instances/ssh#third-party-tools\n\n\n### Create an SSH key pair\nhttps://cloud.google.com/compute/docs/connect/create-ssh-keys#console\n\n\n\n## SSH 키 페어 생성\n\n#### Mac/Linux 유저:\n\n```shell\nssh-keygen -t rsa -f ~/.ssh/KEY_FILENAME -C USERNAME\n```\n\n\n### Windows 유저\n```shell\nssh-keygen -t rsa -f C:\\Users\\WINDOWS_USER\\.ssh\\KEY_FILENAME -C USERNAME\n```\n\n다음을 대체하세요:\n\n- `KEY_FILENAME`: SSH 키 파일의 이름입니다. 예를 들어, `my-ssh-key`라는 파일 이름은 `my-ssh-key`라는 개인 키 파일과 `my-ssh-key.pub`이라는 공개 키 파일을 생성합니다.\n- `USERNAME`: VM에서의 사용자 이름입니다. 예를 들어, `cloudysanfrancisco` 또는 `cloudysanfrancisco_gmail_com`과 같습니다. Linux VM의 경우, VM이 root 로그인을 허용하도록 구성하지 않는 한 `USERNAME`은 `root`가 될 수 없습니다. 자세한 내용은 [root 사용자로 VM에"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Dev/2023-08-27-기술 정리.md",
    "title": "개발 기술 스택 종합 정리",
    "description": "데이터베이스, 백엔드, 프론트엔드, 배포 및 인프라 기술 스택에 대한 종합 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 현대 웹 개발에서 사용되는 주요 기술 스택을 카테고리별로 정리한 참고 자료이다. 관계형 데이터베이스(PostgreSQL, MySQL)와 NoSQL(MongoDB, Redis, Cassandra), 백엔드 프레임워크(Django, Flask, Spring Boot), 프론트엔드 라이브러리(React, Vue.js, Angular), 그리고 클라우드 및 컨테이너 기술(Docker, Kubernetes, AWS, GCP, Azure)까지 각 기술의 핵심 특징과 장점을 체계적으로 다룬다.\n\n## 데이터베이스 (DB):\n\n### 관계형 데이터베이스 (RDBMS):\n#### PostgreSQL:\n- 오픈 소스 RDBMS: JSON 지원, 풀 텍스트 검색, 저장 프로시저 등의 고급 기능을 포함한다\n- 대규모 데이터 처리: 복잡한 쿼리 처리와 대규모 데이터 저장에 적합하다\n- 확장성: 여러 확장 기능과 플러그인을 통해 기능을 확장할 수 있다\n- 안정성: 트랜잭션, 백업, 복구 기능을 지원하여 데이터의 안정성을 보장한다\n- 다양한 운영체제 지원: Linux, Windows, macOS 등 다양한 운영체제에서 사용할 수 있다\n\n#### MySQL:\n- 오픈 소스 RDBMS: 웹 애플리케이션에 널리 사용되며, 플러그인 아키텍처, 저장 프로시저 등의 특징을 포함한다\n- JSON 지원: JSON 형식의 데이터를 저장하고 검색할 수 있다\n- 확장성: 여러 플러그인과 확장을 통해 기능을 확장할 수 있다\n- 안정성: 트랜잭션, 백업, 복구 기능을 지원하여 데이터의 안정성을 보장한다\n- 커뮤니티 및 상업 버전: 무료 커뮤니티 버전과 엔터프라이즈 기능을 제공하는 상업 버전이 있다\n\n#### SQLite:\n- 경량화된 데이터베이스: 디스크 기반의 데이터베이스로, 서버 설치나 설정이 필요 없다\n- 독립성: 외부 의존성 없이 동작하며, 애플리케이션에 내장 가능하다\n- 트랜잭션 지원: ACID 트랜잭션을 지원한다\n- 다양한 플랫폼 지원: 모바일 앱, 데스크톱 앱, 임베"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/자바의정석-2장-변수.md",
    "title": "자바의정석-2장-변수",
    "description": "자바의 정석 교재 2장 변수 파트의 연습문제와 해설, 기본형 데이터 타입과 변수 선언 방법 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 자바의 정석 2장 변수(Variables) 파트의 연습문제와 해설이다. 자바의 8가지 기본형(primitive type) 데이터 타입과 특성, 변수 선언 방법, 형변환 규칙 등을 다룬다. 각 문제를 통해 변수의 개념과 자바 언어의 데이터 타입 시스템을 체계적으로 이해할 수 있다.\n\n## 연습문제\n\n### 2-1. 기본형(primitive type) 분류\n다음 표의 빈칸에 8개의 기본형(primitive type)을 알맞은 자리에 넣으시오.\n\n| 종류 / 크기 | 1 byte  | 2 byte | 4 byte | 8 byte |\n| ----------- | ------- | ------ | ------ | ------ |\n| 논리형      | boolean |        |        |        |\n| 문자형      |         | char   |        |        |\n| 정수형      | byte    | short  | int    | long   |\n| 실수형      |         |        | float  | double |\n\n### 2-2. 적절한 데이터 타입 선택\n주민등록번호를 숫자로 저장하고자 한다. 이 값을 저장하기 위해서는 어떤 자료형(data type)을 선택해야 할까? regNo라는 이름의 변수를 선언하고 자신의 주민등록번호로 초기화하는 한 줄의 코드를 적으시오.\n\n```java\nString regNo = \"012345-6789012\";\n```\n\n### 2-3. 프로그래밍 요소 구분\n다음의 문장에서 리터럴, 변수, 상수, 키워드를 적으시오.\n\n```java\nint i = 100;  \nlong l = 100L;  \nfinal float PI = 3.14f;\n```\n\n- **리터럴**: 100, 100L, 3.14f\n- **변수**: `i`, `l`\n- **키워드**: `int`, `long`, `final`, `float`\n- **상수**: `PI`\n\n### 2-4. "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/알고리즘 대회에 필요한 수학.md",
    "title": "알고리즘 대회에 필요한 수학",
    "description": "알고리즘 대회에서 필요한 수학적 개념과 기법들에 대한 정리. 이산수학, 점화식, 이항계수, 확률, 정수론, 정렬 알고리즘 등 다양한 수학 개념 포함",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 알고리즘 대회에서 자주 활용되는 핵심 수학 개념들을 정리한 문서이다. 이산 수학의 점화식 풀이 기법, 이항계수, 확률론, 정수론, 조합론적 게임 이론 등의 주제를 다룬다. 각 주제별로 문제 해결에 활용할 수 있는 구체적인 알고리즘과 공식을 제공한다.\n\n출처: [알고리즘 대회에 필요한 수학](https://algospot.com/wiki/read/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98_%EB%8C%80%ED%9A%8C%EC%97%90_%ED%95%84%EC%9A%94%ED%95%9C_%EC%88%98%ED%95%99) "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/프라임칼리지 수업 정리.md",
    "title": "프라임칼리지 수업 정리",
    "description": "3-1학기 프라임칼리지 수강 과목 및 수업 내용 정리, 데이터공학, 머신러닝응용, 선형대수, 컴퓨터C프로그래밍, 클라우드컴퓨팅, 파이썬과R을이용한데이터분석",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> \n> 3-1학기에 프라임칼리지에서 수강한 6개 과목(데이터공학, 머신러닝응용, 선형대수, 컴퓨터C프로그래밍, 클라우드컴퓨팅, 파이썬과R을이용한데이터분석)에 대한 강의 내용, 교육 목표, 평가 기준 등을 정리한 문서이다. 각 과목별 주차별 강의 내용과 평가 방식을 체계적으로 기록하였다.\n\n## 수강 과목\n\n- 수강 학점: 전공 18학점\n\n| No. | 교과목            | 분반  | 학점  | 이수구분 | 교수명 |\n| --- | -------------- | --- | --- | ---- | --- |\n| 1   | 데이터공학          | 01  | 3   | 전공   | 민경하 |\n| 2   | 머신러닝응용         | 01  | 3   | 전공   | 김동하 |\n| 3   | 선형대수           | 01  | 3   | 전공   | 유찬우 |\n| 4   | 컴퓨터C프로그래밍      | 01  | 3   | 전공   | 조경운 |\n| 5   | 클라우드컴퓨팅        | 01  | 3   | 전공   | 정재화 |\n| 6   | 파이썬과R을이용한데이터분석 | 01  | 3   | 전공   | 유찬우 | "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/PPV and PARA.md",
    "title": "PPV and PARA",
    "description": "PPV와 PARA 지식 관리 시스템의 개념과 구조를 비교 설명",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n> [!summary]\n> \n> 이 문서는 두 가지 주요 지식 관리 시스템인 PPV(Pillars, Pipelines, Vaults)와 PARA(Projects, Areas, Resources, Archives)의 개념과 특징을 비교 설명한다. PPV는 조직이나 시스템의 성공적 운영을 위한 세 가지 핵심 구성요소를 나타내며, PARA는 Tiago Forte가 개발한 개인 지식 관리를 위한 체계적 방법론이다. 두 시스템 모두 정보를 구조화하고 효율적으로 관리하는 방법을 제공하지만, 각각의 초점과 적용 영역에 차이가 있다.\n\n## 개요\n\n최근 관심을 갖게 된 PARA를 노션 팀 프로젝트 페이지에 적용할 수 있는지 고민하던 중, 우연히 유튜브에서 PPV 방법론을 접하게 되었다. 이 문서에서는 두 시스템을 비교하여 각각의 장단점과 적용 방안을 살펴본다.\n\n---\n\n## PPV(Pillars, Pipelines, Vaults) 시스템\n\nPPV는 조직이나 경영 관련 문맥에서 시스템이나 프로세스의 성공과 원활한 운영에 중요한 세 가지 구성요소를 나타낸다. 각 요소는 특정한 측면을 대표한다.\n\n![PPV 시스템 구조](https://i.imgur.com/placeholder-for-ppv.png)\n\n### Pillars (기둥)\nPillars는 조직이나 시스템을 이끄는 기본 원칙, 핵심 가치, 또는 전반적인 목표를 상징한다. 이는 다음과 같은 특징을 가진다:\n\n- 조직 또는 개인이 달성하려는 주요 목표 제시\n- 비전과 미션을 포함한 이상적인 가치 표현\n- 의사결정의 기준이 되는 원칙 제공\n\n### Pipelines (파이프라인)\nPipelines는 자원, 정보, 또는 활동의 이동, 흐름, 또는 변환을 원활하게 하는 프로세스, 작업 흐름, 또는 시스템을 나타낸다:\n\n- 작업이나 제품 또는 서비스를 제공하기 위한 단계 정의\n- 효율적인 정보 및 작업 흐름 제공\n- 프로세스 최적화를 통한 생산성 향상\n\n### Vaults (금고)\nVaults는 중요한 자원, 데이터, 또는 정보"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/정보처리기사/2023-07-05-소프트웨어 공학.md",
    "title": "[정보처리기사]1과목 소프트웨어 구축-1.소프트웨어 공학",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n# 1과목. 소프트웨어 구축 - 1.소프트웨어 공학\n\n## 1. 소프트웨어 공학\n정의: 소프트웨어 위기를 극복하고 효율적으로 품질 높은 소프트웨어를 개발하기 위한 학문\n\n#정처기중요 \n## 2. 소프트웨어 공학의 3R\n완성된 소프트웨어를 기반으로 역공학, 재공학, 재사용을 통해 소프트웨어 생산성을 극대화하는 방법\n\n### 역공학(Reverse-Engineering)\n- 기존 개발된 소프트웨어를 CASE(Computer Aided Software Engineering)도구를 이용하여 요구분석서, 설계서 등의 문서로 추출\n\n### 재공학(Re-Engineering)\n- 기존 소프트웨어를 폐기하지 않고 기능을 개선시키거나 새로운 소프트웨어로 재활용\n- 예방 유지보수(Preventitive Maintenance)\n- 분석(Anaylysis)-재구성(Restructuring)-역공학(Reverse Engineering)-이관(Migration)\n\n### 재사용(Re-use)\n- 이미 개발된 소프트웨어의 전체나 일부분을 재사용\n- 함수와 객체 재사용, 컴포넌트 재사용, 애플리케이션 재사용\n- 재사용 방법:\n\t- 합성 중심(Composition Based, 블록 구성): 블록(모듈)을 끼워 맞추는 방식\n\t- 생성 중심(Gernation Based, 패턴 구성): 추상화 형태로 쓰여진 명세를 구체화하여 프로그램을 만드는 방식\n\n\n## 3. 소프트웨어 개발 단계\n계획-분석-설계-구현-테스트-유지보수\n\n### 1. 계획\n- 개발 주체, 범위 정의 및 결정\n- 비용과 기간 예측\n\n### 2. 요구사항 분석(Requirements Analysis)\n- 기능, 제약조건, 목표등을 고객과 함께 정의\n- 요구사항의 정확한 이해와 요구사항 유도\n- 고객의 요구를 명확히 이해\n\n### 3. 소프트웨어 설계(Design)\n- 모델링\n- 요구사항을 기준으로 입력자료, 처리내용, 출력자료등을 정리\n- 시스템 구조 설계, 프로그램 설계, 사용자 인터페이스 설계\n\n### 4. 구현(Developm"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/정보처리기사/2023-07-21-정처기-3과목-운영체제.md",
    "title": "[정보처리기사]3과목 운영체제",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# Chapter 01. 운영체제 기초\n\n## Section 1. 운영체제 기초\n\n### 기억장치\n- 데이터, 프로그램, 연산의 중간 결과 등을 일시적 또는 영구적으로 저장하는 장치\n\n#### 기억장치의 종류\n1. 레지스터\n2. 캐시 메모리\n3. 주기억장치\n\t- ROM(Read Only Memory)\n\t- RAM(Random Access Memory)\n\t\t- SRAM: 전원이 공급되는 중에 내요이 사라지지 않음\n\t\t- DRAM: 일반적인 주기억장치, 일정 시간이 지나면 내용이 사라짐\n4. 보조기억장치\n\t- HDD, SSD, CD, USB, 플로피디스크\n5. 연관 메모리\n\t- 주소에 의해 접근하지 않고, 기억된 내용의 일부를 이용하여 Access할 수 있는 기억장치\n\n\n### 시스템 소프트웨어\n- 응용 소프트웨어를 실행하기 위한 플랫폼을 제공\n- 컴퓨터 하드웨어를 동작하고 접근한다\n\n#### 시스템 소프트웨어의 종류\n- 로더\n- 링커\n- 유틸리티\n- 번역기(컴파일러, 어셈블러)\n- 장치 드라이버\n- 운영체제\n\n#### 시스템 소프트웨어의 구성\n\n#정처기중요 \n제어 프로그램\n- 감시 프로그램: 각종 프로그램의 실행과 시스템 전체의 작동 상태를 감시/감독하는 프로그램\n- 작업 관리 프로그램: 연속 처리를 위한 스케줄 및 시스템 자원 할당 등 담당\n- 데이터 관리 프로그램: 주기억/보조기억장치 사이의 자료전송, 파일의 조작 및 처리, 입출력 자료와 프로그램 간의 논리적 연결 등 처리할 수 있도록 관리\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/정보처리기사/2023-07-11-소프트웨어 설계.md",
    "title": "[정보처리기사]1과목 소프트웨어 구축-3.소프트웨어 설계",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# 1. 소프트웨어 설계의 기본원칙\n\n## 1. 소프트웨어 설계\n\n### 1. 소프트웨어 설계의 개념\n- 요구사항 명세서 참조 -> 소프트웨어 설계서 작성\n- Story Board(파워포인트), Wireframe(기획자랑 디자이너)\n\n### 2. 설계의 종류\n- 상위 설계: \n\t- 아키텍서 설계: 전체적인 구조 설계\n\t- 데이터 설계: 데이터베이스 설계\n\t- 인터페이스 정의: \n\t- 사용자 인터페이스 설계: 사용자 화면 설계(UI/UX)\n- 하위 설계: \n\t- 모듈 설계\n\t- 자료구조 설계\n\t- 알고리즘 설계\n\n### 3. 설계의 원리\n1. 분할과 정복(Divide & Conquer)\n2. 추상화(Abstraction)\n\t- 과정 추상화: 흐름만 먼저 설계\n\t- 데이터 추상화: 데이터 구조\n\t- 제어 추상화: 여러 명령어를 간단한 표현으로 대체\n3. 단계적 분해(Gradual Decomposition)\n4. 모듈화(Modulization)\n5. 정보 은닉(Information Hiding)\n\t- 캡슐화와 밀접한 관계\n\n## 2. 설계 모델링\n### 1. 개념\n- 소프트웨어를 구성하는 모듈들을 식별하고, 연결을 그림으로 표현한 것\n- 보기 쉬운 그림과 설명으로 문서화\n\n### 2. 원칙\n- 변경이 용이하도록 구조화시켜야 한다\n- 필요한 자료만을 사용\n- 요구사항 분석에 얻은 정보를 이용하여 명확히 표현\n- 모듈 단위로 설계\n\n### 3. 유형\n- 구조 모델링(정적 모델링)\n\t- 구조적 관계와 특성 위주\n\t- UML 정적 다이어그램\n- 행위 모델링(동적 모델링)\n\t- 어떤 순서로 기능 수행하는지 위주\n\t- 유즈케이스 다이어그램, 액티비티 다이어그램, 상태 다이어그램\n\n### 4. 소프트웨어 설계 절차 및 유형\n- 아키텍처 설계: 전체적인 구조\n- 데이터베이스 설계\n- 서브시스템 설계\n- 컴포넌트 설계\n- 자료구조와 알고리즘 설계\n- 협약의 의한 설계\n\t- 클래스에 대한 여러 가정을 공유하도록 명세\n\t- 선행 조건: 사용전에 이루어져야할 조건\n\t- 결과 조건: "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/정보처리기사/2023-07-05-소프트웨어 개발 방법론.md",
    "title": "[정보처리기사]1과목 소프트웨어 구축-2.소프트웨어 개발 방법론",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n[[2023-07-05-소프트웨어 공학]]\n# 1과목. 소프트웨어 구축 - 2.소프트웨어 개발 방법론\n\n## 소프트웨어 생명주기 (SDLC): Software Development Life Cycle)\n1. 요구사항 분석\n\t- 기능 요구사항, 비기능 요구사항\n2. 설계\n\t- 시스템 구조 설계, 프로그램 설계, 사용자 인터페이스 설계\n3. 구현\n\t- 인터페이스 개발, 자료구조 개발, 오류 처리\n4. 테스트\n\t- 단위 테스트, 통합 테스트, 시스템 테스트, 인수 테스트\n5. 유지보수\n\t- 예방, 완전, 교정, 적응 유지보수\n\n## 1. 소프트웨어 개발 방법론 개념\n- 소프트웨어 개발에 필요한 과정(절차, 방법, 산출물, 기법, 도구)들을 체계적으로 정리\n\n## 2. 소프트웨어 개발 방법론 종류\n### 1.  구조적 방법론\n- 절차지향 개발 방법론\n- 하향식\n- 데이터 흐름도(DFD), 자료사전(DD), 상태전이도(STD), 소단위 명세서(Minispec)\n\n### 2. 정보공학 방법론\n- 기업에서 사용하는 데이터 중심 방법론\n- 기업의 경영 전략에 초점을 둠\n\n### 3. 객체지향 방법론\n- 현실 개체(Entity)를 속성(Attribute)과 메소드(Method)형태로 표현\n- 분석과 설계, 구현의 전 과정을 객체 중심으로 개발\n- 특징: 캡슐화, 정보은닉, 상속, 다형성, 추상화\n\n### 4. CBD(Component Based Development) 분석 방법론\n- 컴포넌트별로 개발 후 하나의 어플리케이션으로 조합하는 방법\n- 기능추가 용이, 생산성 및 품질 향상, 유지보수 비용 최소화(잘 만들었을때ㅋㅋ;)\n\n### 5. 애자일 방법론\n- 기존 방법론들과는 달리 절차를 중요시 하지 않음, 변화에 빠른 대응 가능\n- XP(eXtreme Programming), SCRUM, FDD, Crystal\n\n### 6. 개발 방법론 선택 기준\n- 프로젝트 특성 및 규모\n- 참여자 수준\n- 가용 자원(인력, 장비, 시간, 비용)\n- 요구사항의 정확도\n- 위험도\n\n> 기본"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/정보처리기사/2023-07-16-화면 설계.md",
    "title": "[정보처리기사]1과목 소프트웨어 구축-4.화면 설계",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# Section 1. UI 설계\n\n## 1. UI User Interface 개념\n\n### UI 유형\n- CLI(Command Line Interface), CUI\n- GUI(Graphical User Interface)\n- NUI(Natural User Interface): 인간의 자연스러운 움직임\n- OUI(Organic User Interface): 현실의 모든 것\n\n## 2. UI 설계\n### 1. UI 요구사항 구분\n#### 1. 기능적 요구사항\n- 시스템이 제공해야 하는 기능에 대한 요구사항\n- 입력, 출력, 데이터, 연산에 관한 요구사항\n#### 2. 비기능적 요구사항\n- 사용성, 효율성, 신뢰성, 유지 보수성, 재사용성 등 품질에 관한 요구사항\n- 비용, 일정 등 프로젝트 계획에 관한 요구사항\n\n### 2. UI 설계 절차\n1. UI 개발목표 및 범위 수립\n2. UI 전략 수립\n3. 사용자 요구사항 분석\n4. UI 상세 설계\n5. 구현\n6. 테스트\n\n### 3. UI 설계 원칙(중요!)\n\n1. 직관성: 누구나 쉽게 이해하고 사용해야 한다\n2. 유효성: 사용자의 목적을 정확하게 달성해야 한다\n3. 학습성: 누구나 쉽게 배우고 익힐 수 있어야 한다\n4. 유연성: 사용자의 요구사항을 최대한 수용하며, 오류를 최소해야 한다\n\n\n### 4. UI 설계 도구\n1. 와이어프레임(Wireframe)\n2. 스토리보드(StoryBoard)\n3. 프로토타입(Prototype)\n4. 목업(Mockup)\n5. 유스케이스(Use-Case)\n\n\n## 3. 감성공학\n### 1. 감성공학의 개념\n- 인간의 심상을 구체적인 물리적 설꼐 요소로 번역하여 이를 실현하는 기술\n- 요소화 -> 형상화 -> 구현 -> 생산\n\n### 2. 제품과 관련된 인간의 감성\n1. 감각적 감성\n2. 기능적 감성\n3. 문화적 감성\n\n### 3. 감성공학의 접근 방법\n1. 1류 접근 방법\n2. 2류 접근 방법\n3. 3류 접근 방법\n\n\n# Section 2. UI 구현\n\n## 1. 화면 레이아웃 구"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/정보처리기사/2023-07-08-프로젝트 계획 및 분석.md",
    "title": "[정보처리기사]1과목 소프트웨어 구축-2.프로젝트 계획 및 분석",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n# 프로젝트 계획\n\n## 1. 프로젝트 관리\n\n프로젝트 핵심 관리대상(3P)\n- People(사람)\n- Problem(문제)\n- Process(프로세스))\n\nPMBOK(Project Management Body Of Knowledge)\n- PMI(Project Management Institute)에서 제작한 프로젝트 프로세스 및 지식 체계\n- 5단계 프로세스 그룹\n\t- 착수-계획-실행-통제-종료\n\n## 2. 개발 비용 산정\n### 1. 소프트웨어 계발 비용 계획\n- 개발에 소요되는 인원, 자원, 기간 등으로 소프트웨어의 규모를 파악하여 필요한 비용을 산정\n- 비용 계획 결정 요소 (개발자 역량, 소프트웨어 크기와 복잡도, 개발기간, 요구되는 신뢰도 & 기술 수준)\n- 비용 산정 기법\n\n| 기법 | 종류 |\n| --- | --- |\n| 하향식 산정 기법 | - 전문가 판단 기법 |\n| | - 델파이 기법|\n| 상향식 산정 기법 | - 원시 코드 라인수(LOC, Line of Code)|\n|  | - 개발 단계별 노력 기법 |\n| 수학적 산정 기법 | - COCOMO 기법 |\n| | - PUTNAM 기법 |\n| | - FP(기능 점수) 기법 |\n\n\n### 2. 하향식 산전 기법(Top-Down)\n#### 1) 전문가 기법\n- 조직 내 경험있는 전문가가 비용 산정\n\n#### 2) 델파이 기법\n- 여러 전문가의 의견을 종합하여 판단\n\n### 3. 상향식 산정 기법(Bottoms-Up)\n#### 1) LOC(원시코드 라인수) 기법\n- **비관치(가장 많은 라인 수), 낙관치(가장 적은 라인수), 중간치(평균 라인 수)**\n- LOC = 낙관치 + (4 * 중간치) + 비관치)/6\n\n#### 2) 단계별 인원수(MM)기법\n- LOC를 발전시켜 더 정확함\n\n### 4. 수학적 산정 기법 \n#### 1) COCOMO 기법\n- 개발할 S/W의 규모를 예측한 후 S/W 종류에 따라 각 비용 산정 공식에 대입하여 비용을 산정하는 기법\n- LOC 기법을 개발유형에 따라 다르게 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/정보처리기사/2023-07-16-서버 프로그램 구현.md",
    "title": "[정보처리기사]1과목 소프트웨어 구축-5. 서버 프로그램 구현",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# Section 1. 개발 환경 구축\n\n## 1. 서버 환경 구축\n### 1. 웹 서버(WEB)\n- 정적 파일(HTML, CSS, JS, 이미지)을 제공하는 웹서버 애플리케이션이 설치된 하드웨어\n- Apache Web Server, IIS, Nginx, GWS 등\n\n### 2. 웹 어플리케이션 서버(WAS)\n- 동적인 웹 서비스를 제공하기 위한 미들웨어가 설치된 하드웨어\n- 요청에 맞는 동적인 콘텐츠를 생성\n- DB조회나 다양한 로직 처리\n- Web Logic, Web Sphere, Jeus, Tomact등\n\n### 3. 데이터베이스 서버(DBMS)\n- 데이터의 저장과 관리를 위한 데이터베이스 소프트웨어가 설치된 하드웨어\n- ORacle, MySQL, MS-SQL 등\n\n### 4. 파일 서버\n- 사용자의 파일을 저장하고, 파일을 공유할 목적으로 구성된 하드웨어\n\n### 5. Load Balancer\n- 여러 대의 서버가 존재할 경우 요청을 분배해주는 역할\n- 분배 방식\n\t- Random\n\t- Least Loaded\n\t- Round Robin: 순서를 정하여 돌아가며 작업 분배\n\n### 6. CDN(Content Delievery Network)\n- 용량이 큰 컨텐츠 데이터(이미지, 비디오 등)를 빠른 속도로 제공하기 위해 사용자와 가까운 곳에 분산되어 있는 데이터 저장 서버\n- 클라이언트는 용량이 큰 콘텐츠 데이터를 가까운 CDN에 요청해 멀리 있는 웹서버에서 직접 받는것보다 빠르게 받을 수 있다\n\n> 투명성: 난 몰라도 된다~ 사용자가 알 필요없다\n\n### 7. 시스템 아키텍처 고려사항\n- 확장성: 클라이언트 수가 늘어났을 때 무리없이 요청을 처리할 수 있는 확장성을 고려\n- 성능: 요청한 내용을 정확하고 빠르게 제공\n- 응답 시간: 빠른 시간안에 요청\n- 처리량\n- 접근성\n- 일관성: 일정한 결과를 돌려주어야 한다\n\n## 2. 개발 소프트웨어 환경\n### 1. 시스템 소프트웨어\n1. 운영체제(OS, Operating System)\n2. JVM(Java"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/ADsP/2024-02-16-메타코드-ADSP-1과목.md",
    "title": "ADsP 제1과목 데이터의 이해 정리",
    "description": "ADsP 제1과목(데이터의 이해) 핵심 개념 정리 - 데이터/정보, 품질, 거버넌스",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> ADsP 제1과목 '데이터의 이해' 메타코드 강의 정리 노트이다. 데이터의 정의와 특성(정성적/정량적), DIKW 피라미드(Data-Information-Knowledge-Wisdom), 암묵지와 형식지의 상호작용(내공표연), 데이터베이스의 4가지 특징(통합/저장/공용/변화), 데이터 품질관리, 데이터 거버넌스와 마스터데이터 관리(MDM) 등 시험에 자주 출제되는 핵심 개념을 체계적으로 정리한다.\n\n영상 링크: [https://mcode.co.kr/video/list2?viewMode=view&idx=58](https://mcode.co.kr/video/list2?viewMode=view&idx=58)\n\n## 시험 정보\n\n- 객관식 50문항\n- 합격 기준: 총점 60점 이상\n- 과락 기준: 과목별 40% 미만 취득\n- 시험 시간: 90분\n\n#### 과목\n1. 데이터 이해 : 10문항\n\t- 데이터의 이해\n\t- 데이터의 가치와 미래\n\t- 가치 창조를 위한 데이터 사이언스와 전략 인사이트\n2. 데이터 분석 기획: 10문항\n\t- 데이터분석 기획의 이해\n\t- 분석 마스터 플랜\n3. 데이터 분석: 30문항\n\t- R기초와 데이터 마트\n\t- 통계분석\n\t- 정형 데이터 마이닝\n\n---\n\n# 1과목 - 데이터 이해\n\n## 데이터의 정의\n\n데이터의 이해\n- 데이터: 추론, 예측, 추정 등의 근거가 되는 사실\n- 가치창출의 기초\n\n데이터의 유형\n- 정성적 데이터: \n\t- 언어, 그림, 영상 등의 비정형 데이터\n\t- 비용/기술 많이 소요\n- 정량적 데이터:\n\t- 수치, 기호 등 구조화된 데이터\n\t- 저장, 분석 등에 쉽게 활용\n\n#### 데이터의 특성\n- 존재적 특성: 객관적 사실(Fact, Raw Material)\n- 당위적 특성: 추론, 예측, 전망, 추청을 위한 근거(Basis)\n\n| 구분 | 형태 | 예 | 특징 |\n| --- | --- | --- | --- |\n| 정성적 데이터<br>(Qualitative Data) | 언어, 문자 등 | 회사"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/ADsP/2024-02-20-메타코드-ADSP-2과목.md",
    "title": "ADsP 제2과목 데이터 분석 기획 정리",
    "description": "ADsP 제2과목(데이터 분석 기획) 핵심 개념 정리 - 과제 정의, 목표 설정, 관리 방안",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> ADsP 제2과목 '데이터 분석 기획' 메타코드 강의 정리 노트이다. 분석 기획의 4가지 유형(최적화/솔루션/통찰/탐색), 데이터 사이언티스트의 3대 역량(수학통계/IT기술/도메인 지식), 분석 방법론(KDD, CRISP-DM, 빅데이터 방법론), 폭포수 모델과 프로토타입 모델의 차이, 분석 과제 도출 프레임워크, 그리고 분석 마스터 플랜 수립 방법을 포괄적으로 다룬다.\n\n## 1장. 데이터 분석 기획의 이해\n### 1절. 분석기획 방향성 도출\n\n#### 분석기획의 특징\n분석기획이란?\n- 분석을 수행하기 전에 수행할 과제를 정의하고, 의도한 결과를 도출하기 위해 관리 방안을 사전에 계획하는 작업\n\n데이터 사이언티스트의 역량\n- 수학/통계학적 지식 및 정보기술, 해당 비즈니스에 대한 이해와 전문성을 포함한 3가지 영역에 대한 고른 역량과 시각이 요구\n\n#### 분석 대상과 방법\n- 분석의 **대상(What)**과 분석의 **방법(How)**에 따라서 4가지로 나뉜다\n\n![](https://i.imgur.com/kqfJL0T.png)\n\n출처: https://needjarvis.tistory.com/505\n\n\n- 최적화(Optimization): 분석 대상 및 분석방법을 이해하고 현 문제를 최적화 형태로 수행\n- 솔루션(Solution): 분석과제는 수행되고, 분석 방법을 모를 경우 솔루션을 찾아서 분석 수행\n- 통찰(Insight): 분석 대상이 불분명하지만 분석 방법을 알 경우 인사이트 도출\n- 탐색(Discovery): 분석 대상과 방법을 모를 경우 탐색을 통해 분석 대상 자체를 새롭게 도출 가능\n\n\n#### 목표 시점 별 분석 기획 방안\n- **과제 중심적인 접근 방식**: 당면한 과제를 빠르게 해결\n- **장기적인 마스터 플랜 방식**: 지속적인 분석 내재화\n\n- 분석기획에는 문제해결을 위한 단기적인 접근 방법과 분석과제 정의를 위한 중장기적인 마스터 플랜 접근 방식을 융합하는것이 필요\n\n![](https://i.imgur.c"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/ADsP/2023-08-02-ADsP-1과목. 데이터의 이해.md",
    "title": "ADsP 제1과목 데이터의 이해 요약",
    "description": "ADsP 제1과목(데이터의 이해) 요약 정리 - 데이터/정보 개념과 특성",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> ADsP 제1과목 '데이터의 이해' 전체 요약 노트이다. 데이터의 존재적/당위적 특성, 정성적 데이터와 정량적 데이터의 차이, 암묵지와 형식지의 4단계 상호작용(공통화-표출화-연결화-내면화), DIKW 피라미드의 각 단계별 정의와 관련 시스템, 데이터베이스의 특징(통합/저장/공용/변화), 빅데이터의 3V 특성, 데이터 사이언스와 비즈니스 모델, 그리고 가치 창조를 위한 데이터 전략을 포괄적으로 정리한다.\n\n# ADsP-데이터분석가 준전문가-1과목. 데이터의 이해\n\n## 1장. 데이터의 이해\n\n### 1절. 데이터와 정보\n\n#### 데이터의 정의\n- 1646년 영국 문헌에 처음 등장, '주어진 것'이란 의미로 라틴어 Dare(주다)의 과거분사형\n- 추론과 추정의 근거를 이루는 사실(Oxford Dictionary)\n- 단순한 객체로서의 가치뿐만 아니라 다른 객체와의 상호관계에서 가치를 갖는 것\n\n#### 데이터의 특성\n- 존재적 특성: 객관적 사실(Fact, Raw Material)\n- 당위적 특성: 추론, 예측, 전망, 추청을 위한 근거(Basis)\n\n| 구분 | 형태 | 예 | 특징 |\n| --- | --- | --- | --- |\n| 정성적 데이터<br>(Qualitative Data) | 언어, 문자 등 | 회사 매출이 증가함 등 | 저장, 검색, 분석에 많은 비용이 소모 됨 |\n| 정량적 데이터 <br> (Quantitative Data) | 수치, 도형 기호 등 | 나이, 몸무게, 주가 등 | 정형화된 데이터로 비용 소모가 적음 |\n\n\n> 정성적 데이터: \n> - **질적 자료**\n> - 비정형 데이터, 주관적 내용 통계분석이 어려움\n> \n> \n> 정량적 데이터: \n> - **양적 자료**\n> - 정형 데이터 , 객관적 내용 통계분석이 용이함\n> - 데이터분석에 선호됨\n\n#adsp중요\n\n암묵지: 학습과 경험을 통해 개인에게 체화되어 있지만 곁으로 드러나지 않는 지식\n1. 내면화(Internalization)\n\t- 학습과 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/ADsP/2024-08-09-ADSP 중요 포인트.md",
    "title": "ADsP 시험 핵심 요약 - 중요 포인트 정리",
    "description": "ADsP 자격증 시험 대비 핵심 개념과 중요 포인트 이미지 모음",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> ADsP 시험 대비 핵심 개념을 시각적으로 정리한 중요 포인트 모음이다. 제2과목(데이터 분석 기획)과 제3과목(데이터 분석)의 시험에 자주 나오는 핵심 개념들을 이미지로 정리하여 빠른 복습과 암기에 활용할 수 있다.\n\n\n## 2과목\n\n![](https://i.imgur.com/pSydZVG.png)\n\n![](https://i.imgur.com/7AJLdax.png)\n\n![](https://i.imgur.com/HZDi3jP.png)\n\n![](https://i.imgur.com/6icfCs7.png)\n\n\n![](https://i.imgur.com/8dUjFsA.png)\n\n\n![](https://i.imgur.com/nPjUc0u.png)\n\n![](https://i.imgur.com/hY8XLFc.png)\n\n## 3과목\n\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/빅분기/2023-11-30-빅분기-실기-2유형.md",
    "title": "빅분기-실기-2유형",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 2 유형 분석 순서\n\n1. 라이브러리 및 데이터 확인\n2. 데이터 탐색(EDA)\n\t- 데이터타입, 결측치, 기초통계량 등\n3. 데이터 전처리 및 분리\n\t- 결측치/이상치: 대체 or 삭제\n\t- 변수처리\n4. 모델링 및 성능 평가\n\t- 분류: RandomForestClassifier\n\t\t- Accuracy, F1 score\n\t- 회귀: RandomForestRegressor\n\t\t- R2, MSE, RMSE\n5. 예측값 제출\n\n### 2. 데이터 탐색(EDA)\n\n| 명령어 | 설명 |\n|--------|------|\n| `.shape` | 데이터의 행과 열의 수를 확인 |\n| `.head()` | 데이터의 처음 몇 줄(기본적으로 5줄)을 보여줌 |\n| `.info()` | 각 변수의 데이터 타입과 결측치 여부를 확인 |\n| `.describe()` | 데이터의 기초 통계량(평균, 최소값, 최대값 등) 확인 |\n| `.value_counts()` | 각 변수의 고유값들의 빈도수를 확인 |\n\n### 3. 데이터 전처리 및 분리(결측치, 이상치, 변수 처리)\n\n| 명령어                                                            | 설명                                                                     |\n| ----------------------------------------------------------------- | ------------------------------------------------------------------------ |\n| `.isnull().sum()`                                                 | 결측치의 갯수 확인                                                       |\n| `.dropna()`                    "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/빅분기/2023-09-22-빅분기.md",
    "title": "빅분기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n## 회귀분석\n\n### 회귀분석의 가정\n1. 선형성: 독립변수(X)와 종속변수(Y)간의 선형성\n2. 잔차의 3가지 가정(등분산성, 정규성, 독립성)\n\t1. 등분산성: 산점도\n\t2. 정규성:\n\t\t- H0(귀무가설: 정규분포를 따른다\n\t\t- H1(대립가설): not H0\n\t\t- 검정방법: Q-Q plot, 샤피오윌크 검정, 콜모고로프-스미스노프(K-S) 검정(비모수방법)\n3. 독립성: 더빗왓슨 검정\n\t- 잔차: 표본의 실제값과 회귀분석 예측값과의 차이(실제값-예측값)\n\n\n### 회귀분석에서 가설검정\n(회귀모형, 회귀계수가 통계적으로 유의한지?)\n\n1. 회귀모형: F검정, p-value < 0.05\n\t- H0(귀무): 회귀계수 = 0\n\t- H1(대립): 회귀계수 != 0\n2. 회귀꼐소: t 검정, p-value < 0.0.5\n\t- H0(귀무): i번째 회귀계수 = 0\n\t- H1(대립): i번째 회귀계수 != 0\n\n\n### 회귀식의 성능\n1. 결정계수($R^2$)\n\t- 정의: 설명력, 전체 변동에서 회귀식이 설명가능한 변동의 비율\n\t- $R^2=SSR/SST = 1-(SSE/SST)$\n\t\t- SSR: 회귀식에 의해 설명되는 변동 ($\\sum_{}^{}(\\hat{y}-\\bar{y})^2$) 예측값 - y평균값\n\t\t- SSE: 회귀식으로 설명 불가한 변동 ($\\sum_{}^{}(y-\\hat{y})^2$) 실제값 - 예측값\n\t\t- SST: 총 변동(SSR + SSE) ($\\sum_{}^{}(y-\\bar{y})^2$) 실제값 - y평균값\n\t- 범위: 0~1 사이 값을 가지며 클수록 성능이 좋음\n\t- 주의: 단 독립변수(X) 수가 증가 → $R^2$ 증가\n\t\t- $R^2$ adjust: 독립변수의 수가 증가하면 패널티를 줌\n\n### 다중회귀 분석시 변수를 선택하는 방법\n1. 전진 선택법(Forward selection): 하나씩 변수를 넣어보기\n2. 후진 제거법(Backward elimination): 다 넣고 하나씩 빼기\n3. 단계적 방법(Stepwise): 모든 조합 고"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/빅분기/2023-11-27-빅분기-실기-1유형.md",
    "title": "빅분기-실기-1유형",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 1유형-데이터 다루기\n\n### 유형\n\n1. 데이터 타입(object, int, float, bool 등)\n2. 기초통계량(평균, 중앙값, 사분위수, IQR, 표준편차 등)\n3. 데이터 indexing, filtering, sort, 변경 등\n4. 중복값, 결측치, 이상치 처리(제거 or 대체)\n5. 데이터 Scaling(데이터 표준화(z), 데이터 정규화(min-max))\n6. 데이터 합치기\n7. 날짜/시간 데이터, index 다루기\n\n> 날짜, 시간 데이터 연습이 많이 필요할듯!\n\n\n\n## 명령어 정리\n### 1. 데이터 타입(object, int, float, bool 등)\n\n\n| 명령어           | 설명                       | 사용 예시                           |\n| ---------------- | -------------------------- | ----------------------------------- |\n| `dtypes`         | 데이터 타입 확인           | `df.dtypes`                         |\n| `astype`         | 데이터 타입 변경           | `df.astype({'column':'data type'})` |\n| `value_counts()` | 컬럼에 대한 발행 횟수 반환 | `df['column'].value_counts()`       |\n\n\n### 2. 기초통계량(평균, 중앙값, 사분위수, IQR, 표준편차 등)\n\n#### 1) 중심측도\n\n\n| 명령어     | 설명   | 사용 예시              |\n| ---------- | ------ | ---------------------- |\n| `mean()`   | 평균값 | `df['column'].mean()   |\n| `median()` | 중앙값 | `df['column'].median() |\n| `mode()`   | 최빈값 |"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/빅분기/2023-12-02-빅분기-실기-3유형.md",
    "title": "빅분기-실기-3유형",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n### 3 유형 내용\n\n#### 1. 가설검정\n\n모평균 검정\n- 모집단 1개\n- 모집단 2개\n- 모집단 3개 이상\n- + 정규성/등분산성 검정\n\n카이제곱 검정\n- 적합성 검정\n- 독립성 검정\n#### 2. 상관분석\n- 피어슨 상관계수\n#### 3. 회귀분석\n- 다중 선형 회귀\n- 로지스틱 회귀\n\n\n\n### 1. 가설검정\n\"~할 것이다\" 라는 잠정적인 주장(가설)에 대해 통꼐적인 방식으로 검정하는 것으로 통계적 가설검정\n\n\n#### 1. 귀무가설과 대립가설\n1. 귀무가설(H0, Null hypothesis): 영가설(기존에 알려진 사실)\n\t- 차이가 없다, 서로 같다, 영향을 주지 않는다 등으로 설정\n2. 대립가설(H1, Alternative hypothesis): 연구가설, 대안가설\n\t- 차이가 있다, 같지 않다, 영향을 준다 등으로 설정\n\n> 가설검정은 검정통계량을 구해서 귀무가설(H0)을 채택할 건지 기각할 건지 판단하는 과정\n\n\n\n#### 2. 가설 검정의 오류(1종 오류, 2종 오류)\n\n##### 1종 오류\n- 귀무가설이 참일 때 이를 기각하는 오류를 범할 확률\n- 귀무가설이 참일 대 귀무가설을 기가할 최대 허용 한계\n- 보통 𝛼(알파)로 표기하고 유의수준이라 부른다)\n\t- 유의수준을 보통 5%로 설정함\n##### 2종 오류\n- 귀무가설이 거짓일 때 이를 채택하는 오류를 범할 확률\n#### 3. 가설 검정 순서\n1. 가설 설정(귀무/대립가설)\n2. 유의수준(𝛼) 설정(일반적으로 5%)\n3. 귀무가설하에 검정통계량 계산\n4. 검정통계량으로 P-value 계산\n5. 귀무가설(H0) 기각여부 결정(채택/기각)\n\t- P-value(유의확률) > 0.05(유의수준): H0(귀무가설) 채택\n\t- P-value(유의확률) ≤ 0.05(유의수준): H0(귀무가설) 기각\n\n\n\n### 3. 회귀분석\n#### 2. 로지스틱 회귀분석\n\n##### Odds(승산)\n\n$$odds = \\frac{P}{1-P}=\\frac{성공할 확률(Y=1)}{실패할 확률(Y=0)}$$\n\n\n\n\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Design-Patterns/2024-08-11-Structural Patterns.md",
    "title": "Structural Patterns",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n## Adapter\n\n### Adapter 이란?\n- 호환되지 않는 인터페이스를 가진 객체들이 협업가능하게 하는 구조적 디자인 패턴\n\n### Bridge vs Adapter\n\n- Bridge는 사전에 설계됨\n- Adapter은 일반적으로 기존 앱과 사용되어 원래는 호환되지 않던 일부 클래스들이 서로 잘 동작하게 함\n\n### 코드\n\n\n```python\nclass MediaPlayer:\n    \"\"\"\n    The MediaPlayer defines the standard interface for playing audio files.\n    \"\"\"\n\n    def play(self, audio_type: str, file_name: str) -> None:\n        raise NotImplementedError(\"This method should be overridden.\")\n\n\nclass AdvancedMediaPlayer:\n    \"\"\"\n    The AdvancedMediaPlayer defines an interface for playing advanced media formats.\n    \"\"\"\n\n    def play_mp4(self, file_name: str) -> None:\n        raise NotImplementedError(\"This method should be overridden.\")\n\n    def play_vlc(self, file_name: str) -> None:\n        raise NotImplementedError(\"This method should be overridden.\")\n\n\nclass Mp4Player(AdvancedMediaPlayer):\n    \"\"\"\n    Mp4Player is a concrete implementation of AdvancedMediaPlayer for playing MP4 files.\n    \"\"\"\n\n    def play_mp4(self, file_name: str) -> "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Design-Patterns/2024-08-11-Behavior Patterns.md",
    "title": "Behavior Patterns",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## Iterator(반복자 패턴)\n\n\n### Iterator이란?\n\n- 컬렉션의 요소들의 기본 표현(리스트, 스택, 트리 등)을 노출하지 않고 하나씩 순회\n\n\n![](https://i.imgur.com/nkBMQIh.png)\n\n\n### 장점\n- 단일 책임 원칙: 부피가 큰 순회 알고리즘들을 별도의 클래스들로 추출하여 클라이언트 코드와 컬렉션들을 정돈할 수 있다\n-  개방/폐쇄 원칙: 새로운 유형의 컬렉션들과 반복자들을 구현할 수 있으며 이들을 아무것도 훼손하지 않은 체 기존의 코드에 전달할 수 있다\n\n\n\n### 코드\n\n```python\nclass Node:\n    \"\"\"\n    이진 트리의 노드를 나타내는 클래스\n    \"\"\"\n\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n\n\nclass BinaryTree:\n    \"\"\"\n    이진 트리 클래스로, 노드를 추가하고 순회하는 기능을 제공\n    \"\"\"\n\n    def __init__(self, root):\n        self.root = root\n\n    def __iter__(self):\n        return InOrderIterator(self.root)\n\n\nclass InOrderIterator:\n    \"\"\"\n    중위 순회를 위한 이터레이터\n    \"\"\"\n\n    def __init__(self, root):\n        self.stack = []\n        self._push_left(root)\n\n    def _push_left(self, node):\n        while node:\n            self.stack.append(node)\n            node = node.left\n\n    def __next__(self):\n        if not self.stack:\n            raise St"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Design-Patterns/2024-08-11-Creational Patterns.md",
    "title": "Creational Patterns",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## Abstract Factory\n\n![](https://i.imgur.com/MFN6ace.png)\n\n### Abstract Factory란?\n- 패턴은 관련이 있거나 의존적인 객체들의 가족을 생성하기 위한 인터페이스를 제공하는 생성 패턴\n- 패턴은 구체적인 클래스에 의존하지 않고 객체의 가족을 생성하기 용이\n- 서로 관련된 객체들을 하나의 주제나 개념으로 묶어 생성\n\n\n![](https://i.imgur.com/CRw1AX6.png)\n\n\n### 장점\n- 관련 제품군 생성: 관련 제품(또는 객체)들을 하나의 가족으로 캡슐화하여, 가족 내 제품들이 서로 잘 협력할 수 있도록 함\n\n- 제품 호환성 보장: 팩토리를 통해 제품을 생성함으로써 생성된 객체들이 서로 호환될 수 있도록 보장\n\n- 제품 가족 전환의 용이성: 런타임 시 팩토리 객체를 변경함으로써 제품 가족을 쉽게 교체할 수 있어, 클라이언트 코드를 수정하지 않고도 전체 제품 세트를 교체에 용이\n\n\n### Abstract Factory vs Factory Method\n\n- Factory Method: 조건에 따른 생성을 팩토리 클래스로 위임하여, 팩토리 클래스에서 객체를 생성하는 패턴\n- Abstract Factory: 서로 관련이 있는 개체들을 통째로 묶어서 팩토리 클래스로 만들고, 이들 팩토리를 조건에 따라 생성하도록 다시 팩토리를 만들어서 객체를 생성하는 패턴\n\n\n### 코드\n```python\nfrom __future__ import annotations\nfrom abc import ABC, abstractmethod\n\n\nclass AbstractFactory(ABC):\n    \"\"\"\n    The Abstract Factory interface declares a set of methods that return\n    different abstract products. These products are called a family and are\n    related by a high-level t"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-07-26-SeSAC-데이터분석.md",
    "title": "[SeSAC]판다스 데이터분석",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 28. 여러 개의 데이터 프레임을 합치는 방법\n\n### concat\n\n- 여러 개의 데이터프레임을 하나의 데이터프레임으로 합치는 함수\n- 열 이름을 기준으로 합침\n- 행 기준으로 합치기 위해서는 `axis=1`를 추가해주면 된다\n\naxis \n- 1: 열 방향\n- 0: 행 방향\n\n### 행 이름 바꾸기\n\n```python\ndf.index = [...]\n```\n\n### 열 이름 바꾸기\n\n```python\ndf.columns = [...]\n```\n\n\n## 29. 스마트하게 데이터 프레임을 합치는 방법\n\n### merge\n- 특정 열을 기준으로 데이터 프레임을 합치는 방법\n\n\n```python\ndf1.merge(df2, left_on=df1의기준열, right_on=df2의 기준열)\n# 기준열의 이름이 서로 같은 경우 on으로 대체 가능\n```\n\n## 30. 누락값을 처리하는 방법\n\n### 누락값이란?\n- 비어있는 값을 말함\n- 하나라도 있다면 데이터분석 및 연산이 원활하지 못할 수 있음\n- 누락값은 비교할 수 없음(단, pd.isnull()함수로 누락값인지 판단 가능)\n- `from numpy import NAN, NaN, nan`\n\n> #### 널값 비교 불가\n> - null값은 비교불가기 떄문에, `if i==np.nan`과 같은 비교연산이 불가능하다\n> - `pd.isnull()`와 같은 함수로 판단 가능\n\n### 누락값 판단 함수\n\n```python\npd.isnull() # 누락값이면 True\npd.notnull() # 누락값이 아니면 True\n```\n\n### 누락값 개수 구하기\n\n```python\ndf.count() # 전체 개수\nnp.count_nonzero(데이터.isnull)\n\ndf['Cases_guinea'].value_counts(dropna=False)\n```\n\n### 누락값 채우기\n```python\nfillna(값) # 값으로 결측값을 채운다\nfillna(method='ffill') # 앞에 값으로 채운다\nfillna(method='b"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-11-21-Azure ML Classic.md",
    "title": "Azure ML Classic",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n## Azure ml classic\n\n- No Coding Tool 이 아닌 Low Coding Tool이라 부른다\n- `Python`이나 `R` 코드를 사용할 수 있기 때문\n\n### 접속\n1. https://studio.azureml.net/ 접속\n2. 회원가입 & 로그인\n\n### Blank Experiments 생성\n\n1. Experiments > Blank Experiment\n\n![](https://i.imgur.com/ZdmzErL.png)\n\n### 데이터 불러오기\n\n1. https://gallery.azure.ai/Experiment/Titanic-1-2\n\n![](https://i.imgur.com/e9ZU1iz.png)\n\n2. Open in Studio(classic) 클릭\n\n> Azure ML Classic에 로그인 되어있어야 한다\n\n![](https://i.imgur.com/JQpcdfL.png)\n\n\n\n### 데이터 확인\n1. Titanic Dataset 우클릭해서 Visualize 선택\n![](https://i.imgur.com/mDCeXBe.png)\n![](https://i.imgur.com/bsAI5j7.png)\n\n\n### Select Columns in Dataset\n\n1. `Select Columns in Dataset` 클릭\n2. 우측에 `Launch column selector` 클릭\n\n![](https://i.imgur.com/5PRc9lX.png)\n### Edit Metadata\n\n![](https://i.imgur.com/tFwupI5.png)\n![](https://i.imgur.com/BcPKYWv.png)\n![](https://i.imgur.com/vP97C6Z.png)\n\n### Missing Values Scrubber\n\n![](https://i.imgur.com/hb5AxF4.png)\n\n- `For missing values`: 결측치 처리 방법\n\n### Missing Values Scrubber2\n\n![](https:"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-07-29-SeSAC-이중우선순위큐.md",
    "title": "[lvl3]이중우선순위큐",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 힙(heap) > 이중우선순위큐](https://school.programmers.co.kr/learn/courses/30/lessons/42628)\n\n## 문제 설명\n\n이중 우선순위 큐는 다음 연산을 할 수 있는 자료구조를 말합니다.\n\n|명령어|수신 탑(높이)|\n|---|---|\n|I 숫자|큐에 주어진 숫자를 삽입합니다.|\n|D 1|큐에서 최댓값을 삭제합니다.|\n|D -1|큐에서 최솟값을 삭제합니다.|\n\n이중 우선순위 큐가 할 연산 operations가 매개변수로 주어질 때, 모든 연산을 처리한 후 큐가 비어있으면 [0,0] 비어있지 않으면 [최댓값, 최솟값]을 return 하도록 solution 함수를 구현해주세요.\n\n## 제한사항\n\n- operations는 길이가 1 이상 1,000,000 이하인 문자열 배열입니다.\n- operations의 원소는 큐가 수행할 연산을 나타냅니다.\n    - 원소는 “명령어 데이터” 형식으로 주어집니다.- 최댓값/최솟값을 삭제하는 연산에서 최댓값/최솟값이 둘 이상인 경우, 하나만 삭제합니다.\n- 빈 큐에 데이터를 삭제하라는 연산이 주어질 경우, 해당 연산은 무시합니다.\n\n## 입출력 예\n\n|operations|return|\n|---|---|\n|[\"I 16\", \"I -5643\", \"D -1\", \"D 1\", \"D 1\", \"I 123\", \"D -1\"]|[0,0]|\n|[\"I -45\", \"I 653\", \"D 1\", \"I -642\", \"I 45\", \"I 97\", \"D 1\", \"D -1\", \"I 333\"]|[333, -45]|\n\n## 입출력 예 설명\n\n### 입출력 예 #1\n\n- 16과 -5643을 삽입합니다.\n- 최솟값을 삭제합니다. -5643이 삭제되고 16이 남아있습니다.\n- 최댓값을 삭제합니다. 16이 삭제되고 이중 우선순위 큐는 비어있습니다.\n- 우선순위 큐가 비어있으므로 최댓값 삭제 연산이 무시됩니다.\n- 123을 삽입합니다.\n- 최솟값을 삭제합니다. 123이 삭제되고 이중 우선순위 큐는"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-09-01-SeSAC-혼공 머신러닝+딥러닝-Ch8. 이미지를 위한 인공 신경망.md",
    "title": "[SeSAC]혼공 머신러닝+딥러닝 Ch8. 이미지를 위한 인공 신경망",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 08-1 합성곱 신경망의 구성 요소\n### 합성곱\n- 1개 이상의 합성곱 층을 쓴 인공 신경망\n\n- 경계선을 찾는 필터로 사용댔던 값\n\n![](https://i.imgur.com/OPhUFIa.png)\n\n### CNN (Convolutional Neural Network)\n\n- **Convolutional Neural Network (CNN)**: 이미지 인식, 비디오 분석 등의 시각적 데이터 처리에 특화된 딥 러닝 아키텍처이다.\n\n#### 주요 구성 요소 및 용어\n\n- **Filter (Kernel, Mask)**: \n    - 작은 크기의 행렬로 이미지의 특정 특징을 감지하는 데 사용\n    - 입력 이미지에 컨볼루션 연산을 적용하여 특징 맵(feature map)을 생성\n    - 1차원 입력뿐 만 아니라 2차원 입력에도 적용할 수 있는 장점\n\n- **Feature Map**: \n    - 필터를 통해 이미지에 적용된 결과로, 이미지에서 감지된 특정 특징을 나타냄\n\n> -  **Stride**:\n> \t- Filter이 움직이는 간격\n\nFilter을 거쳐 Feature Map이 만들어지는 과정\n\n![](https://i.imgur.com/HI97RvM.png)\n\n\n![](https://ujwlkarn.files.wordpress.com/2016/07/convolution_schematic.gif?w=268&h=196_)\n\n\n- **Pooling (또는 Subsampling)**: \n    - 피처 맵의 차원을 줄이거나 다운샘플링하기 위한 과정\n    - 연산량을 줄이고, 공간적 변동성에 대한 모델의 민감도를 감소시킴\n\n- **Max Pooling**: \n    - 피처 맵의 영역 내에서 가장 큰 값을 선택하는 풀링 방법\n\n- **Mean Pooling (또는 Average Pooling)**: \n    - 피처 맵의 영역 내에서 모든 값의 평균을 계산하는 풀링 방법\n\n![](https://i.imgur.com/cE1KjBf.png)\n\n### CNN"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-31-혼공 머신러닝 & 딥러닝 요약.md",
    "title": "[SeSAC]혼공 머신러닝 & 딥러닝 요약",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# 1. Machine Learning\n\n1. 지도 학습(Supervised-Learning)\n\t- Target(Label)이 있음\n\t- ex) 여태 배운 모델중 K-Means를 제외한 나머지\n2. 비지도 학습(Unsupervised-Learning)\n\t- 라벨이 없음 → 성능 평가 불가\n\t- ex) K-means\n3. 강화 학습(Reinforcement-Learning)\n\t- 라벨이 없음\n\t- 경험을 기반으로 학습해나감(?)\n## 1-1. 모델(Model)\n### 수학적 분류\n\n1. **유사성 기반 학습 (Similarity-based Learning)**:\n\t- 새로운 데이터 포인트와 가장 유사한 학습 데이터 포인트를 찾아서 예측을 하는 방법\n\t- 예: KNN(K-Nearest Neighbors), K-Means\n2. **정보 기반 학습 (Information-based Learning)**:\n\t- 데이터에서 가장 유용한 특성(정보)을 찾아내서 예측 모델을 구성\n\t- 예: Decision Trees, Random Forest\n3. **확률 기반 학습 (Probability-based Learning)**:\n\t- 데이터의 확률 분포를 학습하여 예측을 하는 방법\n4. **에러 기반 학습 (Error-based Learning)**:\n\t- 예측의 에러를 최소화하도록 모델을 조정하는 방법\n\t- 예: Linear Regression, Logistic, Lasso, Ridge, SGD(Stochatic Gradient Descent)\n\n## 1-2. 성능 평가 & 비용 함수(Cost-Function)\n\n### 성능 평가\n1. $R^2$ : 회귀 모델 평가\n2. Accuracy: 분류 모델 평가\n\n#### $R^2$ (결정 계수)\n\n\n$$ \nR^2 = 1-\\tfrac{오차^2}{편차^2} \n\t= 1-\\tfrac{\\sum (예측값 - 실제값)^2}{\\sum (실제값평균-실제값)^2}\n\t= 1-\\tfrac{\\sum (\\widehat{y} - y)^2}{\\sum (\\ba"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-04-SeSAC-파이썬 데이터 처리 프로그래밍-5일차.md",
    "title": "[SeSAC]파이썬 데이터 처리 프로그래밍-5일차",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n\n\n## 파이썬 기초\n\n### 랜덤 숫자 맞추기 게임\n```python\n# 프로그램 실행시 랜덤으로 1~100 사이의 숫자를 생성\n# 10번의 기회가 있고, 10번 동안 숫자를 입력 받아 숫자를 맞추는 게임\n# 정답이 아닐 때마다 up/down을 출력\n# 정답을 맞추면 \"정답\"을 출력\n# 10번의 기회동안 정답을 못 맟췄다면 \"실패\" 출력\n\nimport random\nanswer = random.randint(1,100)\n\nfor i in range(10):\n    try:\n        guess = int(input(f\"[{i+1}번째 기회]숫자 입력:\").strip())\n        if guess == answer:\n            break\n        elif guess > answer:\n            print(\"down\")\n        elif guess < answer:\n            print(\"up\")\n    except:\n        print(\"숫자를 입력해주세요\")\n        \nif guess == answer:\n    print(\"성공!\")\nelse: print(\"실패!\")\n```\n\n> quit(), exit()와 같은 함수로 바로 종료시켜보려 했으나, jupyter notebook환경은 파이썬을 직접 돌리지 않기 때문에 동작하지 않는다\n\n\n### 랜덤 숫자 맞추기 게임(2)\n- 입력 숫자 범위 설정 추가\n\n```python\n# 숫자 맞추기\n# 입력값이 숫자가 아니거나 1~100 사이의 숫자가 아닐 경우\n# 기회를 차감하지 않도록 변경\n\n# 프로그램 실행시 랜덤으로 1~100 사이의 숫자를 생성\n# 10번의 기회가 있고, 10번 동안 숫자를 입력 받아 숫자를 맞추는 게임\n# 정답이 아닐 때마다 up/down을 출력\n# 정답을 맞추면 \"정답\"을 출력\n# 10번의 기회동안 정답을 못 맟췄다면 \"실패\" 출력\n\nimport random\nanswer = random.randint(1,100)\n\ncount = 0"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-11-17-딥러닝 영상처리.md",
    "title": "딥러닝 영상처리",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n## To-do:\n- Yann LeCun LeNet-5 논문 읽어보기\n### 권고 도서\n- 대니얼 콴 생각에 대한 생각\n- 인공지능 교과서: 스튜어트 러셀의 인공지능 1: 현대적 접근방식(AI: Modern Approach)\n- 정통파: 비숍의 패턴인식과 머신러닝(Pattern Recognition and Machine Learning)\n\n- 오바마의 디지털 참모: 신호와 소음\n### NeurIPS 2019에서 소개된 System 1, System 2\n- NeurIPS 2019에서 소개된 \"System 1\"과 \"System 2\"의 개념은 인지 심리학의 이론을 인공지능에 적용한 것\n- 이 이론은 다니엘 카너먼의 저서 \"생각에 관한 생각(Thinking, Fast and Slow)\"에서 비롯되었는데, 여기서 그는 인간의 사고 과정을 두 가지 시스템으로 나눈다\n\n1. **System 1 (시스템 1)**: \n\t- 이는 빠르고 직관적인 사고를 담당\n\t- 자동적이고 무의식적인 반응과 결정을 포함하며, 일상적인 상황에서 빠른 판단이나 간단한 문제 해결에 활용\n    \n2. **System 2 (시스템 2)**: \n\t- 느리고 논리적인 사고 과정\n\t- 의식적이고 주의를 요하는 작업, 복잡한 계산, 논리적 추론, 비판적 사고 등에 관여\n    \n\nNeurIPS 2019에서는 이러한 개념을 인공지능에 적용하여, 시스템 1과 같은 빠르고 직관적인 결정을 내리는 알고리즘과, 시스템 2처럼 더 복잡하고 계산이 많이 필요한 문제를 해결하는 알고리즘을 연구하고 개발하는 데 초점을 맞췄습니다. 이는 인공지능이 인간처럼 다양한 유형의 문제를 해결하고, 더 복잡하고 유연한 방식으로 사고할 수 있게 하는 데 목적을 두고 있습니다.\n\n이러한 접근 방식은 인공지능이 단순히 데이터와 알고리즘에 의존하는 것을 넘어서, 인간의 사고 방식을 모방하여 더욱 직관적이고 창의적인 해결책을 제시할 수 있게 돕습니다.\n\n\n\n## LeNet-5\n\n![](https://i.imgur.com/cxcklV5.png)"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-02-SeSAC-파이썬 데이터 처리 프로그래밍-3일차.md",
    "title": "[SeSAC]파이썬 데이터 처리 프로그래밍-3일차",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 공공데이터포털  API 사용\n- 접속(https://www.data.go.kr/)\n- 가입\n- 데이터 활용 신청 (https://www.data.go.kr/data/15059468/openapi.do)\n- OpenAPI 인증키 발급: 마이페이지 > 데이터활용 > Open API > 인증키 발급 현황\n\n### 기상청 데이터 API 사용\n```python\nimport requests\n\nurl = \"http://apis.data.go.kr/1360000/MidFcstInfoService/getMidFcst\"\nparams = {\n    'serviceKey':'{개인인증키}',\n    'numOfRows':'10',\n    'pageNo':'1',\n    'dataType':'JSON',\n    'stnId':'108',\n    'tmFc':'202308020600'\n}\nresponse = requests.get(url,params=params)\ndata = response.json()\nprint(data)\n```\n\n![](https://i.imgur.com/JnfNGTx.png)\n\n> 개인인증키 사용시: Encoding이 아닌 Decoding으로 사용해야 한다\n\n### JSON 보기 쉽게 출력:pprint(prettyprint)\n```python\nimport pprint\npprint.pprint(data)\n```\n\n![](https://i.imgur.com/hQ4MyUs.png)\n\n\n## Selenium\n- 동적 크롤링을 위한 라이브러리\n\n```python\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom webdriver_manager.chrome import ChromeDriverManager\nimport requests\nimport time\nrelease = 'https://chromedriver.storage.googleapis.com/LA"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-24-SeSAC-혼공 머신러닝+딥러닝-Ch3,4.md",
    "title": "[SeSAC]혼공 머신러닝+딥러닝 Ch3, 4",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 복습\n\n인공지능의 세가지\n- 지도학습\n\t- 데이터와 라벨을 줌\n- 비지도학습\n\t- 라벨을 주지 않음\n- 강화학습\n\t- 데이터가 없음\n\n### 지도학습\n\n- 출력값에 따른 분류\n\t1. 회귀\n\t\t- 연속적 수치\n\t2. 분류\n\t\t- 결과 종류별 확률 수치\n\t\t- ex) 개일 확률: 80%, 고양이일 확률: 20%\n\n> 회귀, 분류 모두 prediction, 즉 예측이다\n\n\n- 수학적 분류\n\t1. **유사성 기반 학습 (Similarity-based Learning)**:\n\t\t- 이 방식은 새로운 데이터 포인트와 가장 유사한 학습 데이터 포인트를 찾아서 예측을 하는 방법입니다.\n\t\t- 예: K-Nearest Neighbors (KNN) 알고리즘. KNN은 입력 데이터와 가장 가까운 k개의 학습 데이터 포인트를 찾아서 이들의 레이블을 기반으로 예측을 합니다.\n\t2. **정보 기반 학습 (Information-based Learning)**:\n\t\t- 이 방식은 데이터에서 가장 유용한 특성(정보)을 찾아내서 예측 모델을 구성합니다.\n\t\t- 예: Decision Trees. 결정 트리는 데이터를 분할하는 데 가장 정보가 많은 특성을 기반으로 규칙을 만들어 학습합니다.\n\t3. **확률 기반 학습 (Probability-based Learning)**:\n\t\t- 이 방식은 데이터의 확률 분포를 학습하여 예측을 하는 방법입니다.\n\t\t- 예: Naive Bayes 알고리즘. 이 알고리즘은 특성 간의 독립성을 가정하고 각 특성의 확률 분포를 학습하여 예측을 합니다.\n\t4. **에러 기반 학습 (Error-based Learning)**:\n\t\t- 이 방식은 예측의 에러를 최소화하도록 모델을 조정하는 방법입니다.\n\t\t- 예: Neural Networks, Linear Regression. 이러한 알고리즘들은 에러를 최소화하는 파라미터를 찾기 위해 반복적으로 학습을 수행합니다.\n\n\n## Chapter 03 회귀 알고리즘과 모델 규제\n\n### 03-1 K-최근접 이웃 회귀\n\n####"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-07-19-SeSAC-정처기-2과목-데이터베이스 구축.md",
    "title": "[정보처리기사]2과목 데이터베이스 구축",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# Chapter 1. 데이터베이스 구축\n\n## Section 1. 데이터베이스 개념\n\n### 1. 데이터베이스 개념\n\n#정처기중요\n#공장통운\n#### 데이터베이스의 정의 (중요!)\n- 통합데이터(Integrated Data)\n\t- 검색의 효율성을 위해 중복이 최소화된 데이터의 모임\n- 저장 데이터(Stored Data)\n\t- 컴퓨터가 접근 가능한 저장 매체에 저장된 데이터\n- 운영 데이터(Operational Data)\n\t- 조직의 목적을 위해 존재 가치가 확실하고 반드시 필요한 데이터\n- 공유 데이터(Shared Data)\n\t- 여러 응용 프로그램들이 공동으로 사용하는 데이터\n\n#### 데이터베이스의 특징\n- 실시간 접근성\n- 계속적인 변화\n- 동시 공유\n- 내용에 의한 참조\n- 데이터의 독립성\n\n#### 데이터 언어\n- DDL(Data Definition Language): 데이터 정의\n\t- \n- DML(Data Manipulation Language): 데이터 조작\n\t- CRUD\n- DCL(Data Control Language): 데이터 제어어\n\t- GRANT\n\t- ROLLBACK\n\t- REVOKE\n\t- COMMIT\n\n#### 스키마(Schema)\n- 데이터베이스의 구조와 제약조건에 관해 전반적인 명세를 기술한 것\n- 개체, 속성, 관계에 대한 정의와 이들이 유지해야 할 제약조건들을 기술한 것\n- 스키마는 데이터 사전(Data Dictionary)에 저장\n\n3계층 스키마\n- 외부 스키마(External Schema): \n\t- 사용자가 보는 관점\n\t- 논리적 구조 정의\n\t- 여러개 존재\n- 개념 스키마(Conceptual Schema): \n\t- 전체적인 제약 조건\n\t- 한개만 존재\n- 내부 스키마(Internal Schema): \n\t- 물리적인 제약 조건\n\n#정처기중요\n데이터 독립성\n- 논리적 독립성\n\t- 응용 프로그램에 영향을 주지 않고 데이터베이스 논리적 구조를 변경할 수 있는 능력\n\t- 개념 스키마가 변경되어도 외부 스키마에는 영향을 미치지 않"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-11-21-Orange 실습.md",
    "title": "Orange 실습",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n# Orange 실습\n## 실습\n### 다운로드\n\n- https://orangedatamining.com/download/ 에서 자신의 OS에 맞는 버전 설치\n\n### Image Analytics Add-on 설치\n\n1. 윈도우의 경우 관리자 버전으로 실행\n2. Options -> Add-ons -> Image Analytics 검색, 설치\n\n![](https://i.imgur.com/4cLvpxf.png)\n\n\n\n## wine dataset 실습\n### 데이터 불러오기 \n\n1. 좌측 Data 메뉴에서 File 위젯 두개 생성\n\n![](https://i.imgur.com/RlSbntv.png)\n\n2. 파일을 더블 클릭하여 옵셩 창 열고, 다운로드한 데이터 설정\n\n![](https://i.imgur.com/jgMFz3K.png)\n### 데이터 합치기\n\n1. 촤즉 Transform 탭에서 Concate 선택\n\n![](https://i.imgur.com/GkDxLXT.png)\n2. 아래와 같이 연결 후 Concatenate 더블 클릭\n\n![](https://i.imgur.com/vTGNQuJ.png)\n\n\n> 두 데이터셋의 컬럼명이 같기 때문에 `all variables that appear in input table` 을 선택해도 상관없다. 하지만, 다를 경우 위는 합집합, 아래는 교집합이라는 점 참고하자\n\n\n3. Append data source IDs 선택\n\t- Feature name: type\n\n![](https://i.imgur.com/H8i5ukB.png)\n> 하단의 `1599`개의 샘플 과`4898`개의 샘플을 받아 `6497`개의 샘플로 concatenate 한다는 뜻\n\n\n\n### 데이터 확인\n1. Data 탭에 DataTable 두개 선택(하나는 Concatenate, 하나는 wine red에 연결)\n\n![](https://i.imgur.com/tWk8QFw.png)\n2. Data Table을 더블 클릭하여 확인\n\nConcatenate:\n![](htt"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-21-빅데이터의 다음 단계는 예측 분석이다.md",
    "title": "빅데이터의 다음 단계는 예측 분석이다",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# 빅데이터의 다음 단계는 예측 분석이다\n## 기계학습\n- 컴퓨터에 명시적으로 프로그래밍 하지 않고 학습할 수 있는 영역 (Arthur Samuel , 1959)\n\n만약 작업 T에 대해 기준 P로 측정한 성능이 E로 인해 향상되었다면, 그 프로그램은 작업 T에 대해 P의 관점에서 경험 E로부터 \"배웠다\"라고 말할 수 있다. (Tom Mitchell, Machine LEarning, 1998)\n\n![](https://i.imgur.com/jgLcg0f.png)\n\n\n### 기계학습의 핵심\n- 표현(representation)\n\t- 기계학습 알고리즘이 어떻게 데이터의 특징을 잘 잡아내도록 할까?\n- 일반화(generalization)\n\t- 기계학습 알고리즘이 어떻게 이전에 보지 못한 데이터에서도 잘 작동하게 할까?\n\n### 기계학습을 수행하기 위해 필요한 능력\n\n![](https://i.imgur.com/0bcS8Nu.png)\n\n\n### 머신러닝 3종류\n- unsupervised learning\n- supervised learning\n- reinforcement learning\n\n### 4차 산업혁명\n1. 1차 산업혁명: 증기기관을 활용하여 기계적 혁명 시작\n2. 2차 산업혁명: 공장에 전력이 공금되고 대량 생산이 가능\n3. 3차 산업혁명: 컴퓨터 & 인터넷의 발달로 발생된 정보혁명\n5. 4차 산업혁명: 디지털 기술에 의한 생산 혁명\n\n\n![](https://i.imgur.com/KvSZE2e.png)\n\n\n### 데이터 리터러시\n- 데이터를 목적에 맞게 활용하는 데이터 해석 능력\n- 데이터 수집, 관리, 가공 및 분석, 시각화 ,기획 역량 등\n\n### 비즈니스 애널리틱스\n1. 과거 데이터를 통해 밝히는 묘사 분석(Descriptive Analytics)\n- 어떤 일이 있었는지(What happended?)\n\n2. 진단 분석(Diagnostic Analytics)\n- 발생한 현상에 대한 원인을 찾는(Why did it happen?)\n\n3. 예측 분석(Predic"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-09-04-SeSAC-혼공 머신러닝+딥러닝-Ch9. 텍스트를 위한 인공 신경망.md",
    "title": "[SeSAC]혼공 머신러닝+딥러닝 Ch9. 텍스트를 위한 인공 신경망",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n## 09-1 순차 데이터와 순환 신경망\n\n> 벡터: 크기가 있는 스칼라에 방향을 추가함으로써 같은 크기임에도 다른 숫자로 표현 가능하게 한다\n\n\n### 순환 신경망(RNN: Recurrent Neural Network)\n\n> weighted-sum(가중치합): perceptron이 계산하는것\n\nN:1 구조\n- 입력 여러개: 출력 1개\n\nautoencoder: encode & decode\n- N:1 진행 후 1:M로 나오게 함\n- N과 M이 달라도 된다\n\nimage embedding\n\nword embedding\n- 단어의 중요성: 빈도수(긍정과 부정에 골고루 나타난다면 제거)\n\t- 중요한 단어의 가중치를 올려줌\n- 단어 간 관련: 같은 문장에 등장\n\t- 비슷한 단어들끼리 근처에 둠\n\n## 09-2 순환 신경망으로 IMDB 리뷰 분류하기\n\n\n```python\n# 실행마다 동일한 결과를 얻기 위해 케라스에 랜덤 시드를 사용하고 텐서플로 연산을 결정적으로 만듭니다.\nimport tensorflow as tf\n\ntf.keras.utils.set_random_seed(42)\ntf.config.experimental.enable_op_determinism()\n```\n\n### IMDB 리뷰 데이터셋\n\n\n```python\nfrom tensorflow.keras.datasets import imdb\n\n(train_input, train_target), (test_input, test_target) = imdb.load_data(\n    num_words=300)\n```\n\n    Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n    17464789/17464789 [==============================] - 0s 0us/step\n\n> num_words=300: 문장 길이 300이라는 뜻이 아니라 300개의 어휘를 사용한다는 뜻\n\n```pytho"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-07-24-SeSAC-파이썬 강의.md",
    "title": "[SeSAC]파이썬 강의",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# 1. 파이썬 알아보기\n\n## 파이썬이란?\n\n- 1990년 암스테르담의 귀도 반 로선(Guido Van Rossum)이 개발한 인터프리터 방식의 프로그래밍 언어\n- 구글 소프트웨어의 50%이상이 파이썬을 사용\n- 드롭박스, 인스타그램, 유튜브등이 파이썬으로 작성됨\n- 공동작업과 유지 보수가 쉽다\n\n> #### 인터프리터 방식이란?\n> 한줄씩 실행되는 방식\n\n\n## 파이썬의 특징\n- 인간다운 언어\n\n### 강점:\n- 쉬운 난이도\n\t- 초보 프로그래머들에게 자주 추천됨\n\t- 오픈 소스가 많아 정보 검색이 용이\n- 무료지만 강력\n\t- 오픈 소스임으로 어디서든 파이썬 사용 가능\n\t- 개발 속도가 빠름\n\n### 활용 분야:\n- 테이터 크롤링\n- 테이터 분석\n- 머신 러닝\n\n\n다른 언어들의 활용 분야:\n- C: 속도에 특화된 언어\n- Java: 웹, 안드로이드 언어\n- Swift: 아이폰 앱\n\n## 파이썬 설치\n\n공식 싸이트에서 다운보단 필요한 툴들과 함께 패키지 형식으로 제공하는 아나콘다에서 받는걸 추천\n\n아나콘다 링크: [https://www.anaconda.com/products/distribution](https://www.anaconda.com/products/distribution)\n\n## 파이썬 개발 환경\n- Jupyter Notebook: 웹 브라우저에서 파이썬 코드를 작성, 실행할 수 있는 개발도구\n- Google Colab: 주피터 노트북과 같지만, 협업에 용이함\n- Pycharm: 스마트 코드 완성, 코드 검사, 즉성 오류 강조 표시 기능이 추가된 플랫폼\n\n# 2. 숫자형 자료형\n\n- 숫자 형태로 이루어진 자료형\n\n### 정수형\n```python\na = 3 # a에 3을 저장\nprint(a) # print() 출력 명령어\n```\n\n### 실수형\n```python\na = 3.14 # 소수 형태의 숫자를 a에 저장\nprint(a)\n```\n\n다른 언어들과 다르게 형변환이 불필요하다\n\n### 지수 표현\n```python\na = 5.15E+10 # 5.1"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-08-프로젝트 소통역량 강화.md",
    "title": "[SeSAC]프로젝트 소통역량강화",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## Intro: \n### 일을 왜 잘해야 하나?\n- 신뢰 상승 → 하고 싶은 일을 할 수 있는 기회가 넓어짐\n\n### 성적과 성과\n\n성적의 게임과 성과의 게임은 다르다\n- 각자의 능력에 따라 천재가 될 수도, 허당이 될 수도 있다\n\n| 지향점 | 학업의 세계         | 직업의 세계        |\n| ------ | ------------------- | ------------------ |\n| 지향점 | 더 좋은 직업과 직장 | 업계에서 인정 받기 |\n|         | 성적을 높히는                    |                    |\n\n### 우리나라 프로젝트와 해외 프로젝트의 차이점\n\n- 스탠포드의 IDEO가 일하는 방식\n\n\n## 스마트하게 일하는 사람들에게 배운 것\n### 1. 목적과 목표를 명확히 한다\nBe를 생각하며 Do를 하는 습관이 중요\n- 목적인 Be를 잊어버리면 안된다\n\n목적\n- 우선순위\n- 기준/준거\n\nProject Triangle\n- Better\n- Faster\n- Cheaper\n\n\n#### SMART한 목표\n##### **Specific**\n- 구체적이어야 한다\n\n##### **Measurable**\n- 측정할 수 있어야 한다\n- ex) How much, How many, how?\n\n##### **Attainable**\n- 달성할 수 있어야 한다\n- 현실적이면서 동시에 도전적이어야 한다\n- 쉬움과 무리를 모두 피해야 함\n\n##### **Relevant**\n- 목표 자체가 중요해야 함\n\n##### **Time**\n- 기한을 명시할 수 있어야 한다\n\n### 네모 그리기 게임\n\n#### 도전적 \n\nA값 = G1\n\t- 16 이하\n\t- 17~26\n\t- 37~46\n\t- 47~\n\n> 40\n\n#### 향상하려는 의지\n\nB값 = \\[(G3-P2) + (G4-P3) + (G5-P4) + (G6-P5)]/4\n- \\[(32-36) + (36-36) + (40-40)] = -1\n\n> -1\n\n#### 실력과 계획 간의 간극\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-25-PCCP-3일차.md",
    "title": "[PCCP]3일차",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 구구단 만드는 법\n\n```python\nfrom pprint import pprint  \ngugudan = []  \nfor i in range(2, 10):  \n    temp = []  \n    for j in range(1, 10):  \n        temp.append(j*i)  \n    gugudan.append(temp)  \n  \npprint(gugudan)  \n```\n\\[\\[2, 4, 6, 8, 10, 12, 14, 16, 18],\n \\[3, 6, 9, 12, 15, 18, 21, 24, 27],\n \\[4, 8, 12, 16, 20, 24, 28, 32, 36],\n \\[5, 10, 15, 20, 25, 30, 35, 40, 45],\n \\[6, 12, 18, 24, 30, 36, 42, 48, 54],\n \\[7, 14, 21, 28, 35, 42, 49, 56, 63],\n \\[8, 16, 24, 32, 40, 48, 56, 64, 72],\n \\[9, 18, 27, 36, 45, 54, 63, 72, 81]]\n\n### 구구단(list comprehension)\n```python\ngugudan2 = [[i*j for i in range(1, 10)] for j in range(2, 10)]  \n  \npprint(gugudan2)\n```\n\\[\\[2, 4, 6, 8, 10, 12, 14, 16, 18],\n \\[3, 6, 9, 12, 15, 18, 21, 24, 27],\n \\[4, 8, 12, 16, 20, 24, 28, 32, 36],\n \\[5, 10, 15, 20, 25, 30, 35, 40, 45],\n \\[6, 12, 18, 24, 30, 36, 42, 48, 54],\n \\[7, 14, 21, 28, 35, 42, 49, 56, 63],\n \\[8, 16, 24, 32, 40, 48, 56, 64, 72],\n \\[9, 18, 27, 36, 45, 54, 63, 72, 81]]\n\n\n### 얕은 복사, 깊은 복사\n1. **얕은 복사 (Shallow C"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-11-23-딥러닝 영상처리4.md",
    "title": "딥러닝 영상처리4",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n\n## 수업:\n\n\n![](https://i.imgur.com/4zsfdlV.png)\n\n### SSD(Single Shot Detection):\n\n\n\n#### SSD Network 구조\n\n\n![](https://i.imgur.com/ikrgkTn.png)\n\n\n> Anchor Box의 크기는 고정하되, Feature map의 크기를 줄여나간다 => MaxPooling과 같은 효과\n\n\n\n#### SSD 주요 구성 요소\n\n- Multi Scale Feature LAyer\n\n- Default (Anchor) Box\n\n> AnchorBox 덕분에 Selective Search보다 계산량이 적음 => 훈련할떈 모르겠으나 사용할떈 빠름\n\n\n##### SSD Node 수\n\n- 4개의 Anchor Box\n- Classifier: 3 * 3 * (4 * (classes + 4))\n\t- * 4: 4개의 Anchor box\n\t- + 4: 좌표\n- 2~4번째 Conv 레이어에서는 Anchor Box 의 개수가 6개로 바뀜\n\n\n\n### Yolo(You Only Look Once)\n\n#### mAP: \n\n1. **Precision과 Recall**:\n    \n    - **Precision**: 정확하게 감지된 객체의 비율을 나타냅니다. 즉, 실제로 얼마나 많은 예측이 정확했는가를 나타냅니다.\n    - **Recall**: 실제 객체 중 감지된 객체의 비율을 나타냅니다. 즉, 실제 객체 중 얼마나 많이 감지되었는가를 나타냅니다.\n2. **각 클래스 별 AP (Average Precision) 계산**:\n    \n    - 각 클래스에 대해 Precision-Recall 곡선을 그립니다.\n    - 이 곡선 아래 영역의 면적을 계산하여 각 클래스에 대한 AP를 산출합니다.\n    - Precision-Recall 곡선은 다양한 임계값(Threshold)에 대한 Precision과 Recall 값을 연결한 것입니다.\n3. **mAP 계산**:\n    \n    - 모든 클래스에 대한 AP"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-11-30-Transformers 실습.md",
    "title": "Transformers 실습",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n```\n\n\n```python\ntf.__version__\n```\n\n\n\n\n    '2.14.0'\n\n\n\n\n```python\n# 최종 버전\nclass PositionalEncoding(tf.keras.layers.Layer):\n  def __init__(self, position, d_model):\n    super(PositionalEncoding, self).__init__()\n    self.pos_encoding = self.positional_encoding(position, d_model)\n\n  def get_angles(self, position, i, d_model):\n    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n    return position * angles\n\n  def positional_encoding(self, position, d_model):\n    angle_rads = self.get_angles(\n        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n        d_model=d_model)\n\n    # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n    sines = tf.math.sin(angle_rads[:, 0::2])\n\n    # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n    cosines = tf.math.cos(angle_rads[:, 1::2])\n\n    angle_rads = np.zeros(angle_rads.shape)\n    angle_rads[:, 0::2] = sine"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-29-SeSAC-혼공 머신러닝+딥러닝-Ch6. 비지도 학습.md",
    "title": "[SeSAC]혼공 머신러닝+딥러닝 Ch6. 비지도 학습",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 06-1 군집 알고리즘\n- 레이블(종속 데이터)가 없음\n- 추천 시스템에 사용\n- k-means\n### 과일 사진 데이터 준비하기\n\n```python\n!wget https://bit.ly/fruits_300_data -O fruits_300.npy\nimport numpy as np\nimport matplotlib.pyplot as plt\nfruits = np.load('fruits_300.npy')\nprint(fruits.shape)  # (300, 100, 100)\nprint(fruits[0, 0, :]) \n# [  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   2   1\n#    2   2   2   2   2   2   1   1   1   1   1   1   1   1   2   3   2   1\n#    2   1   1   1   1   2   1   3   2   1   3   1   4   1   2   5   5   5\n#   19 148 192 117  28   1   1   2   1   4   1   1   3   1   1   1   1   1\n#    2   2   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n#    1   1   1   1   1   1   1   1   1   1]\n\nplt.imshow(fruits[0], cmap='gray')\nplt.show()\n```\n\n![](https://i.imgur.com/KqHAQxs.png)\n\n\n```python\nplt.imshow(fruits[0], cmap='gray_r')\nplt.show()\n```\n\n![](https://i.imgur.com/DBw9L4C.png)\n\n```python\nfig, axs = plt.subplots(1, 2)\naxs[0].imshow(fruits[100], cmap='gray_r')\naxs[1].imshow("
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-03-SeSAC-파이썬 데이터 처리 프로그래밍-4일차.md",
    "title": "[SeSAC]파이썬 데이터 처리 프로그래밍-4일차",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## Selenium\n\n### 네이버 주식 크롤링 \n\n```python\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom selenium.webdriver.common.by import By\nimport requests\nimport time\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.keys import Keys\n\nservice = Service()\nd = webdriver.Chrome(service=service)\n\ntry:\n    url = 'https://finance.naver.com/'\n    d.get(url)\n    trs = WebDriverWait(d, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, '#_topItems1 > tr')))\n    for tr in trs:\n        updown = tr.get_attribute(\"class\")\n        if updown == \"up\":\n            sign = \"+\"\n        elif updown == \"down\":\n            sign = \"-\"\n        else: sign = \"\"\n        item = tr.find_element(By.CSS_SELECTOR, \"th > a\").text.strip()\n        tds = tr.find_elements(By.CSS_SELECTOR, \"td\")\n        price = tds[0].text."
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-01-SeSAC-파이썬 데이터 처리 프로그래밍-2일차.md",
    "title": "[SeSAC]파이썬 데이터 처리 프로그래밍-2일차(BeautifulSoup, Pymysql, Openpyxl)",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## BeautifulSoup\n\n### Naver 지식인 타이틀 페이지네이션\n\n```python\nimport requests\nfrom bs4 import BeautifulSoup\nfrom fake_useragent import UserAgent\n\nua = UserAgent()\nheaders = {\n    \"User-Agent\":ua.random\n}\nfor i in range(1, 10):\n    link = f'https://kin.naver.com/search/list.naver?query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&page={i}'\n    res = requests.get(link, headers=headers)\n    bs = BeautifulSoup(res.text, 'html.parser')\n\n\n    uls = bs.select_one('#s_content > div.section > ul')\n    titles = uls.select('dt > a')\n    for title in titles:\n        print(title.text)\n        print(title.attrs.get(\"href\"))\n```\n\n## Pymysql\n- database에 접속하기 위한 라이브러리\n\n### Pymysql을 이용한 데이터 조회\n```python\n#!pip install pymysql\nimport pymysql\n\ndb = pymysql.connect(host=\"localhost\", port=3306, user=\"root\", password=\"{비밀번호}\", db=\"market_db\")\ncursor = db.cursor()\n\nsql = \"\"\"\nSELECT * FROM member;\n\"\"\"\n\ncursor.execute(sql)\nresult = cursor.fetchmany(size=100)\nfor data in result:\n    print(data)\n    \ndb.close()\n```\n\n> db.close()를 항상 주의해"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-29-SeSAC-혼공 머신러닝+딥러닝-정리.md",
    "title": "SeSAC-혼공 머신러닝+딥러닝-정리",
    "description": "머신러닝과 딥러닝의 주요 개념, 모델 평가 지표, 정규화 기법 및 다양한 모델 파라미터에 대한 정리",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## \n#RMSE\n#### **Root Mean Squared Error (RMSE)**\n$$\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}((y-\\widehat{y})^2)}$$ \n- 해석:\n\t- 예측 오차의 크기를 직관적으로 해석하기 쉽게 만드\n\t- 값이 낮을수록 모델의 성능이 좋다\n#MSE\n#### **Mean Squared Error(MSE)**\n$$\\frac{1}{n}\\sum_{i=1}^{n}((y-\\widehat{y})^2)$$\n- **해석**: \n\t- MSE는 예측 오차의 제곱 평균\n\t- 값이 낮을수록 모델의 성능이 좋다\n\n#R2 \n#### **$R^2$ (결정 계수)**\n$$R^2 = 1-\\tfrac{오차^2}{편차^2} \n\t= 1-\\tfrac{\\sum (예측값 - 실제값)^2}{\\sum (실제값평균-실제값)^2}$$\n- **해석**:\n\t- 값이 0과 1 사이에 있으며, 1에 가까울수록 모델이 데이터의 변동성을 잘 설명한다는 것을 의미\n\t- 반면, 0에 가까울수록 모델의 설명력이 떨어진다는 것을 의미합니다.\n\n- MSE는 예측 오차의 제곱 평균을 나타내며, 값이 낮을수록 좋다\n- RMSE는 MSE의 제곱근으로, 예측 오차의 실제 크기를 나타낸다.\n- **$R^2$는 모델이 데이터의 변동성을 얼마나 잘 설명하는지를 나타내는 지표로, 1에 가까울수록 좋다.\n\n#비용함수\n#### 로지스틱 회귀의 비용 함수:\n\n$$ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right] $$\n\n$$\nh_\\theta(x) = \\frac{1}{1 + e^{-\\theta^T x}}\n$$\n\n#### 정규화(regularization) 기법\n\n- 불순물 추가 하여 과적합을 막는다\n$$(y-(W_{1}X_{1} + W_{2}X_{2}\\cdots +W_{0})) + \\lambda$$\n$\\lam"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-11-22-딥러닝 영상처리3.md",
    "title": "딥러닝 영상처리3",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 정리:\n### Non-maximum Suppression (NMS)\n\n#### 설명:\n\n- **목적**: 객체 검출(Object Detection)에서 여러 겹쳐진 경계 상자(Bounding Boxes) 중 최적의 상자를 선택하기 위함.\n- **방법**:\n    - 각 경계 상자에 대해 감지 확률을 평가.\n    - 가장 높은 점수를 가진 상자를 선택하고, 다른 상자들과의 중첩(Overlap)을 계산.\n    - 특정 임계값(IoU: Intersection over Union)보다 높은 중첩을 가진 상자는 제거.\n- **결과**: 각 객체에 대해 단일, 최적의 경계 상자를 얻음.\n\n### Selective Search\n\n#### 설명:\n\n- **목적**: R-CNN에서 사용, 이미지 내 잠재적인 관심 영역(Regions of Interest, RoIs)을 식별하기 위함.\n- **방법**:\n    - 세분화(Segmentation) 기법을 사용하여 이미지를 여러 영역으로 나눔.\n    - 유사한 특징(색상, 질감 등)을 가진 인접 영역을 병합.\n    - 다양한 크기와 모양의 후보 영역 생성.\n- **결과**: 후보 영역들이 객체 검출 알고리즘의 입력으로 사용됨.\n\n![](https://i.imgur.com/GwZO3sY.png)\n\n![](https://i.imgur.com/yY8td0f.png)\n\n\n### R-CNN, Fast R-CNN, Faster R-CNN\n\n![](https://i.imgur.com/UuZDMz9.png)\n\n\n#### R-CNN (Regions with CNN features)\n\n- **구조**:\n    - Selective Search로 후보 영역 추출\n    - 각 영역을 CNN에 입력하여 특징 추출\n    - 추출된 특징을 SVM(Classifier)에 입력하여 객체 분류\n- **단점**: 계산 비효율성 (각 영역마다 CNN 통과)\n\n#### Fast R-CNN\n\n- **개선점**:\n    - 전체 이미지를 한 번에 CNN"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-29-SeSAC-혼공 머신러닝+딥러닝-Chap7. 딥러닝.md",
    "title": "[SeSAC]혼공 머신러닝+딥러닝 Ch7. 딥러닝",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n## 07-1 인공 신경망\n\n```python\nimport tensorflow as tf\n\ntf.keras.utils.set_random_seed(42)\ntf.config.experimental.enable_op_determinism()\n```\n\n### 패션 MNIST:\n- MNIST(Modified National Institute of Standars and Technology Database)\n\n```python\nfrom tensorflow import keras\n\n(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n\nprint(train_input.shape, train_target.shape)  # (60000, 28, 28) (60000,)\n\nprint(test_input.shape, test_target.shape)  # (10000, 28, 28) (10000,)\n\nimport matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(1, 10, figsize=(10,10))\nfor i in range(10):\n    axs[i].imshow(train_input[i], cmap='gray_r')\n    axs[i].axis('off')\nplt.show()\n```\n\n![](https://i.imgur.com/5JVHqKJ.png)\n\n\n```python\nprint([train_target[i] for i in range(10)])  # [9, 0, 0, 3, 0, 2, 7, 2, 5, 5]\n\nimport numpy as np\n\nprint(np.unique(train_target, return_counts=True))\n# (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([6000, 6000, 6000, 6000, 6000, 6000, 60"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-09-29-대화 요약 어플.md",
    "title": "회의록 작성 어플 프로젝트",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n## 필요한 과정\n\n### 1. 음성 인식 (ASR) 시스템 구축\n\n- **목표**: 회의 중 발생하는 음성을 텍스트로 변환합니다.\n- **세부 작업**:\n    1. **음성 인식 API 선택**: Google Speech-to-Text, IBM Watson Speech to Text 등을 선택합니다.\n    2. **API 통합**: 선택한 API를 시스템에 통합하여 실시간으로 음성을 텍스트로 변환합니다.\n    3. **테스트 및 최적화**: 다양한 환경과 발언자로부터 음성 데이터를 테스트하여 성능을 확인하고 필요시 최적화합니다.\n\n### 2. 키워드 및 주제 추출\n\n- **목표**: 회의록 텍스트에서 핵심 키워드와 주제를 추출합니다.\n- **세부 작업**:\n    1. **PLM 선택 및 Fine-tuning**: BERT, RoBERTa 등의 모델을 선택하고, 키워드 및 주제 추출 작업에 맞게 Fine-tuning합니다.\n    2. **키워드 추출**: Fine-tuned 모델을 사용하여 회의록에서 핵심 키워드를 추출합니다.\n    3. **주제 분류**: 추출된 키워드를 바탕으로 주제를 분류합니다.\n\n### 3. 문장 요약\n\n- **목표**: 각 발언이나 문단을 요약합니다.\n- **세부 작업**:\n    1. **요약 모델 선택 및 학습**: GPT-3, GPT-4, BERT 등을 선택하고 문장 요약 작업에 맞게 Fine-tuning합니다.\n    2. **문장 요약 실행**: 학습된 모델을 사용하여 회의록의 각 부분을 요약합니다.\n\n### 4. 마크다운 형식 변환\n\n- **목표**: 추출된 키워드, 주제, 및 요약문을 마크다운 형식으로 정리합니다.\n- **세부 작업**:\n    1. **템플릿 설계**: 마크다운 문서의 템플릿을 설계합니다. (예: 제목, 부제목, Bullet Points 등)\n    2. **문서 변환**: 요약된 내용과 키워드를 사용하여 마크다운 문서를 생성합니다.\n\n### 5. 사용자 인터페이스 (UI) 개발\n\n- **목표"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-07-25-SeSAC-판다스 라이브러리.md",
    "title": "[SeSAC]판다스, Seaborn, Matplotlib 라이브러리",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 19. 판다스 소개 및 데이터 불러오기\n\n### 판다스란?\n- 파이썬에서 데이터분석을 할 때 가장 많이 쓰이는 라이브러리\n- 표 형태의 데이터를 다루는 다양한 기능을 제공\n- 데이터 가시화\n\n1. 엑셀, csv등 다양한 데이터 형식 지원\n2. 결측치 처리 기능\n3. 데이터 형태 바꾸기\n4. 데이터 삭제 및 추가\n5. 그룹화, 정렬, 결합\n6. 시계열 데이터\n7. 문자열 및 날짜/시간 지원\n\n\n### open() 함수\n- 쓰기\n```python\nf = open('hello.txt', 'wt')\nf.write('hello')\nf.close()\n```\n\n- 읽기\n```python\nf = open('hello.txt', 'rt')\ndata = f.read()\nf.close()\nprint(data) # hello\n```\n\n- 추가\n```python\nf = open('hello.txt', 'at')\nf.write('hello')\nf.close()\n```\n\n## 20. 시리즈와 데이터프레임 이해하기\n\n표 형태의 데이터\n- 열: 시리즈\n- 표: 데이터프레임\n\n- 시리즈\n\t- 데이터프레임에서 각각의 열\n\t- 판다스의 pd.Series() 함수로 생성\n- 딕셔너리를 사용하여 시리즈 만들기\n\n```python\ndic = {\"a\":1, \"b\":2, \"c\":3}\ns = pd.Series(dic)\n```\n\n- 리스트를 사용하여 시리즈 만들기\n\n```python\nbox = ['홍길동', '이순신', '아이유']\ns = pd.Series(box, index=['가', '나', '다'])\n```\n\n- 시리즈 행 이름 확인\n```python\ns.index\n```\n\n- 시리즈 값 확인\n```python\ns.values\n```\n\n- 딕셔너리로 데이터프레임 만들기\n```python\ndic = {'이름':['홍길동', '이순신','아이유'],\n\t  '성별':['남자', '남자', '여자'],\n\t  \"나이\":[40,50,20]}\npd.DataFrame(dic, index = ['A', 'B'"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-11-파이썬 라이브러리를 활용한 데이터분석-2.md",
    "title": "[SeSAC]파이썬 라이브러리를 활용한 데이터분석-2",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## Intro: \n\n## Chapter 4. 넘파이 기본: 배열과 벡터 연산\n\n\n## Chapter 5. Pandas\n\n### 기초 개념\n\n```python\nimport numpy as np\nimport pandas as pd\nlogx = np.logspace(0, 1, 100)\nlinx = np.linspace(0, 10, 100)\n\ndf = pd.DataFrame()\ndf['logspace'] = logx  #컬럼명 logspace의 Series 데이터\ndf['linspace'] = linx  # 컬럼명 linespace의 Series 데이터\n```\n\n\n### Column명 변경\n\nDataFrame의 컬럼명 Rename 3가지 방법\n- `pd.DataFrame.columns = [ '칼럼1', '칼럼2', … , ]` \n- `pd.DataFrame.rename( { 'OLD칼럼명' : 'NEW칼럼명', …, }, axis=1)`\n- `pd.DataFrame.rename(columns={ 'OLD칼럼명' : 'NEW칼럼명', …, })`\n\n\n### \n\n\n## 몬티홀 딜레마\n\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# 그림 그리는 환경\nimport random\n\ndef init():\n    doors = ['A', 'B', 'C']\n    choice = random.choice(doors)\n    prize = random.choice(doors)\n    return choice, prize\n\ndef MC(mychoice, prize):\n    candidates = [\"A\", \"B\", \"C\"]\n    \n    if mychoice == prize:\n        candidates.remove(prize)\n    else:\n        candidates = [x for x in candidates if x !="
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-09-파이썬 라이브러리를 활용한 데이터 분석-1.md",
    "title": "[SeSAC]파이썬 라이브러리를 활용한 데이터 분석-1",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 파이썬 라이브러리를 활용한 데이터 분석\n- 웹 도서: https://wesmckinney.com/book\n- 코드: https://github.com/wesm/pydata-book\n\n\n## Chapter 1. 시작하기 전에\n### 1.2 파이썬을 사용하면 안되는 경우\n- 속도가 중요시 되는 경우 C계열 사용\n- 동시성이 높은 멀티스레드 사용이 요구 시\n\n### 1.3 필수 파이썬 라이브러리\n- Numpy\n- Pandas\n- Matplotlib\n- IPython, Jupyter\n- SciPy\n- Scikit-learn\n- Statsmodels\n- others\n\n\n> 기존 conda 환경중에 버전이 꼬인것들이 많아서 다 지우고 책 환경만 하나 새로 만들었다\n\n\n```sh\nconda config --add channels conda-forge\nconda config --set channel_priority strict\n\nconda create -y -n pydata-book python=3.11\nconda env list\n\nconda activate pydata-book\nconda install -y pandas jupyter matplotlib\nconda install lxml beautifulsoup4 html5lib openpyxl requests sqlalchemy seaborn scipy statsmodels patsy scikit-learn pyarrow pytables numba\n```\n\n\n\n> 주피터에 새로 생긴 환경이 생기지 않아 검색해 방법을 찾아냈다\n\n```sh\nsource activate pydata-book\npip install ipykernel\npython -m ipykernel install --user --name pydata-book --display-name \"Python (pydata-book)\"\n```\n\n\n## Chapter 2. 파이썬 기초, IPython과 주피터 노트북\n### 2.1 파이썬 인터프리터\n\n#### 인터"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-07-31-SeSAC-파이썬 데이터 처리 프로그래밍-1일차.md",
    "title": "[SeSAC]파이썬 데이터 처리 프로그래밍-1일차(BeautifulSoup)",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n\n강사님: 이태희 강사님\n\n# 4. SQL 고급 문법\n# 4-2 두 테이블을 묶는 조인\n\n### 조인(Join)\n- 두 개의 테이블을 서로 묶어서 하나의 결과를 만들어 내는 것\n\n## 내부 조인\n- 두 테이블을 연결할 때 가장 많이 사용되는 것이 내부 조인\n\n### 일대다 관계의 이해\n- 두 테이블의 조인을 위해서는 테이블이 **일대다(one to many)** 관계로 연결되어 있어야 함\n- ex) market_db의 회원 테이블과 구매 테이블\n- 주로 기본 키(Primary Key)와 외래 키(Foreign Key) 관계로 맺어져 있다\n- 'PK-FK' 관계라고도 부른다\n\n```sql\nSELECT *\nFROM buy\nINNER JOIN member\nON buy.mem_id = member.mem_id;\n```\n\n### 내부 조인의 기본\n- `JOIN`이라고만 써도 `INNER JOIN`으로 인식\n- 두 개의 테이블(buy, member)을 조인하는 경우 동일한 열 이름이 존재한다면 **`테이블_이름.열_이름`** 형식으로 표기해야 한다\n\n```sql\nSELECT member.mem_id, prod_name, mem_name, addr\nFROM buy\nINNER JOIN member\nON buy.mem_id = member.mem_id;\n```\n\n## 외부 조인\n- 두 테이블에 모두 데이터가 있어야만 나오는 내부 조인과는 달리 외부 조인은 한쪽에만 데이터가 있어도 결과가 나옴\n\n### 외부 조인의 기본\n- 필요한 내용이 한쪽 테이블에만 있어도 결과 추출 가능\n\n```SQL\nSELECT <열 목록>\nFROM <첫 번째 테이블(LEFT 테이블)>\n<LEFT | RIGHT FULL> OUTER JOIN <두 번째 테이블(RIGHT 테이블>\nON <조인될 조건>\n[WHERE 검색 조건];\n```\n\n\n### FULL OUTER JOIN\n- 왼쪽 외부 조인과 오른쪽 외부 조인의 합\n- 왼쪽이든 오른쪽이든 한쪽에 들어있는 내용이면 출력\n\n\n## 기타 조인\n\n### 상호"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-10-23-SeSAC 3주년 프로젝트.md",
    "title": "SeSAC 3주년 프로젝트",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n# 프로젝트 배경\n\n---\n\n### 팀 구성원\n- [박주원](https://github.com/ParkSeoul)\n- [박어진](https://github.com/likecola)\n- [신승엽](https://github.com/syshin0116)\n- [이현지](https://github.com/FrontHeadNULL)\n- [이혜원](https://github.com/dev-hw)\n- [최준혁](https://github.com/kimbap918)\n\n<br>\n\n영등포 새싹 캠퍼스의 3주년 **생일축하를 기념하는 영스데이에 초대**됐다!\n\n### 목표\n\n- 새싹이의 생일을 축하하기 위해 **AI로 작곡&작사&캐릭터를 만들자!**\n\n### 로고\n\n> **새싹을 통해서 수강생들의 미래가 피어나기를 바라는 마음**으로 제작\n\n‘3주년 생일축하 파티를 위한 작곡&작사&캐릭터 생성’ 이라는 주제로 발표를 준비하며\n\n발표 주제에 맞게 새싹과 음악을 조합했습니다.\n\n![](https://i.imgur.com/EBFIpuU.png)\n\n<br>\n\n# 프로젝트 순서\n\n---\n\n**[기획]**\n\n**이미지** : 다양한 생성 모델을 통해 새싹 캐릭터 제작\n\n**영상** : 이미지 + 음악 = 영상 모델에 직접 만든 노래 삽입, deforum을 사용해서 영상 제작\n\n**음악** : 생성 모델을 통해 가사 생성, 멜로디 모델, 음악 생성 모델을 통해 음악 제작\n\n<br>\n\n**[순서]**\n\n데이터 정제 및 사용 : 웹 크롤링을 통해 후기 데이터 수집, 토큰화 & 불용어 처리\n\n가사 생성 : 정제된 데이터를 통해서 KoGPT2를 사용해서 가사를 생성\n\n이미지 제작 : 오리지널 새싹 캐릭터 제작, 영상에 사용할 수 있는 다양한 이미지 제작 (Stable diffusion)\n\n음악 제작 : 생성된 가사와 생일 축하 분위기에 맞는 음악 생성 (SunoAI)\n\n영상 제작 : 캐릭터와 음악을 합성해서 입모양을 움직일 수 있는 영상 제작\n\n<br>\n\n# 사용 데이터\n\n---\n\n### **웹 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-09-24-SeSAC-Natural Language Process(자연어 처리).md",
    "title": "Natural Language Process(자연어 처리)",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n## 1. 자연어 처리의 개념\n### 자연어 처리(Natural Language Processing)란?\n- 자연어의 의미를 분석하여 컴퓨터가 처리할 수 있도록 하는 일\n- ex) 음성 인식, 요약, 번역, 감성 분석, 텍스트 분류, 질의 응답 시스텝, 챗복 등...\n- '텍스트 분석' 이라고도 불리우나 '자연어 처리'라고 하면 인공지능을 이용한 분야라는 의미가 추가된다\n### 자연어 처리를 배워야 하는 이유\n- 회사 도메인(유통, 금융, 제조)를 가리지 않고 수요가 있음 \n- 현재 실무에서 여전히 PLM(Pre-trained Language Model)을 이용한 자연어 사용\n- 처리할 수 있는 중급 이상의 인력이 많지 않음 -> 기회!\n- 성능 좋은 오픈 소스가 지속적으로 공개되고 있다\n\n### 한국어 NLP 특징\n한국어 자연어 처리는 영어보다 훨씬 어렵다\n- 교착어 → 형태소 분석기의 필요성\n\n\n|        | 대표언어                 | 특징                                                          |\n| ------ | ------------------------ | ------------------------------------------------------------- |\n| 교착어 | 한국어, 일본어, 몽골어   | 어간에 접사가 붙어, 단어를 이루고 의미와 문법적 기능이 정해짐 |\n| 굴절어 | 라틴어, 독일어, 러시아어 | 단어의 형태가 변함으로써 문법적 기능이 정해짐                 |\n| 고립어 | 영어, 중국어             | 어순에 따라 단어의 문법적 기능이 정해짐                       |\n\n- 한국어 띄어쓰기가 잘 지켜지지 않는다\n- 어순이 그렇게 중요하지 않다\n- 한자어라는 특성상 하나의 음절조차도 다른 의미를 가질 수 있다\n- 주어가 손쉽게 생략된다\n- 데이터와 언어에 특화된 모델이 영어에 비해 부족하다\n\n### 토큰화(Toke"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-10-데이터분석 관련 영상 시청.md",
    "title": "[SeSAC]데이터분석 관련 영상 시청",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 프로젝트 발표 시청\n\n### 땀내 줄이는 Data와 Feature 다루기\n\n\n#### Intro: 땀내나는 이야기: 수학과 통계를 잘 모르는 개발자의 이야기\n\n2017 Kaggle 데이터분석 프로젝트중 겪은 어려움 survey:\n- 데이터 cleaning\n- 결측치 처리\n\n- Data: 우리에게 주어진 날것\n- Feature: 신호와 소음\n\n결측치 시각화 라이브러리: missingno\n\n결측치 종류\n1. MCAR(Missing Completely at Random)\n\t- 완전 무작위 결측\n2. MAR(Missing at Random)\n\t- 임의적 결측 발생\n3. NI(Non-ignorable)\n\t- 무시할 수 없는 결측 발생\n\n결측치 처리 방법\n1) 완전 제거법(List-wise deletion)\n\t- 가장 보편적으로 사용되는 방법\n\t- 결측율이 높을 대 정보 손실\n\t- 각 변수의 분산을 증가하게 하는 비효울적인 방법\n2) 단일대체방법(Single Imputation)\n\t- 다양성을 반영하지 못함\n\t- 관측된 자료에 의존하는 문제\n\t- 구간을 나누어 구간별 평균/중앙값/최빈값을 구해서 대체\n3) 다중대체방법(Multiple Inputation)\n\t- 결측이 완전 무작위로 발생한다는 가정\n\t- 대체가 가능한 값들의 분포로 부터 추출된 값으로 대체한 완전한 데이터세트를 만들어 대체\n\n\n#### Imputation\n\nscikit-learn Imputer\n- 평균값, 중앙값, 최빈값으로 결측치를 채워줌\n\n```python\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer()\ndataset['column'] = imputer.fit_transform(Dataset['column']).values.reshape(-1, 1))\n```\n\n\npredictive_imputer: R의 MissForest의 파이썬 버전\n\n\n#### Feature Engineering\n\n#### 범주형 데이터 다루기\n\nOne-Hot-"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-28-SeSAC-혼공 머신러닝+딥러닝-Ch5트리 알고리즘.md",
    "title": "[SeSAC]혼공 머신러닝+딥러닝 Ch5. 트리 알고리즘",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 05-1 결정 트리\n\n\n---\n\n### Information Gain (정보 이득)\n\n**정의:** \nInformation Gain은 어떤 속성을 기준으로 데이터를 분할했을 때 얻을 수 있는 엔트로피의 감소량이다. 결정 트리 알고리즘에서는 Information Gain이 최대가 되는 속성으로 데이터를 분할한다.\n\n**수식:** \n$$\n\\text{Information Gain} = \\text{Entropy(parent)} - \\sum \\left( \\frac{\\text{number of samples in child}}{\\text{number of samples in parent}} \\times \\text{Entropy(child)} \\right)\n$$\n\n**엔트로피 수식:** \n$$\n\\text{Entropy}(S) = -p_+ \\log_2(p_+) - p_- \\log_2(p_-)\n$$\n여기서 \\( p_+ \\)는 양성 샘플의 비율, \\( p_- \\)는 음성 샘플의 비율이다.\n\n---\n\n### Gini Impurity (지니 불순도)\n\n**정의:** \nGini Impurity는 임의로 선택된 샘플이 잘못 분류될 확률을 측정한다. 결정 트리 알고리즘에서는 Gini Impurity가 낮은 속성으로 데이터를 분할한다.\n\n**수식:** \n$$\n\\text{Gini Impurity}(S) = 1 - (p_+^2 + p_-^2)\n$$\n여기서 \\( p_+ \\)는 양성 샘플의 비율, \\( p_- \\)는 음성 샘플의 비율이다.\n\n---\n\n\n> 모델과 알고리즘의 차이(Decision Tree는 사실 Decision Model이어야 한다?)\n\n\n### 로지스틱 회귀로 와인 분류하기\n```python\nimport pandas as pd\n\nwine = pd.read_csv('https://bit.ly/wine_csv_data')\n\nwine.head()\n\nwine.info()\n\nwine.describe()\n\ndata = wine[['alcohol', 'sugar', 'pH']].to"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-11-29-Transformers 강의 정리.md",
    "title": "Transformers",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## Intro: \n### Attention Function\n\n- Q = Query: t 시점의 디코더 셀에서의 은닉 상태\n\t- 현재 처리하고 있는 단어나 문장 부분\n- K = Key: 모든 시점의 인코더 셀의 은닉 상태들\n\t- 비교 대상이 되는 데이터 세트에서의 요소들\n- V = Values : 모든 시점의 인코더 셀의 은닉 상태들\n\t- 각 Key에 연관된 출력값\n\n\n![](https://i.imgur.com/GFzEHdt.png)\n\n#### 예시\n\n'나는 학교에 간다'를 영어로 번역한다면\n\n- Key : 번역 모델이 학습한 데이터에서 '나는 학교에 간다'와 유사한 구조나 의미를 가진 요소들\n- Query: '나는 학교에 간다'라는 문장의 각 단어\n- Value: '나는 학교에 간다'에 해당하는 영어 문장 구조의 요소들이 Value\n\n- Attention Function은 이 세 요소를 사용하여 입력된 Query와 가장 관련이 높은 정보를 Key-Value 쌍에서 찾아냄. \n- 이 과정을 통해, 모델은 '나는 학교에 간다'라는 문장의 각 단어나 구문이 영어로 어떻게 번역되어야 할지를 학습한 데이터를 기반으로 결정\n\n예를 들어, '나는'이라는 단어(Query)에 대해, 모델은 학습 데이터에서 이와 관련된 Key-Value 쌍을 찾아 'I'(Value)로 번역한다. 이러한 과정이 전체 문장에 걸쳐 이루어지며, 최종적으로 '나는 학교에 간다'는 'I go to school'로 변환된다.\n\n이 과정에서 중요한 것은 모델이 각 단어의 맥락을 이해하고, 문장 전체의 의미를 유지하면서 적절한 번역을 찾아내는 것이다.\n\n\n### Seq to Seq 의 문제점\n\n- RNN을 사용했기 때문에 문장이 길어질수록 **기울기 소실 문제**가 발생. 이를 LSTM으로 보정하지만 완벽히 방지할 수 있는 것은 아님\n- **인코더 부분에서 입력 시퀀스를 고정된 크기의 vector로 만들기 때문에 정보를 압축하는 과정에서 손실**이 발생. \n- 이러한 문제는 입력 시퀀스가 클수록 성능을"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-11-20-딥러닝 영상처리2.md",
    "title": "딥러닝 영상처리2",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n### General Object Detection Framework\n\n1. **Region Proposal**\n    - 이미지 안의 잠재적 객체 위치 식별\n    - 다양한 크기와 비율로 이미지 분할, 각 영역 평가\n    - 이 단계에서 R-CNN과 같은 방법 활용\n\n2. **Feature Extraction and Network Predictions**\n    - 영역 제안 후, 각 영역에서 특징 추출. 주로 CNN 사용\n    - 추출된 특징을 바탕으로 네트워크가 객체 클래스와 위치 예측\n    - Faster R-CNN, YOLO, SSD 등이 이 단계에서 사용\n\n3. **Non-Maximum Suppression (NMS)**\n    - 중복 영역 제안 중 최적 예측 선택\n    - 최대 점수 예측 유지, 중복 영역 제거\n    - 정확도 향상과 중복 감소에 중요\n\n4. **Evaluation Metrics**\n    - 객체 탐지 모델 성능 평가\n    - 정밀도, 재현율, F1 스코어 등을 주요 지표로 사용\n    - 클래스별 성능은 Average Precision(AP)으로 평가\n\n> Two-phase system: 특정 장소에 뭐가 있을것 같다 라고 먼저 생각 한 후에, Detect 한다. 즉, Region proposal 이후 Detectiong\n### Selective Search\n- 이미지 내 객체 후보 영역 식별 방법\n- 영역 제안에서 중요한 역할, 객체 탐지 성공률에 영향\n\n### Object-detector Evaluation Metrics\n- **Frames per Second (FPS)**\n    - 탐지 속도 측정\n- **Mean Average Precision (mAP)**\n    - 다양한 임계값에서 평균 정밀도 측정\n- **Intersection Over Union (IOU)**\n    - 예측 및 실제 경계 상자의 겹침 정도 측정\n\n### R-CNN의 단점\n- 객체 탐지 속도 느림\n- 훈련 과정 여러 단계로 나뉨, "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-14-파이썬 라이브러리를 활용한 데이터분석-3.md",
    "title": "[SeSAC]파이썬 라이브러리를 활용한 데이터분석-3",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n\n### 데이터분석 프로젝트 과정\n\n![](https://i.imgur.com/gVpHBX8.png)\n\n\n### EDA(Exploratory Data Analysis)\n\"탐색적 데이터분석은 우리가 존재한다고\"\n\n- 데이터과학 과정의 핵심적인 부분으로 데이터에 대한 이해를 높이는것\n- 모델링에 앞서 선행되는 작업으로 데이터의 분포나 변수간 관계 파악\n- EDA의 기본 도구는 도표(plot), 그래프(graph), 요약통계(summary statistics)\n\n- e\n![](https://i.imgur.com/ve2sXIw.png)\n\n## 데이터 시각화\n\n### Matplotlib 기초개념\n- 2차원 데이터를 시각화하기 위한 패키지\n- 다양한 출력 형식(PNG, SVG, JPG 등)으로 저장 가능\n\n\n```python\n%matplotlib inline  # 주피터 내부에 출력하겟다는 뜻\nimport matplotlib.pyplot as plt\n\nfig = plt.figure()\nax = fig.add_sublplt(111)\ndata = [0,1]\nax.plot(data)\n\nplt.show()\nfig.savefig('image.png')  # 이미지 저장\n```\n\n### Figure와 Subplot\n- Figure: 서브 플롯 작성하는 틀\n- Subplot: 그래프를 작성하기 위한 영역\n- Axes: Figure 안의 (Sub)Plot들은 각각의 Axes 객체 속함\n- Axix: 플롯의 가로 축이나 세로 축을 의미\n\n\n![](https://i.imgur.com/1gBb38w.png)\n\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/2023-08-25-SeSAC-Roboflow.md",
    "title": "[SeSAC]Roboflow",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## Roboflow\n\n얀 르쿤(Yann LeCun): \n- Convolutional Neural Network 창시자, 페이스북 FAIR 설립자\n- MNIST\n\n> 특이점이 온다: 레이 커즈와일 책\n\n\n## 딥러닝 영상처리\n\n### AI Project Cycle\n1. Problem Scoping\n2. Data Acquisition\n3. Data Exploration\n4. Modeling\n5. Evaluation\n6. Deployment\n\nYOLO의 가장 큰 장점:\n- 빠르다\n\n자율주행에서 YOLO를 쓰지 않는 이유: \n- 정확성이 떨어진다\n\n\n![](https://i.imgur.com/GebX6VH.png)\n\n\n\nImage Classification과 Object Detection의 차이: \n- Image Classification과는 다르게 Object Detection은 물체가 무엇인지에 대한 정보와 함께 위치정보도 제공한다\n\n\n객체 인식과 객체 인지의 차이\n- 객체 인식: 위치 + 라벨\n- 객체 인지: 위치\n\nImageNet - 1000만장이 넘는 이미지에 1000개 class\n\nLabel과 Anotate의 차이:\n- Label: 라벨(Classification)\n- Anotate: 라벨 + 위치정보 (Object Detection)\n\nTrain_test_split 함수의 파라메터:\n- stratify \n\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/data-analysis/2023-07-28-SeSAC-인공지능.md",
    "title": "[SeSAC]인공지능",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 1. 데이터와 인공지능\n\n### 데이터와 인공지능의 관계\n- 인공지능을 이해하기 위해서는 먼저 빅데이터가 무엇인지 알아야 한다\n- 빅테이터 알기 위해서는 데이터 테크놀러지(DT)가 무엇인지 알아야 한다\n\n- 1990년대부터 인터넷 대중화\n- 2000년대부터 인터넷에 일반 사람들이 글을 제3자에게 공유하는 정보 제공자 역할도 가능\n- 수집할 수 잇는 데이터 양이 증가하면서 IT는 DT(Data Technology)로 확대\n\n![](https://i.imgur.com/e9UTQVT.png)\n\n### 빅테이터에 대한 오해\n- 데이터의 양으로 구분하는것이 아니라, 전체 데이터 중 일부를 인포메이션으로 선별했는지 여부\n- 발생한 데이터를 모두 수용했다면 빅 데이터이며, 그렇지 않다면 빅데이터라고 보기 힘들다\n\n### DT의 중요성\n- 사람의 판단으로 데이터를 처리하기에는 데이터의 양이 너무 많음\n- 사람의 논리로 빅 데이터를 해석하면 일부의 데이터만 해석될 위험이 있음\n\n![](https://i.imgur.com/sCWdnX8.png)\n\n## 2. 머신러닝에 필요한 수학 개념\n\n### 기초 선형대수\n- 데이터를 다루는 법, 연립방정식을 사용하여 미지수의 값을 구하는 법 등에 사용되는 데이터분석의 기본적인 도구\n\t- 스칼라: 숫자 하나로 이루어진 데이터\n\t- 벡터 여러 숫자로 이루어진 데이터 레코드\n\t- 형렬: 벡터가 여러 개인 데이터 집합\n\t- 텐서: 같은 크기의 행렬이 여러개 있는 것\n\n\n### 행렬의 덧셈과 뺄셈\n- 같은 크기를 가진 두 개의 벡터나 행렬은 덧셈과 뺄셈을 할 수 있다\n\n![](https://i.imgur.com/xTZff7D.png)\n\n### 스칼라와 벡터/행렬의 곱셈\n- 행렬에 스칼라를 곱하면 모든 원소에 스칼라를 곱하는 것과 같다\n\n![](https://i.imgur.com/mImbmS4.png)\n\n\n### 벡터와 벡터의 곱셈\n- 내적\n\t1. 두 벡터의 차원(길이)이 같아야 한다\n\t2. 앞의 벡터가 행 벡터이고, 뒤의 벡터가 열 벡터이어"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/data-analysis/2023-07-19-SeSAC-데이터 분석 기초-2일차.md",
    "title": "[SeSAC]데이터 분석 기초-2일차",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# Pandas\n\n## Slicing 주의\n`df.drop([start, end])`: end도 포함\n![](https://velog.velcdn.com/images/syshin0116/post/ccacd06b-6cca-44fa-9c2e-e0919de49a42/image.png)\n\n`df[start:end]`: end 미포함\n![](https://velog.velcdn.com/images/syshin0116/post/b9cd87c3-bd36-4367-bbb2-a7c70ee0c8c4/image.png)\n\n## 명령어:\n### df.dropna \n**Parameters:**\naxis : {0 or 'index', 1 or 'columns'}, default 0  \n    결측값을 포함하는 행 또는 열을 제거할지 여부를 결정합니다.<br>\n- 0, or 'index' : 결측값을 포함하는 행 제거\n- 1, or 'columns' : 결측값을 포함하는 열 제거<br>\nhow : {'any', 'all'}, default 'any'  \n    최소한 하나의 NA 값이 있거나 모든 NA 값이 있는 경우 DataFrame에서 행 또는 열이 제거되는 방식을 결정합니다.\n- 'any' : 만약 NA 값이 하나라도 있으면 해당 행 또는 열 제거\n- 'all' : 모든 값이 NA인 경우 해당 행 또는 열 제거\n<br>\nthresh : int, optional  \n    non-NA 값의 수를 요구합니다. how와 함께 사용할 수 없습니다.  \nsubset : 열 레이블 또는 레이블 시퀀스, optional  \n    고려할 다른 축의 레이블입니다. 예를 들어, 행을 삭제하는 경우 열의 리스트여야 합니다.  \ninplace : bool, default False\n\n### df.duplicated(subset=['column1', 'column2', 'column3'], keep=False):\n\n![](https://velog.velcdn.com/images/syshin0116/"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/data-analysis/2023-07-18-SeSAC-데이터 분석 기초-1일차.md",
    "title": "[SeSAC]데이터 분석 기초-1일차",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n<!-- \nSBA AI 취업 사관\nclassroom.google.com\n수업코드: filhock, 54pzy5v\n -->\n# 데이터분석 기초\n\n이미테이션 게임\n### Can machines think? \n**Yes, But machines can't think as people do**\n-> 사람도 사람이 어떻게 생각하는지 모른다\n-> 지능적 행위의 결과물에 대한 모방만 가능하다\n지능을 모방하는 방법\n- 탐색적 방법\n\n### 인공지능 주요 인물\n- 마빈 리 민스키(Marvin Lee Minsky) : 지식의 표현과 추론(knowledge representation and reasoning), 기호주의자\n- 프랑크 로젠블랫(Frank Rosenblatt) : 현대 딥러닝의 단초가 된 퍼셉트론(Perceptron)을 개발, 연결주의자\n- 제프리 에베레스트 힌튼(Geoffrey Everest Hinton) : 인공지능(AI) 분야를 개척한 영국 출신의 인지심리학자이자 컴퓨터 과학자\n- 에츠허르 비버 데이크스트라(Edsger Wybe Dijkstra): 다익스트라 알고리즘(최단 경로)를 개발, 튜링상 수상\n\n## prolog 언어\n#prolog\nhttps://swish.swi-prolog.org/\n\n> ### prolog란?\n《 인공지능 분야에서 사용하는 논리형 고급 프로그래밍 언어. 》\n- 1973년 프랑스 마르세유 대학교의 컴퓨터 과학자 알랭 콜메르(Alan Colmerauer)와 논리학자 P. 루셀이 개발한 언어로서, 논리식을 토대로 하여 오브젝트와 오브젝트 간의 관계에 관한 문제를 해결하기 위해 사용합니다.\n- 영어 단어로 표현되는 사실(fact)과 규칙(rule)으로 프로그램을 표현하며, 논리학에서의 1차 서술 논리의 규칙을 그대로 따르고 있습니다. 주로 숫자 계산보다는 인공 지능 분야에서의 논리적인 추론이나 패턴 매칭, 리스트 처리 등에 적합합니다.\n- 프롤로그(PROLOG)는 술어 논리식을 프로그램, 증명하는 것을 계산한다는 것으로 간주하는 관점에서 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SeSAC/data-analysis/2023-07-20-SeSAC-SQL로 데이터베이스 다루기-1일차.md",
    "title": "[SeSAC]SQL로 데이터베이스 다루기-1일차",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n\n### 데이터베이스란?\n- '데이터의 집합'\n\n### DBMS란? \n- 데이터베이스를 관리하는 프로그램\n- 특정 목적을 처리하기 위한 프로그램\n\n### 계층형(Hierarchical) DB:\n- 계층적으로 구축되고 전형적으로 반전 트리(inverted tree) 형태로 그려짐\n- 계층형 데이터베이스에서 관계는 '부모/자식' 이라는 용어로 표현\n- 부모 테이블은 하나 이상의 자식 테이블들과 관계를 맺을 수 있지만, 자식 테이블은 오직 하나의 부모 테이블에 한해 관계를 맺을 수 있다\n\n![](https://velog.velcdn.com/images/syshin0116/post/68218f1f-8acf-4db7-87bb-99ee35cc923e/image.png)\n전형적인 계층형 데이터베이스의 다이어그램\n\n#### 장점  \n- 테이블 구조들 사이에 명확한 링크가 있기 때문에 사용자가 데이터 추출을 빠르게 할 수 있다.  \n- 참조 무결성이 내장되어 있고 이것이 자동적으로 강화된다.\n#### 단점  \n- 복잡한 관계를 지원할 수 없고, 따라서 중복 데이터로 인해 종종 문제가 발생한다.\n\n### 관계형(Relational) DB:\n- 데이터베이스는 1969년에 처음으로 고안\n- 오늘날 데이터베이스 관리 분야에서 가장 널리 사용되는 데이터베이스 모델\n- 관계형 모델의 아버지인 에드거 F. 코드 박사가 1970년 6월에 '대규모 공유 데이터 뱅크를 위한 관계형 데이터 모델(A Relational Model of Data for Large Shared Databanks)'이라는 제목의 획기적인 연구에서 새로운 관계형 모델을 발표 \n\n\n - 데이터를 릴레이션에 저장\n - 각 릴레이션은 투플(tuples, 또는 레코드)과 속성(또는 필드)들로 구성\n - 테이블 내의 레코드와 필드들의 물리적 순서는 전혀 중요하지 않고, 테이블 내의 각 레코드는 유일한 값을 가지는 필드에 의해 식별됨\n - 데이터를 추출하기 위해서 레코드의 물리적 위치를 알 필요가 없다는 것이 다른 모델과 차이"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Docker/2024-04-09-원티드 프리온보딩 백엔드-Docker-3일차.md",
    "title": "원티드 프리온보딩 백엔드-Docker-3일차",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 전체 과정 설명\n\n- 과정 설계 - 이론 + 실습시연 + 실제 면접 질문 + QnA(매 교시 시작시간 10분 + 수업 마지막 시간 30분 전 - QnA시간양은 유동적으로 조정)  \n    - 4회동안 compact 하게 큰 그림을 그려봅시다 - 세부 사항 학습 자습 병행 (mac os / windows)  \n    - 20% 핵심\n- 포트폴리오에 어떻게 적용되는지 - 서비스 운영환경에 대한 경험 - 운영환경 구축 - CI/CD, 컨테이너\n- ![SDLC_BWC.png](https://bigwater.consulting/wp-content/uploads/2019/04/SDLC_BWC.png)\n\n오늘의 면접질문 원픽\n\n- 모던 웹 개발에서 CI/CD가 왜 필요하게 되었을까? (CI/CD 구축 왜 하셨어요?)\n\n## CI / CD 기초 개념과 아키텍쳐\n\n### CI/CD\n\n- ci/cd 란  \n    ![ci-cd-flow-desktop.png?cicd=32h281b](https://www.redhat.com/rhdc/managed-files/ci-cd-flow-desktop.png?cicd=32h281b)\n- from. “CI/CD(CI CD, 지속적 통합/지속적 배포): 개념, 툴, 구축, 차이.” _Redhat.com_, 2024, [www.redhat.com/ko/topics/devops/what-is-ci-cd](http://www.redhat.com/ko/topics/devops/what-is-ci-cd). (좋은 아티클이니 한번 꼭 읽어보세요!)\n\n‌\n\n- CI/CD는 소프트웨어 개발 과정에서의 효율성과 신속성을 극대화하는 자동화된 프레임워크를 제공한다. 이 접근 방식은 개발부터 운영까지의 소프트웨어 개발 라이프사이클의 모든 단계를 아우르며, 지속적 통합, 지속적 전달, 지속적 배포의 세 주요 구성 요소로 구분된다.\n\n### 지속적 통합 (CI)\n\n- 개발자들이 작업한 코드를 주기적으로 공유 레포지토리에 병합함으로써, 코드의 통합을 자동화하는 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Docker/2024-04-12-원티드 프리온보딩 백엔드-Docker-4일차.md",
    "title": "원티드 프리온보딩 백엔드-Docker-4일차",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 전체 과정 설명\n\n- 과정 설계 - 이론 + 실습시연 + 실제 면접 질문 + QnA(매 교시 시작시간 10분 + 수업 마지막 시간 30분 전 - QnA시간양은 유동적으로 조정)  \n    - 4회동안 compact 하게 큰 그림을 그려봅시다 - 세부 사항 학습 자습 병행 (mac os / windows)  \n    - 20% 핵심\n- 포트폴리오에 어떻게 적용되는지 - 서비스 운영환경에 대한 경험 - 운영환경 구축 - CI/CD, 컨테이너\n\n---\n\n- 싱글 서버 도커의 한계 -> 쿠버네티스\n- 배포 기본기 : 용어 / 배포 전략\n- 추천 아키텍쳐\n- 실습 - github action 사용해서 ecr 에 업로드하기\n    - AWS cloud 사용할 때 체크포인트\n- 자습키워드 - 면접 질문\n\n---\n\n### 쿠버네티스란?\n\n- 서버의 한계에서부터 생각해봅시다\n    - 물리적으로 서버 한대에 도커가 설치가 됨. 사용자가 늘어나서 서버를 늘려야한다면?\n    - -> [면접] 사용자가 늘어나는데 서버를 어떻게 바꾸어야할까요? - [용어] 스케일 업/아웃\n        \n        - 1. 사용자 수가 늘어날 때 서버를 늘리는 것은 일반적으로 필요한 조치.\n        \n        1. **성능 유지**\n        \n        - 서버는 동시에 처리할 수 있는 요청의 수에 한계가 있습니다. 사용자 수가 증가하면, 동시 요청의 수가 늘어나고 이는 서버의 처리 능력을 초과할 수 있습니다. 서버를 늘려서 이러한 요청을 효과적으로 분산시키면, 시스템의 응답 시간을 개선하고 사용자 경험을 유지할 수 있습니다.\n        \n        2. **가용성 향상**\n        \n        - 단일 서버에 문제가 발생하면 전체 서비스에 영향을 미칠 수 있습니다. 서버를 여러 대 운영하면 하나의 서버에 문제가 생겨도 다른 서버가 처리를 계속 수행할 수 있어 서비스의 중단 시간을 줄일 수 있습니다. 이는 고가용성을 보장하는 데 중요합니다.\n    "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Docker/2023-12-23-Docker.md",
    "title": "Docker",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n## Table of Contents\n\n1. What and Why of Docker?\n\t- What is Docker?\n\t- What problems does it solve?\n\t- Softwarer Development before and after Docker\n\t- Software Deployment before and after Docker\n2. Docker vs Virtual Machines\n\t- Understand difference of Docker and VM\n\t- Benefits of Docker\n3. Install Docker locally\n4. Images vs Containers\n5. Public and Private Registries\n6. Run Containers\n\t- Pull and run containers form public repo\n\t- Port Binding, Detached Mode etc\n7. Create own Image(Dockerfile)\n\t- Syntax and cnepts of Dockerfile\n\t- We will dockerize a Node.js app\n8. Main Docker commands\n\t- pull, run, start, stop, logs, build\n9. Image Versioning\n10. Docker Workflow Big Picture\n## What and Why of Docker?\n\n### What is Docker?\n- Virtualization software\n- Makes developing and deploying applications much easier\n- Packages applications with all the necessary dependencies, configuration, system tools and runtime\n- Portable artifact, easilty shared and distributed\n### What problems does it s"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Docker/2024-04-05-원티드 프리온보딩 백엔드-Docker-2일차.md",
    "title": "원티드 프리온보딩 백엔드-Docker-2일차",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n## 전체 과정 설명\n\n- 과정 설계 - 이론 + 실습시연 + 실제 면접 질문 + QnA(쉬는 시간 10분 전 + 수업 마지막 시간 30분 전 - QnA시간양은 유동적으로 조정)  \n    - 4회동안 compact 하게 큰 그림을 그려봅시다 - 세부 사항 학습 자습 병행 (mac os / windows)  \n    - 20% 핵심\n    - 포트폴리오에 어떻게 적용되는지 - 서비스 운영환경에 대한 경험\n\n## 주요 컨셉 복습\n\n- Day 01 수업자료 참고\n- ![imgs%2Fapp%2Fsyoh%2FX-efNW8wEv.png?alt=media&token=f1077a2b-a4a4-4000-b682-d0176b90a7e9](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fsyoh%2FX-efNW8wEv.png?alt=media&token=f1077a2b-a4a4-4000-b682-d0176b90a7e9)\n- ![imgs%2Fapp%2Fsyoh%2Ff_r7w9k4MD.png?alt=media&token=27bd630a-cd11-468f-bd1c-480fe44fcc31](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fsyoh%2Ff_r7w9k4MD.png?alt=media&token=27bd630a-cd11-468f-bd1c-480fe44fcc31)\n\n## 로컬 환경에서 Docker 실행\n\n- 자습 문제 실행\n    - 공식 블로그 : [https://www.docker.com/blog/kickstart-your-spring-boot-application-development/](https://www.docker.com/blog/kickstart-your-spring-boot-application-development/)\n        - git"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/SQLD/2023-05-27-SQLD_1과목-데이터 모델링의 이해.md",
    "title": "[SQLD]1과목-데이터 모델링의 이해",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n\n# Part 1. 데이터 모델링의 이해\n\n## 1.1 Modeling\n### 데이터 모델링 정의\n1. 정보시스템 구축 위한 데이터 관점의 업무 분석기법\n2. 현실세계 데이터에 대해 약속된 표기법에 의해 표현하는 과정\n3. 데이터베이스 구축하기 위한 분석, 설계과정\n\n### 모델링의 특징\n\n|        | 모델링의 특징|\n|--------|---------|\n| 추상화 | 현실세계를 일정한 양식, 표기법에 맞추어 표현 (=모형화, 가설적) |\n| 단순화 | 복잡한 현실 게계를 약속된 규약에 의해 제한된 표기법이나 언어로 표현|\n| 명확화 | 누구나 이해하기 쉽게하기 위해 대상에 대한 애매모호함을 제거하고 정확하게 현상을 기술하는 것 |\n\n### 모델링의 세 가지 관점\n1. 데이터 관점: 업무가 어떤 데이터와 관련이 있는지, 데이터간 관계 무엇인지 (What, Data)\n2. 프로세스 관점: 업무가 실제하고 있는 일 무엇인지, 무엇을 해야하는지 (How, Process)\n3. 상관 관점: 업무 처리하는 방법에 따라 데이터 어떻게 영향 받고 있는지 (Interaction)\n\n### 데이터 모델리의 중요성\n- 파급효과가 크다(Leavarage)\n- 복잡한 정보 요구사항의 간결한 표현(Conciseness)\n- 데이터 품질을 유지 (Data Quality)\n\n### 데이터 모델링의 유의점\n\n|  | 데이터 모델링의 중요성 및 유의점 |\n|---|---|\n| 중복 | 같은 시간 같은 데이터 제공 |\n| 비유연성 | 사소한 업무변화에 데이터 모델이 수시로 변경되면 안됨 |\n| 비일관성 | 신용 상태에 대한 갱신 없이 고객의 납부 이력 정보 갱신 안됨(연계성↓) |\n\n### 데이터 모델링의 3단계 진행\n(추상적)개념적 -> 논리적 -> 물리적(구체적)\n\n |  | 개념-논리-물리 데이터 모델 |\n|---|---|\n| 개념적 데이터 모델링 | 추상화 수준이 높고 업무중심적이고 포관적인 수준의 모델링 진행.전사적 데이터 모델링, EA수립시 많이 적용|\n| 논리적 데이터"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Chinese/2024-07-29-중국어 6회.md",
    "title": "중국어 학습 6회 - 기본 단어 정리",
    "description": "중국어 학습 6회차 - 기본 중국어 단어와 한글 뜻 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 중국어 학습 6회차 노트이다. 기본적인 중국어 단어들을 표 형태로 정리하여 중국어-병음-한글 뜻을 체계적으로 학습한다.\n\n\n单词、拼音和韩文意思\n\n|单词|拼音|韩文意思|\n|---|---|---|\n|馅儿|xiàn ér|소|\n|计划|jì huà|계획|\n|语法|yǔ fǎ|문법|\n|处对象|chù duì xiàng|연애|\n|中国菜|zhōng guó cài|중국 요리|\n|咸|xián|짠|\n|烤串儿|kǎo chuàn ér|꼬치|\n\n已经为你整理好了单词、拼音和韩文意思的表格。\n\n这里是更新后的表格：\n\n1. 馅儿 (xiàn ér) - 소\n2. 计划 (jì huà) - 계획\n3. 语法 (yǔ fǎ) - 문법\n4. 处对象 (chù duì xiàng) - 연애\n5. 中国菜 (zhōng guó cài) - 중국 요리\n6. 咸 (xián) - 짠\n7. 烤串儿 (kǎo chuàn ér) - 꼬치 ​"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Chinese/2024-08-02-중국어 8회.md",
    "title": "중국어 학습 8회 - 음식과 요리 표현",
    "description": "중국어 학습 8회차 - 음식과 요리 관련 단어 및 표현 학습",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 중국어 학습 8회차 노트이다. 음식과 요리 관련 단어(五花肉炖酸菜, 锅包肉 등)와 중국 요리명을 중국어로 표현하는 방법을 학습한다. 한국 요리와 중국 요리의 차이점도 포함한다.\n### 단어\n\n| 중국어 단어 | Pinyin                       | 한국어 뜻      |\n| ------ | ---------------------------- | ---------- |\n| 五花肉炖酸菜 | wǔ huā ròu dùn suān cài      | 오겹살 김치 찜   |\n| 撑死了    | chēng sǐ le                  | 너무 배불러 죽겠어 |\n| 军队     | jūn duì                      | 군대         |\n| 建筑     | jiàn zhù                     | 건축         |\n| 刚开始    | gāng kāi shǐ                 | 처음 시작할 때   |\n| 资格证    | zī gé zhèng                  | 자격증        |\n|        |                              |            |\n| 毕业     | bì yè                        | 졸업하다       |\n| 考研     | kǎ o yán                     | 대학원에 응시하다  |\n| 如果     | rú guǒ                       | 만약에        |\n| 能      | néng                         | 가능하다       |\n| 考上     | kǎ o shàng                   | 합격하다       |\n| 就      | jiù                          | 바로         |\n| 继续     | jì xù                        | 계속       "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Chinese/2024-07-24-중국어 4회.md",
    "title": "중국어 학습 4회 - 일상 활동과 장소 표현",
    "description": "중국어 학습 4회차 - 일상 활동과 장소 관련 단어 및 표현 학습",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 중국어 학습 4회차 노트이다. 일상 활동과 장소 관련 단어(努力, 电影院, 图书馆 등)와 중국어로 일상생활을 표현하는 방법을 학습한다. 노력과 관련된 표현과 다양한 장소명을 포함한다.\n\n**单词:**\n\n1. **努力** (nǔ lì)\n    \n    - 意思: 노력하다\n    - 例: 她非常努力地工作。(Tā fēi cháng nǔ lì de gōng zuò.)\n2. **电影院** (diàn yǐng yuàn)\n    \n    - 意思: 영화관\n    - 例: 我们去电影院看电影吧。(Wǒ men qù diàn yǐng yuàn kàn diàn yǐng ba.)\n3. **零食** (líng shí)\n    \n    - 意思: 간식\n    - 例: 他喜欢吃各种零食。(Tā xǐ huān chī gè zhǒng líng shí.)\n4. **饭桶** (fàn tǒng)\n    \n    - 意思: 밥통 (많이 먹는 사람)\n    - 例: 你这不叫吃货叫饭桶。 (Nǐ zhè bù jiào chī huò jiào fàn tǒng.)\n5. **薯条** (shǔ tiáo)\n    \n    - 意思: 감자튀김\n    - 例: 孩子们喜欢吃薯条。(Hái zi men xǐ huān chī shǔ tiáo.)\n6. **炸弹酒** (zhà dàn jiǔ)\n    \n    - 意思: 폭탄주\n    - 例: 他喝了很多炸弹酒。(Tā hē le hěn duō zhà dàn jiǔ.)\n\n---\n\n**语法:**\n\n1. 你喝咖啡还是啤酒? (Nǐ hē kā fēi hái shì pí jiǔ?)\n    - 너는 커피를 마실래 아니면 맥주를 마실래?\n2. 我喝咖啡或者啤酒都行。 (Wǒ hē kā fēi huò zhě pí jiǔ dōu xíng.)\n    - 나는 커피든 맥주든 다 괜찮아.\n\n---\n\n**纠正句子:**\n\n1. 在家里看电影可以，但是去电影院看电影的话，因为太忙。  \n    (Zài jiā lǐ kàn diàn yǐng kě yǐ, dàn shì qù diàn yǐng yu"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Chinese/2024-07-15-중국어 1회.md",
    "title": "중국어 학습 1회 - 주말 계획 묻기",
    "description": "중국어 학습 1회차 - 주말 계획을 묻는 표현과 관련 단어 학습",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 중국어 학습 1회차 노트이다. \"주말에 무슨 계획이 있나요?\"라는 질문을 중심으로 주말 활동 관련 단어(呆, 打算, 去, 看电影 등), 인명(秀真, 会静), 그리고 기본적인 중국어 대화 패턴을 학습한다.\n## **第一课: 周末你有什么打算？**\n\nhttps://www.youtube.com/watch?v=0X6P5zBcf5s\n\n**【단어】**\n\n| 秀真  | xiù zhēn       | [인명 人名] | 수진            |\n| --- | -------------- | ------- | ------------- |\n| 会静  | huì jìng       | [인명 人名] | 회정            |\n| 呆   | dāi            | [동사]    | 가만히 있다        |\n| 最近  | zuì jìn        | [명사]    | 최근, 요즘        |\n| 新   | xīn            | [형용사]   | 새롭다, 새로운      |\n| 叶问  | yè wèn         | [영화 이름] | 엽문            |\n| 上映  | shàng yìng     | [동사]    | 상영하다. 개봉하다    |\n| 赶紧  | gǎn jǐn        | [부사]    | 서둘러, 급히       |\n| 买票  | mǎi piào       | [동사]    | 표를 사다         |\n| 上午场 | shàng wǔ chǎng | [명사]    | 오전(영화), 조조 할인 |\n| 别   | bié            | [부사]    | ~하지 마라        |\n| 忘   | wàng           | [동사]    | 잊다            |\n| 爆米花 | bào mǐ huā     | [명사]    | 팝콘            |\n| 可乐  | kě lè          | [명사]    | 콜라            |\n| 吃货  | chī huò        | ["
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Chinese/2024-07-19-중국어 2회.md",
    "title": "중국어 학습 2회 - 팀워크와 회의 관련 표현",
    "description": "중국어 학습 2회차 - 팀워크와 회의 관련 단어 및 표현 학습",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 중국어 학습 2회차 노트이다. 팀워크와 회의 관련 핵심 단어(队友, 小组, 开会, 队长 등)와 실제 사용 예문을 통해 중국어로 팀 활동과 회의 상황을 표현하는 방법을 학습한다.\n1. 队友 (duì yǒu)\n    \n    - 뜻: 팀원, 동료\n    - 예: 我和我队友一起开会，因为我是队长，我们一个星期开一次会。 (Wǒ hé wǒ duìyǒu yīqǐ kāihuì, yīnwèi wǒ shì duìzhǎng, wǒmen yīgè xīngqī kāi yīcì huì.) - 나는 팀원과 함께 회의를 한다. 나는 팀장이라 일주일에 한 번 회의를 연다.\n2. 小组 (xiǎo zǔ)\n    \n    - 뜻: 소그룹, 소조\n    - 예: 我们的小组有五个人。 (Wǒmen de xiǎozǔ yǒu wǔ gèrén.) - 우리 소그룹은 다섯 명이다.\n3. 开会 (kāi huì)\n    \n    - 뜻: 회의를 열다\n    - 예: 他们正在开会。 (Tāmen zhèngzài kāihuì.) - 그들은 지금 회의를 하고 있다.\n4. 荣誉 (róng yù)\n    \n    - 뜻: 명예, 영예\n    - 예: 这是我的荣誉。 (Zhè shì wǒ de róngyù.) - 이것은 나의 명예이다.\n5. 音箱 (yīn xiāng)\n    \n    - 뜻: 스피커\n    - 예: 这个音箱的音质很好。 (Zhège yīnxiāng de yīnzhì hěn hǎo.) - 이 스피커의 음질은 매우 좋다.\n6. 挑选 (tiāo xuǎn)\n    \n    - 뜻: 고르다, 선택하다\n    - 예: 我们需要挑选一个好的方案。 (Wǒmen xūyào tiāoxuǎn yīgè hǎo de fāng'àn.) - 우리는 좋은 계획을 선택해야 한다.\n\n### 발음 교정\n\n1. 语言 (yǔ yán)\n    - 뜻: 언어\n    - 발음: yǔ yán (yǔ - 3성, yán - 2성)\n\n\n- 属什么 (shǔ shén me)\n    \n    - 뜻: 무슨 띠예요?\n    - 예: 你属什么?"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Chinese/2024-07-22-중국어 3회.md",
    "title": "중국어 학습 3회 - 연애와 관계 관련 표현",
    "description": "중국어 학습 3회차 - 연애와 관계 관련 단어 및 표현 학습",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 중국어 학습 3회차 노트이다. 연애와 관계 관련 단어(类型, 姐弟恋, 谈恋爱 등)와 중국어로 연애 상황을 표현하는 방법을 학습한다. 연령차가 있는 연애 관계에 대한 중국어 표현도 포함한다.\n\n当然，我可以帮忙加上拼音。以下是整理好的单词和词组：\n\n1. **类型** (lèi xíng)\n    \n    - 例: 你喜欢什么类型的女生? (Nǐ xǐ huān shén me lèi xíng de nǚ shēng?)\n    - 意思: Type, kind, category\n2. **姐弟恋** (jiě dì liàn)\n    \n    - 意思: A romantic relationship where the woman is older than the man\n3. **理由** (lǐ yóu)\n    \n    - 例: 理由是什么? (Lǐ yóu shì shén me?)\n    - 意思: Reason\n4. **懂事** (dǒng shì)\n    \n    - 意思: Sensible, thoughtful, mature\n5. **穿越火线** (chuān yuè huǒ xiàn)\n    \n    - 意思: CrossFire (a popular first-person shooter game in China)\n6. **上瘾** (shàng yǐn)\n    \n    - 意思: To be addicted\n7. **挂吊瓶** (guà diào píng)\n    \n    - 意思: To have an IV drip\n8. **委屈** (wěi qū)\n    \n    - 意思: To feel wronged, to feel aggrieved"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Chinese/2024-07-26-중국어 5회.md",
    "title": "중국어 학습 5회 - 동물과 농담 표현",
    "description": "중국어 학습 5회차 - 동물과 농담 관련 단어 및 표현 학습",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 중국어 학습 5회차 노트이다. 동물 관련 단어(螃蟹, 大象, 大虾, 瞎子 등)와 중국어 농담 표현을 학습한다. 게와 코끼리가 등장하는 재미있는 중국어 농담을 통해 자연스러운 중국어 표현을 익힌다.\n| 단어              | Pinyin                                            | 한글 뜻                        |\n| --------------- | ------------------------------------------------- | --------------------------- |\n| 笑话              | xiào huà                                          | 농담                          |\n| 螃蟹              | páng xiè                                          | 게                           |\n| 大象              | dà xiàng                                          | 코끼리                         |\n| 大虾              | dà xiā                                            | 큰 새우                        |\n| 瞎子              | xiā zi                                            | 장님                          |\n| 一只螃蟹，不小心碰到了大象   | yī zhī páng xiè, bù xiǎo xīn pèng dào le dà xiàng | 게 한 마리가 실수로 코끼리를 부딪쳤다       |\n| 부딪치다            | bù dǎi chī dào                       "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Chinese/2024-08-05-중국어 9회.md",
    "title": "중국어 학습 9회 - 일상 단어 정리",
    "description": "중국어 학습 9회차 - 일상생활에서 자주 사용하는 중국어 단어 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 중국어 학습 9회차 노트이다. 일상생활에서 자주 사용하는 중국어 단어들을 한자-병음-한글 뜻 형태로 체계적으로 정리하여 학습한다.\n\n### 단어 정리\n\n|한자|병음|한글 뜻|\n|---|---|---|\n|天赋|tiān fù|재능|\n|年薪|nián xīn|연봉|\n|体育|tǐ yù|체육|\n|音乐|yīn yuè|음악|\n|理工男|lǐ gōng nán|공대 남자|\n|追求|zhuī qiú|추구하다|\n|情书|qíng shū|연애편지|\n|随礼|suí lǐ|답례하다, 예물을 보내다|\n\n### 문장 예시\n\n1. **例: 理工男越来越受欢迎**\n    - **Lǐ gōng nán yuè lái yuè shòu huān yíng**\n    - 공대 남자가 점점 인기를 얻고 있다\n\n### 문장 수정\n\n1. **对衣服不感兴趣。(X)**\n    - **Duì yī fú bù gǎn xìng qù. (X)**\n    - 옷에 관심이 없다. (수정 전)\n    \n    **对穿着不重视。(O)**\n    - **Duì chuān zhuó bù zhòng shì. (O)**\n    - 복장에 신경 쓰지 않는다. (수정 후)\n\n2. **一时之间比医大和法大受欢迎。(O)**\n    - **Yī shí zhī jiān bǐ yī dà hé fǎ dà shòu huān yíng. (O)**\n    - 한때 의대와 법대보다 인기가 있었다."
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Chinese/2024-08-12-중국어10회.md",
    "title": "중국어 학습 10회 - 종합 단어 정리",
    "description": "중국어 학습 10회차 - 종합적인 중국어 단어 및 표현 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 중국어 학습 10회차 노트이다. 지금까지 학습한 내용을 바탕으로 종합적인 중국어 단어와 표현을 정리하여 복습하고 체계화한다.\n\n중국어 단어 및 뜻\n\n|단어|Pinyin|한글 뜻|\n|---|---|---|\n|高烧|gāo shāo|고열|\n|病毒试纸|bìng dú shì zhǐ|바이러스 검사 키트|\n|第二天|dì èr tiān|두 번째 날, 다음 날|\n|悲惨|bēi cǎn|비참한|\n|因病得福|yīn bìng dé fú|병 덕분에 얻은 복, 전화위복|\n### 문장 예시\n\n- **第二天在家办公，但是我不能集中注意力。**\n    - pinyin: dì èr tiān zài jiā bàngōng, dànshì wǒ bù néng jízhōng zhùyì lì.\n    - 뜻: 다음 날에 재택근무를 했지만, 집중이 안 돼요.\n\n### 문장 교정\n\n1. **小刀刺嗓子。**\n    \n    - pinyin: xiǎo dāo cì sǎng zi\n    - 뜻: 작은 칼이 목구멍을 찌르다.\n2. **你的无怨无悔的精神可嘉。**\n    \n    - pinyin: nǐ de wú yuàn wú huǐ de jīngshén kě jiā.\n    - 뜻: 당신의 후회 없는 정신은 칭찬할 만합니다.\n3. **她结婚的时候我没工作，所以我随礼随得很少。**\n    \n    - pinyin: tā jiéhūn de shíhòu wǒ méi gōngzuò, suǒyǐ wǒ suí lǐ suí de hěn shǎo.\n    - 뜻: 그녀가 결혼했을 때 저는 직장이 없어서, 축의금을 적게 냈어요.\n\n### 추가 단어\n\n- **精神可嘉 (jīngshén kě jiā)**\n    - 뜻: 정신이 칭찬할 만하다.\n- **礼金 (lǐ jīn)**\n    - 뜻: 축의금\n- **随礼 (suí lǐ)**\n    - 뜻: 축의금을 내다\n\n### 예시 문장\n\n- **前女友为了让你随礼才告诉你的。**\n    \n    - pinyin: qián nǚyǒu wèile ràng nǐ suí lǐ cá"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Chinese/2024-07-31-중국어 7회.md",
    "title": "중국어 학습 7회 - 취미와 활동 표현",
    "description": "중국어 학습 7회차 - 취미와 활동 관련 단어 및 표현 학습",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 중국어 학습 7회차 노트이다. 취미와 활동 관련 단어(钓鱼, 放生, 体育 등)와 중국어로 다양한 취미 활동을 표현하는 방법을 학습한다.\n| 중국어      | Pinyin                            | 한글 뜻           |\n| -------- | --------------------------------- | -------------- |\n| 钓鱼       | diào yú                           | 낚시             |\n| 放生       | fàng shēng                        | 방생하다           |\n| 体育       | tǐ yù                             | 체육             |\n| 计划       | jì huà                            | 계획             |\n| 旅游攻略     | lǚ yóu gōng lüè                   | 여행 가이드         |\n| 闺蜜       | guī mì                            | 절친한 친구 (여자 친구) |\n| 路线       | lù xiàn                           | 노선             |\n| 攻略       | gōng lüè                          | 가이드, 전략        |\n| 坐车需要多长时间 | zuò chē xū yào duō cháng shí jiān | 차를 타고 얼마나 걸리는지 |\n| ESFP     | ESFP                              | ESFP 성격 유형     |\n\n### 예문과 뜻\n\n1. **放生** (fàng shēng): 방생하다  \n    예: 一定要把鱼放生。  \n    (yí dìng yào bǎ yú fàng shēng.)  \n    뜻: 꼭 물고기를 방생"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-04-29-_lvl2_옳바른 괄호.md",
    "title": "[lvl2]옳바른 괄호",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers: 옳바른 괄호\n](https://school.programmers.co.kr/learn/courses/30/lessons/12909)\n\n## 문제 설명\n\n괄호가 바르게 짝지어졌다는 것은 '(' 문자로 열렸으면 반드시 짝지어서 ')' 문자로 닫혀야 한다는 뜻입니다. 예를 들어\n\n* \"()()\" 또는 \"(())()\" 는 올바른 괄호입니다.\n* \")()(\" 또는 \"(()(\" 는 올바르지 않은 괄호입니다.\n\n\n'(' 또는 ')' 로만 이루어진 문자열 s가 주어졌을 때, 문자열 s가 올바른 괄호이면 true를 return 하고, 올바르지 않은 괄호이면 false를 return 하는 solution 함수를 완성해 주세요.\n\n### [제한사항]\n* 문자열 s의 길이 : 100,000 이하의 자연수\n* 문자열 s는 '(' 또는 ')' 로만 이루어져 있습니다.\n\n\n### 입출력 예:\n\n| s        | answer |\n|----------|--------|\n| \"()()\"   | true   |\n| \"(())()\" | true   |\n| \")()(\"   | false  |\n| \"(()(\"   | false  |\n\n### 입출력 예에 대한 설명:\n\n입출력 예 #1,2,3,4\n\n문제의 예시와 같습니다.\n\n<br>\n\n<hr>\n## 피드백: \n* 처음엔 deque가 아닌 list형태의 for문을 썼었던것 같은데(확실힌 기억안남..) 시간제한에 걸렸다\n* deque 가 list보다 효율성이 좋다는 점을 생각해 deque로 진행해 보았더니 통과하였다\n \n<br>\n\n\n## 코드설명:\n* collections의 deque 사용\n* \")\" 로 시작한다면 False return\n* while문을 사용해 deq가 없어질때까지 leftpop(): '('면 track++, ')'면 --\n* track이 음수가 되면 false\n* for문이  완료된 이후 track이 0이 아니라면 false\n\n\n## 코드:\n\n```python\nfrom collections im"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-10-1-lvl2-삼각 달팽이.md",
    "title": "[lvl2]삼각 달팽이",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 월간 코드 챌린지 시즌1 > 삼각 달팽이](https://school.programmers.co.kr/learn/courses/30/lessons/68645)\n\n## 문제 설명:\n\n\n정수 n이 매개변수로 주어집니다. 다음 그림과 같이 밑변의 길이와 높이가 n인 삼각형에서 맨 위 꼭짓점부터 반시계 방향으로 달팽이 채우기를 진행한 후, 첫 행부터 마지막 행까지 모두 순서대로 합친 새로운 배열을 return 하도록 solution 함수를 완성해주세요.\n\n![examples.png](https://grepp-programmers.s3.ap-northeast-2.amazonaws.com/files/production/e1e53b93-dcdf-446f-b47f-e8ec1292a5e0/examples.png)\n\n---\n\n### 제한사항\n\n- n은 1 이상 1,000 이하입니다.\n\n---\n\n### 입출력 예\n\n|n|result|\n|---|---|\n|4|`[1,2,9,3,10,8,4,5,6,7]`|\n|5|`[1,2,12,3,13,11,4,14,15,10,5,6,7,8,9]`|\n|6|`[1,2,15,3,16,14,4,17,21,13,5,18,19,20,12,6,7,8,9,10,11]`|\n\n---\n### 입출력 예 설명\n\n입출력 예 #1\n\n- 문제 예시와 같습니다.\n\n입출력 예 #2\n\n- 문제 예시와 같습니다.\n\n입출력 예 #3\n\n- 문제 예시와 같습니다.\n\n## 코드:\n\n```python\ndef solution(n):\n    graph = []\n    for i in range(1, n+1):\n        graph.append([0]*i)\n    \n    dir = [(1, 0), (0, 1), (-1, -1)]\n    x, y, num = -1, 0, 1\n    for i in range(n):\n        for j in range(i, n):\n            dir_x, dir_y = dir[i%3]\n            x"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-08-_lvl1_내적.md",
    "title": "[lvl1]내적",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 2021 카카오 채용연계형 인턴쉽 > 거리두기 확인하기](https://school.programmers.co.kr/learn/courses/30/lessons/81302)\n\n## 문제 설명:\n\n길이가 같은 두 1차원 정수 배열 a, b가 매개변수로 주어집니다. a와 b의 내적을 return 하도록 solution 함수를 완성해주세요.\n\n이때, a와 b의 내적은 a[0]\\*b[0] + a[1]\\*b[1] + ... + a[n-1]*b[n-1] 입니다. (n은 a, b의 길이)\n\n## [제한사항]\na, b의 길이는 1 이상 1,000 이하입니다.\na, b의 모든 수는 -1,000 이상 1,000 이하입니다.\n\n## 입출력 예:\n\n| a \t| b \t| result \t|\n|---\t|---\t|---\t|\n| [1,2,3,4] \t| [-3,-1,0,2] \t| 3 \t|\n| [-1,0,1] \t| [1,0,-1] \t| -2 \t|\n\n### 입출력 예 설명:\n#### 입출력 예 #1:\n\na와 b의 내적은 1\\*(-3) + 2\\*(-1) + 3\\*0 + 4*2 = 3 입니다.\n#### 입출력 예 #2:\n\na와 b의 내적은 (-1)\\*1 + 0\\*0 + 1*(-1) = -2 입니다.\n\n<br>\n\n<hr>\n\n## 피드백: \n* 정수 answer=0을 먼저 선언한 뒤, answer+= a[i]\\*b[i] 로 더했지만\n* 바로 sum([x*y for x, y in zip(a,b)]) 로 한줄로 간단히 구현이 가능했다\n\n\n<br>\n\n## 코드설명:\n\n* zip 함수를 활용하여 a, b를 묶어서 a[i]*b[i]를 구한 후 answer에 쌓아 나가는 방식을 사용했다\n\n## 코드:\n\n```python\ndef solution(a, b):\n    answer = 0\n    for i, j in zip(a,b):\n        answer += (i*j)\n    return answer\n```\n\n## 우수답변자 코드:\n\n```python\n\ndef solution"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-08-_lvl2_거리두기 확인하기.md",
    "title": "[lvl2][2021 카카오 인턴쉽]거리두기 확인하기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 2021 카카오 채용연계형 인턴쉽 > 거리두기 확인하기](https://school.programmers.co.kr/learn/courses/30/lessons/81302)\n\n## 문제 설명:\n\n개발자를 희망하는 죠르디가 카카오에 면접을 보러 왔습니다.\n\n코로나 바이러스 감염 예방을 위해 응시자들은 거리를 둬서 대기를 해야하는데 개발 직군 면접인 만큼\n아래와 같은 규칙으로 대기실에 거리를 두고 앉도록 안내하고 있습니다.\n\n1. 대기실은 5개이며, 각 대기실은 5x5 크기입니다.\n2. 거리두기를 위하여 응시자들 끼리는 맨해튼 거리1가 2 이하로 앉지 말아 주세요.\n3. 단 응시자가 앉아있는 자리 사이가 파티션으로 막혀 있을 경우에는 허용합니다.\n\n예를 들어,\n\n<br>\n<p align=\"center\">\n<img width=\"530\" alt=\"image\" src=\"https://user-images.githubusercontent.com/99532836/184472375-e892e2ff-fe1e-4c82-9360-5dcbc660e57b.png\">\n</p>\n<br>\n\n5개의 대기실을 본 죠르디는 각 대기실에서 응시자들이 거리두기를 잘 기키고 있는지 알고 싶어졌습니다. 자리에 앉아있는 응시자들의 정보와 대기실 구조를 대기실별로 담은 2차원 문자열 배열 places가 매개변수로 주어집니다. 각 대기실별로 거리두기를 지키고 있으면 1을, 한 명이라도 지키지 않고 있으면 0을 배열에 담아 return 하도록 solution 함수를 완성해 주세요.\n\n## [제한사항]\n* places의 행 길이(대기실 개수) = 5\n\t* places의 각 행은 하나의 대기실 구조를 나타냅니다.\n* places의 열 길이(대기실 세로 길이) = 5\n* places의 원소는 P,O,X로 이루어진 문자열입니다.\n\t* places 원소의 길이(대기실 가로 길이) = 5\n\t* P는 응시자가 앉아있는 자리를 의미합니다.\n\t* O는 빈 테이블을 의미합니다.\n\t* X는"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-03-18-_lvl1_당구 연습.md",
    "title": "[lvl1]당구연습",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습 > 연습문제 > 당구 연습](https://school.programmers.co.kr/learn/courses/30/lessons/169198)\n\n## 문제 설명:\n\n프로그래머스의 마스코트인 머쓱이는 최근 취미로 당구를 치기 시작했습니다.\n\n머쓱이는 손 대신 날개를 사용해야 해서 당구를 잘 못 칩니다. 하지만 끈기가 강한 머쓱이는 열심히 노력해서 당구를 잘 치려고 당구 학원에 다니고 있습니다.\n\n오늘도 당구 학원에 나온 머쓱이에게 당구 선생님이\"원쿠션\"(당구에서 공을 쳐서 벽에 맞히는 걸 쿠션이라고 부르고, 벽에 한 번 맞힌 후 공에 맞히면 원쿠션이라고 부릅니다) 연습을 하라면서 당구공의 위치가 담긴 리스트를 건네줬습니다. 리스트에는 머쓱이가 맞춰야 하는 공들의 위치가 담겨있습니다. 머쓱이는 리스트에 담긴 각 위치에 순서대로 공을 놓아가며 \"원쿠션\" 연습을 하면 됩니다. 이때, 머쓱이는 항상 같은 위치에 공을 놓고 쳐서 리스트에 담긴 위치에 놓인 공을 맞춥니다.\n\n머쓱이와 달리 최근 취미로 알고리즘 문제를 풀기 시작한 당신은, 머쓱이가 친 공이 각각의 목표로한 공에 맞을 때까지 최소 얼마의 거리를 굴러가야 하는지가 궁금해졌습니다.\n\n당구대의 가로 길이 m, 세로 길이 n과 머쓱이가 쳐야 하는 공이 놓인 위치 좌표를 나타내는 두 정수 startX, startY, 그리고 매 회마다 목표로 해야하는 공들의 위치 좌표를 나타내는 정수 쌍들이 들어있는 2차원 정수배열 balls가 주어집니다. \"원쿠션\" 연습을 위해 머쓱이가 공을 적어도 벽에 한 번은 맞춘 후 목표 공에 맞힌다고 할 때, 각 회마다 머쓱이가 친 공이 굴러간 거리의 최솟값의 제곱을 배열에 담아 return 하도록 solution 함수를 완성해 주세요.\n\n단, 머쓱이가 친 공이 벽에 부딪힐 때 진행 방향은 항상 입사각과 반사각이 동일하며, 만약 꼭짓점에 부딪힐 경우 진입 방향의 반대방향으로 공이 진행됩니다. 공의 크기는 무시하며, 두 공의 좌표가 정확히"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-07-01-숫자의 표현.md",
    "title": "[lvl2]숫자의 표현",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습 > 연습문제 > 숫자의 표현](https://school.programmers.co.kr/learn/courses/30/lessons/12924)\n\n## 문제 설명:\n\nFinn은 요즘 수학공부에 빠져 있습니다. 수학 공부를 하던 Finn은 자연수 n을 연속한 자연수들로 표현 하는 방법이 여러개라는 사실을 알게 되었습니다. 예를들어 15는 다음과 같이 4가지로 표현 할 수 있습니다.\n\n- 1 + 2 + 3 + 4 + 5 = 15\n- 4 + 5 + 6 = 15\n- 7 + 8 = 15\n- 15 = 15\n\n자연수 n이 매개변수로 주어질 때, 연속된 자연수들로 n을 표현하는 방법의 수를 return하는 solution를 완성해주세요.\n\n## 제한사항\n\n- n은 10,000 이하의 자연수 입니다.\n\n---\n\n## 입출력 예\n\n|n|result|\n|---|---|\n|15|4|\n\n## 입출력 예 설명\n\n입출력 예#1  \n문제의 예시와 같습니다.\n\n## 코드 설명:\n- 2중 for문을 사용하여 경우의 수를 다 구하고, 합이 숫자보다 넘어가면 `break`를 걸어줬다\n\n## 코드:\n```python\ndef solution(n):\n    answer = 0\n    for i in range(1, n+1):\n        summ = 0\n        for j in range(i, n+1):\n            summ += j\n            if summ == n: \n                answer += 1\n            elif summ > n:\n                break\n    return answer\n```\n\n## 우수답변자 코드:\n- list comprehension을 len과 함께 써서 사용하여 간결하다\n- 2씩 늘리는 for문을 사용한 뒤, if문으로 `n % i ==0` 를 걸어줬다\n```python\ndef solution(num):\n    return len([i  for "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-03-19-_lvl2_귤 고르기.md",
    "title": "[lvl2]귤 고르기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습 > 연습문제 > 귤 고르기](https://school.programmers.co.kr/learn/courses/30/lessons/138476?language=python3)\n\n## 문제 설명:\n\n경화는 과수원에서 귤을 수확했습니다. 경화는 수확한 귤 중 'k'개를 골라 상자 하나에 담아 판매하려고 합니다. 그런데 수확한 귤의 크기가 일정하지 않아 보기에 좋지 않다고 생각한 경화는 귤을 크기별로 분류했을 때 서로 다른 종류의 수를 최소화하고 싶습니다.\n\n예를 들어, 경화가 수확한 귤 8개의 크기가 [1, 3, 2, 5, 4, 5, 2, 3] 이라고 합시다. 경화가 귤 6개를 판매하고 싶다면, 크기가 1, 4인 귤을 제외한 여섯 개의 귤을 상자에 담으면, 귤의 크기의 종류가 2, 3, 5로 총 3가지가 되며 이때가 서로 다른 종류가 최소일 때입니다.\n\n경화가 한 상자에 담으려는 귤의 개수 k와 귤의 크기를 담은 배열 tangerine이 매개변수로 주어집니다. 경화가 귤 k개를 고를 때 크기가 서로 다른 종류의 수의 최솟값을 return 하도록 solution 함수를 작성해주세요.\n\n### [제한 조건]\n\n* 1 ≤ k ≤ tangerine의 길이 ≤ 100,000\n* 1 ≤ tangerine의 원소 ≤ 10,000,000\n\n### 입출력 예\n\n| k | tangerine                | result |\n|---|--------------------------|--------|\n| 6 | [1, 3, 2, 5, 4, 5, 2, 3] | 3      |\n| 4 | [1, 3, 2, 5, 4, 5, 2, 3] | 2      |\n| 2 | [1, 1, 1, 1, 2, 2, 2, 3] | 1      |\n\n<br>\n\n<hr>\n\n## 피드백: \n* collections.Counter 을 바로 떠울려 most common 함수를 사용한것이 좋았다\n* most common  함수가 생각안날땐 sort를 쓰"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-01-_lvl1_로또의 최고 순위와 최저 순위.md",
    "title": "[lvl1]로또의 최고 순위와 최저 순위",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n출처: [Programmers 로또의 최고 순위와 최저 순위](https://school.programmers.co.kr/learn/courses/30/lessons/77484?language=python3)\n\n## 문제 설명\n로또 6/45(이하 '로또'로 표기)는 1부터 45까지의 숫자 중 6개를 찍어서 맞히는 대표적인 복권입니다. 아래는 로또의 순위를 정하는 방식입니다.\n\n<br>\n\n| 순위\t당첨  | 내용           |\n| ------ | ------------ |\n| 1      | 6개 번호가 모두 일치 |\n| 2      | 5개 번호가 일치    |\n| 3      | 4개 번호가 일치    |\n| 4      | 3개 번호가 일치    |\n| 5      | 2개 번호가 일치    |\n| 6 (낙첨) | 그 외          |\n\n<br>\n\n로또를 구매한 민우는 당첨 번호 발표일을 학수고대하고 있었습니다. 하지만, 민우의 동생이 로또에 낙서를 하여, 일부 번호를 알아볼 수 없게 되었습니다. 당첨 번호 발표 후, 민우는 자신이 구매했던 로또로 당첨이 가능했던 최고 순위와 최저 순위를 알아보고 싶어 졌습니다.\n알아볼 수 없는 번호를 0으로 표기하기로 하고, 민우가 구매한 로또 번호 6개가 44, 1, 0, 0, 31 25라고 가정해보겠습니다. 당첨 번호 6개가 31, 10, 45, 1, 6, 19라면, 당첨 가능한 최고 순위와 최저 순위의 한 예는 아래와 같습니다.\n\n<br>\n\n\n| 당첨 번호  | 31 | 10 | 45 | 1 | 6 | 19 | 결과 |\n| ------------- | ------------- | --- | --- | --- | --- | --- | --- |\n| 최고 순위 번호  | 31 | 0→10 | 44 | 1 | 0→6 | 25 | 4개 번호 일치, 3등 |\n| 최저 순위 번호  | 31 | 0→11 | 44 | 1 | 0→7 | 25 | 2개 번호 일치, 5등 |\n\n<br>\n\t\n* 순서와 상관없이, 구매한 로"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-19-_lvl2__2022 KAKAO TECH INTERNSHIP_두 큐 합 같게 만들기.md",
    "title": "[lvl2][2022 KAKAO TECH INTERNSHIP]두 큐 합 같게 만들기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 2022 KAKAO Tech Intership > 두 큐 합 같게 만들기](https://school.programmers.co.kr/learn/courses/30/lessons/118667)\n\n# 두 큐 합 같게 만들기\n\n## 문제 설명:\n\n길이가 같은 두 개의 큐가 주어집니다. 하나의 큐를 골라 원소를 추출(pop)하고, 추출된 원소를 다른 큐에 집어넣는(insert) 작업을 통해 각 큐의 원소 합이 같도록 만들려고 합니다. 이때 필요한 작업의 최소 횟수를 구하고자 합니다. 한 번의 pop과 한 번의 insert를 합쳐서 작업을 1회 수행한 것으로 간주합니다.\n\n큐는 먼저 집어넣은 원소가 먼저 나오는 구조입니다. 이 문제에서는 큐를 배열로 표현하며, 원소가 배열 앞쪽에 있을수록 먼저 집어넣은 원소임을 의미합니다. 즉, pop을 하면 배열의 첫 번째 원소가 추출되며, insert를 하면 배열의 끝에 원소가 추가됩니다. 예를 들어 큐 [1, 2, 3, 4]가 주어졌을 때, pop을 하면 맨 앞에 있는 원소 1이 추출되어 [2, 3, 4]가 되며, 이어서 5를 insert하면 [2, 3, 4, 5]가 됩니다.\n\n다음은 두 큐를 나타내는 예시입니다.\n\n\tqueue1 = [3, 2, 7, 2]\n\tqueue2 = [4, 6, 5, 1]\n\n두 큐에 담긴 모든 원소의 합은 30입니다. 따라서, 각 큐의 합을 15로 만들어야 합니다. 예를 들어, 다음과 같이 2가지 방법이 있습니다.\n\n1. queue2의 4, 6, 5를 순서대로 추출하여 queue1에 추가한 뒤, queue1의 3, 2, 7, 2를 순서대로 추출하여 queue2에 추가합니다. 그 결과 queue1은 [4, 6, 5], queue2는 [1, 3, 2, 7, 2]가 되며, 각 큐의 원소 합은 15로 같습니다. 이 방법은 작업을 7번 수행합니다.\n2. queue1에서 3을 추출하여 queue2에 추가합니다. 그리고 queue2에서 4를 추출하여 queue1에 추가합니다. 그"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-05-01-_lvl2__Summer:Winder Coding(~2018)_영어 끝말잇기.md",
    "title": "[lvl2][Summer/Winder Coding(~2018)]영어 끝말잇기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습 > 연습문제 > Summer/Winder Coding(~2018) > 영어 끝말잇기](https://school.programmers.co.kr/learn/courses/30/lessons/12981)\n\n## 문제 설명:\n\n1부터 n까지 번호가 붙어있는 n명의 사람이 영어 끝말잇기를 하고 있습니다. 영어 끝말잇기는 다음과 같은 규칙으로 진행됩니다.\n\n1. 1번부터 번호 순서대로 한 사람씩 차례대로 단어를 말합니다.\n1. 마지막 사람이 단어를 말한 다음에는 다시 1번부터 시작합니다.\n1. 앞사람이 말한 단어의 마지막 문자로 시작하는 단어를 말해야 합니다.\n1. 이전에 등장했던 단어는 사용할 수 없습니다.\n1. 한 글자인 단어는 인정되지 않습니다.\n\n다음은 3명이 끝말잇기를 하는 상황을 나타냅니다.\n\ntank → kick → know → wheel → land → dream → mother → robot → tank\n\n위 끝말잇기는 다음과 같이 진행됩니다.\n\n* 1번 사람이 자신의 첫 번째 차례에 tank를 말합니다.\n* 2번 사람이 자신의 첫 번째 차례에 kick을 말합니다.\n* 3번 사람이 자신의 첫 번째 차례에 know를 말합니다.\n* 1번 사람이 자신의 두 번째 차례에 wheel을 말합니다.\n* (계속 진행)\n끝말잇기를 계속 진행해 나가다 보면, 3번 사람이 자신의 세 번째 차례에 말한 tank 라는 단어는 이전에 등장했던 단어이므로 탈락하게 됩니다.\n\n사람의 수 n과 사람들이 순서대로 말한 단어 words 가 매개변수로 주어질 때, 가장 먼저 탈락하는 사람의 번호와 그 사람이 자신의 몇 번째 차례에 탈락하는지를 구해서 return 하도록 solution 함수를 완성해주세요.\n\n### 제한 사항\n* 끝말잇기에 참여하는 사람의 수 n은 2 이상 10 이하의 자연수입니다.\n* words는 끝말잇기에 사용한 단어들이 순서대로 들어있는 배열이며, 길이는 n 이상 100 이하입니다.\n* 단어의 길이는 2 이상 5"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-08-_lvl1_소수 만들기.md",
    "title": "[lvl1]소수 만들기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > Summer/Winter Coding(~2018) > 소수 만들기](https://school.programmers.co.kr/learn/courses/30/lessons/12977)\n\n## 문제 설명:\n\n주어진 숫자 중 3개의 수를 더했을 때 소수가 되는 경우의 개수를 구하려고 합니다. 숫자들이 들어있는 배열 nums가 매개변수로 주어질 때, nums에 있는 숫자들 중 서로 다른 3개를 골라 더했을 때 소수가 되는 경우의 개수를 return 하도록 solution 함수를 완성해주세요.\n\n### [제한사항]\n\nnums에 들어있는 숫자의 개수는 3개 이상 50개 이하입니다.\nnums의 각 원소는 1 이상 1,000 이하의 자연수이며, 중복된 숫자가 들어있지 않습니다.\n\n### 입출력 예:\n\n| nums        \t| result \t|\n|-------------\t|--------\t|\n| [1,2,3,4]   \t| 1      \t|\n| [1,2,7,6,4] \t| 4      \t|\n\n### 입출력 예 설명: \n#### 입출력 예 #1:\n* [1,2,4]를 이용해서 7을 만들 수 있습니다.\n\n#### 입출력 예 #2:\n* [1,2,4]를 이용해서 7을 만들 수 있습니다.\n* [1,4,6]을 이용해서 11을 만들 수 있습니다.\n* [2,4,7]을 이용해서 13을 만들 수 있습니다.\n* [4,6,7]을 이용해서 17을 만들 수 있습니다.\n\n<br>\n\n<hr>\n\n## 피드백: \n* 소수인지 확인하는 다른 방법 : 에라토스테네스의 체\n* 주어진 자연수 n에 대해서 1보다 크고 루트 n 이하인 모든 자연수들로 나누어떨어지지 않으면 소수\n\n에라토스테네스의 체:\n\n출처: [Wikipedia:에라토스테네스의 체](https://ko.wikipedia.org/wiki/%EC%97%90%EB%9D%BC%ED%86%A0%EC%8A%A4%ED%85%8C%EB%84%A4%EC%8A%A4%EC%9D%98_%EC%B2%B4)\n\n알고리즘:\n\n1. 2부터 소"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-02-_lvl1_K번째 수.md",
    "title": "[lvl1]K번째 수",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers K번째 수](https://school.programmers.co.kr/learn/courses/30/lessons/42748)\n## 문제 설명:\n\n배열 array의 i번째 숫자부터 j번째 숫자까지 자르고 정렬했을 때, k번째에 있는 수를 구하려 합니다.\n\t\n예를 들어 array가 [1, 5, 2, 6, 3, 7, 4], i = 2, j = 5, k = 3이라면\n\t\narray의 2번째부터 5번째까지 자르면 [5, 2, 6, 3]입니다.\n\n1에서 나온 배열을 정렬하면 [2, 3, 5, 6]입니다.\n\n2에서 나온 배열의 3번째 숫자는 5입니다.\n\n배열 array, [i, j, k]를 원소로 가진 2차원 배열 commands가 매개변수로 주어질 때, commands의 모든 원소에 대해 앞서 설명한 연산을 적용했을 때 나온 결과를 배열에 담아 return 하도록 solution 함수를 작성해주세요.\n\n## 제한사항:\narray의 길이는 1 이상 100 이하입니다.\n\narray의 각 원소는 1 이상 100 이하입니다.\n\ncommands의 길이는 1 이상 50 이하입니다.\n\ncommands의 각 원소는 길이가 3입니다.\n\n### 입출력 예:\n\n| array                                             | commands                                 | return    |\n|---------------------------------------------------|------------------------------------------|-----------|\n| [1, 5, 2, 6, 3, 7, 4]                             | [[2, 5, 3], [4, 4, 1], [1, 7, 3]]        | [5, 6, 3] |\n\t\n### 입출력 예 설명:\n\n[1, 5, 2, 6, 3, 7, 4]를 2번째부터 5번째까지 자른 후 정렬합니다. \n\n[2"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-05-_lvl1_체육복.md",
    "title": "[lvl1]체육복",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 탐욕복(Greedy) > 체육복](https://school.programmers.co.kr/learn/courses/30/lessons/42862)\n\n## 문제 설명:\n\n점심시간에 도둑이 들어, 일부 학생이 체육복을 도난당했습니다. 다행히 여벌 체육복이 있는 학생이 이들에게 체육복을 빌려주려 합니다. 학생들의 번호는 체격 순으로 매겨져 있어, 바로 앞번호의 학생이나 바로 뒷번호의 학생에게만 체육복을 빌려줄 수 있습니다. 예를 들어, 4번 학생은 3번 학생이나 5번 학생에게만 체육복을 빌려줄 수 있습니다. 체육복이 없으면 수업을 들을 수 없기 때문에 체육복을 적절히 빌려 최대한 많은 학생이 체육수업을 들어야 합니다.\n\n전체 학생의 수 n, 체육복을 도난당한 학생들의 번호가 담긴 배열 lost, 여벌의 체육복을 가져온 학생들의 번호가 담긴 배열 reserve가 매개변수로 주어질 때, 체육수업을 들을 수 있는 학생의 최댓값을 return 하도록 solution 함수를 작성해주세요.\n\n### [제한사항]\n* 전체 학생의 수는 2명 이상 30명 이하입니다.\n* 체육복을 도난당한 학생의 수는 1명 이상 n명 이하이고 중복되는 번호는 없습니다.\n* 여벌의 체육복을 가져온 학생의 수는 1명 이상 n명 이하이고 중복되는 번호는 없습니다.\n* 여벌 체육복이 있는 학생만 다른 학생에게 체육복을 빌려줄 수 있습니다.\n* 여벌 체육복을 가져온 학생이 체육복을 도난당했을 수 있습니다. 이때 이 학생은 체육복을 하나만 도난당했다고 가정하며, 남은 체육복이 하나이기에 다른 학생에게는 체육복을 빌려줄 수 없습니다.\n\n### 입출력 예:\n\n| n \t| lost   \t| reserve   \t| return \t|\n|---\t|--------\t|-----------\t|--------\t|\n| 5 \t| [2, 4] \t| [1, 3, 5] \t| 5      \t|\n| 5 \t| [2, 4] \t| [3]       \t| 4      \t|\n| 3 \t| [3]    \t| ["
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-08-_lvl2_문자열 압축.md",
    "title": "[lvl2][2020 KAKAO BLIND RECRUITMENT]문자열 압축",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 2020 KAKAO BLIND RECRUITMENT > 문자열 압축](https://school.programmers.co.kr/learn/courses/30/lessons/60057)\n\n# 문자열 압축\n\n## 문제 설명:\n\n데이터 처리 전문가가 되고 싶은 \"어피치\"는 문자열을 압축하는 방법에 대해 공부를 하고 있습니다. 최근에 대량의 데이터 처리를 위한 간단한 비손실 압축 방법에 대해 공부를 하고 있는데, 문자열에서 같은 값이 연속해서 나타나는 것을 그 문자의 개수와 반복되는 값으로 표현하여 더 짧은 문자열로 줄여서 표현하는 알고리즘을 공부하고 있습니다.\n\n간단한 예로 \"aabbaccc\"의 경우 \"2a2ba3c\"(문자가 반복되지 않아 한번만 나타난 경우 1은 생략함)와 같이 표현할 수 있는데, 이러한 방식은 반복되는 문자가 적은 경우 압축률이 낮다는 단점이 있습니다. 예를 들면, \"abcabcdede\"와 같은 문자열은 전혀 압축되지 않습니다. \"어피치\"는 이러한 단점을 해결하기 위해 문자열을 1개 이상의 단위로 잘라서 압축하여 더 짧은 문자열로 표현할 수 있는지 방법을 찾아보려고 합니다.\n\n예를 들어, \"ababcdcdababcdcd\"의 경우 문자를 1개 단위로 자르면 전혀 압축되지 않지만, 2개 단위로 잘라서 압축한다면 \"2ab2cd2ab2cd\"로 표현할 수 있습니다. 다른 방법으로 8개 단위로 잘라서 압축한다면 \"2ababcdcd\"로 표현할 수 있으며, 이때가 가장 짧게 압축하여 표현할 수 있는 방법입니다.\n\n다른 예로, \"abcabcdede\"와 같은 경우, 문자를 2개 단위로 잘라서 압축하면 \"abcabc2de\"가 되지만, 3개 단위로 자른다면 \"2abcdede\"가 되어 3개 단위가 가장 짧은 압축 방법이 됩니다. 이때 3개 단위로 자르고 마지막에 남는 문자열은 그대로 붙여주면 됩니다.\n\n압축할 문자열 s가 매개변수로 주어질 때, 위에 설명한 방법으로 1개 이상 단위로 문자열을 잘라 압축하여 표현한 문자열 중 가장 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-03-_lvl1_폰켓몬.md",
    "title": "[lvl1]폰켓몬",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers: 폰켓몬\n](https://school.programmers.co.kr/learn/courses/30/lessons/1845)\n\n## 문제 설명\n\n당신은 폰켓몬을 잡기 위한 오랜 여행 끝에, 홍 박사님의 연구실에 도착했습니다. 홍 박사님은 당신에게 자신의 연구실에 있는 총 N 마리의 폰켓몬 중에서 N/2마리를 가져가도 좋다고 했습니다.\n\n홍 박사님 연구실의 폰켓몬은 종류에 따라 번호를 붙여 구분합니다. 따라서 같은 종류의 폰켓몬은 같은 번호를 가지고 있습니다. 예를 들어 연구실에 총 4마리의 폰켓몬이 있고, 각 폰켓몬의 종류 번호가 [3번, 1번, 2번, 3번]이라면 이는 3번 폰켓몬 두 마리, 1번 폰켓몬 한 마리, 2번 폰켓몬 한 마리가 있음을 나타냅니다. 이때, 4마리의 폰켓몬 중 2마리를 고르는 방법은 다음과 같이 6가지가 있습니다.\n\n1. 첫 번째(3번), 두 번째(1번) 폰켓몬을 선택\n2. 첫 번째(3번), 세 번째(2번) 폰켓몬을 선택\n3. 첫 번째(3번), 네 번째(3번) 폰켓몬을 선택\n4. 두 번째(1번), 세 번째(2번) 폰켓몬을 선택\n5. 두 번째(1번), 네 번째(3번) 폰켓몬을 선택\n6. 세 번째(2번), 네 번째(3번) 폰켓몬을 선택\n\n이때, 첫 번째(3번) 폰켓몬과 네 번째(3번) 폰켓몬을 선택하는 방법은 한 종류(3번 폰켓몬 두 마리)의 폰켓몬만 가질 수 있지만, 다른 방법들은 모두 두 종류의 폰켓몬을 가질 수 있습니다. 따라서 위 예시에서 가질 수 있는 폰켓몬 종류 수의 최댓값은 2가 됩니다.\n\n당신은 최대한 다양한 종류의 폰켓몬을 가지길 원하기 때문에, 최대한 많은 종류의 폰켓몬을 포함해서 N/2마리를 선택하려 합니다. N마리 폰켓몬의 종류 번호가 담긴 배열 nums가 매개변수로 주어질 때, N/2마리의 폰켓몬을 선택하는 방법 중, 가장 많은 종류의 폰켓몬을 선택하는 방법을 찾아, 그때의 폰켓몬 종류 번호의 개수를 return 하도록 solution 함수를 완성해주세요.\n\n### [제한사항]\n*"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-01-_lvl1_숫자 문자열과 영단어.md",
    "title": "[lvl1]숫자 문자열과 영단어",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers: 숫자 문자열과 영단어\n](https://school.programmers.co.kr/learn/courses/30/lessons/81301)\n## 문제 설명\n\n네오와 프로도가 숫자놀이를 하고 있습니다. 네오가 프로도에게 숫자를 건넬 때 일부 자릿수를 영단어로 바꾼 카드를 건네주면 프로도는 원래 숫자를 찾는 게임입니다.\n\n다음은 숫자의 일부 자릿수를 영단어로 바꾸는 예시입니다.\n\n* 1478 \t\t&nbsp;&ensp;&ensp;&nbsp;&nbsp;&nbsp; → &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"one4seveneight\"\n* 234567 \t\t&nbsp;&nbsp;&nbsp;&nbsp;→ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"23four5six7\"\n* 10203\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;→ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"1zerotwozero3\"\n\n이렇게 숫자의 일부 자릿수가 영단어로 바뀌어졌거나, 혹은 바뀌지 않고 그대로인 문자열 s가 매개변수로 주어집니다. s가 의미하는 원래 숫자를 return 하도록 solution 함수를 완성해주세요.\n\n참고로 각 숫자에 대응되는 영단어는 다음 표와 같습니다.\n\n| 숫자 | 영단어 |\n|------|--------|\n| 0    | zero   |\n| 1    | one    |\n| 2    | two    |\n| 3    | three  |\n| 4    | four   |\n| 5    | five   |\n| 6    | six    |\n| 7    | seven  |\n| 8    | eight  |\n| 9    | nine   |\n\n### 제한사항:\n* 1 ≤ s의 길이 ≤ 50\n* s가 \"zero\" 또는 \"0\"으로 시작하는 경우는 주어지지 않습니다.\n* return 값이 1 이상 2,000,000,000 이하의 정수가 되는 올바른 입력만 s로 주어집니다.\n\n### 입출력 예:\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-06-24-SQL-그룹별 조건에 맞는 식당 목록 출력하기.md",
    "title": "[SQL]그룹별 조건에 맞는 식당 목록 출력하기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습 > JOIN > 그룹별 조건에 맞는 식당 목록 출력하기](https://school.programmers.co.kr/learn/courses/30/lessons/131124)\n\n## 문제 설명:\n\n다음은 고객의 정보를 담은 `MEMBER_PROFILE`테이블과 식당의 리뷰 정보를 담은 `REST_REVIEW` 테이블입니다. `MEMBER_PROFILE` 테이블은 다음과 같으며 `MEMBER_ID`, `MEMBER_NAME`, `TLNO`, `GENDER`, `DATE_OF_BIRTH`는 회원 ID, 회원 이름, 회원 연락처, 성별, 생년월일을 의미합니다.\n\n|Column name|Type|Nullable|\n|---|---|---|\n|MEMBER_ID|VARCHAR(100)|FALSE|\n|MEMBER_NAME|VARCHAR(50)|FALSE|\n|TLNO|VARCHAR(50)|TRUE|\n|GENDER|VARCHAR(1)|TRUE|\n|DATE_OF_BIRTH|DATE|TRUE|\n\n`REST_REVIEW` 테이블은 다음과 같으며 `REVIEW_ID`, `REST_ID`, `MEMBER_ID`, `REVIEW_SCORE`, `REVIEW_TEXT`,`REVIEW_DATE`는 각각 리뷰 ID, 식당 ID, 회원 ID, 점수, 리뷰 텍스트, 리뷰 작성일을 의미합니다.\n\n|Column name|Type|Nullable|\n|---|---|---|\n|REVIEW_ID|VARCHAR(10)|FALSE|\n|REST_ID|VARCHAR(10)|TRUE|\n|MEMBER_ID|VARCHAR(100)|TRUE|\n|REVIEW_SCORE|NUMBER|TRUE|\n|REVIEW_TEXT|VARCHAR(1000)|TRUE|\n|REVIEW_DATE|DATE|TRUE|\n\n## 문제\n\n`MEMBER_PROFILE`와 `REST_REVIEW` 테이블에서 리뷰를 가장 많이 작성한 회원의 리뷰들을 조회하는 SQL문을 작성해주세요. 회원 이름, 리뷰 텍스"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-01-lvl1_카카오 인턴_키패드 누르기.md",
    "title": "[lvl1][카카오 인턴]키패드 누르기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers [카카오 인턴] 키패드 누르기](https://school.programmers.co.kr/learn/courses/30/lessons/67256)\n## 문제 설명\n스마트폰 전화 키패드의 각 칸에 다음과 같이 숫자들이 적혀 있습니다.\n\n![kakao_phone1](https://user-images.githubusercontent.com/99532836/182303561-c525a79a-7d00-4bf4-88a3-da786938c759.png){: width=\"25%\" height=\"25%\"}\n\n* 이 전화 키패드에서 왼손과 오른손의 엄지손가락만을 이용해서 숫자만을 입력하려고 합니다.\n* 맨 처음 왼손 엄지손가락은 * 키패드에 오른손 엄지손가락은 # 키패드 위치에서 시작하며, 엄지손가락을 사용하는 규칙은 다음과 같습니다.\n\n1. 엄지손가락은 상하좌우 4가지 방향으로만 이동할 수 있으며 키패드 이동 한 칸은 거리로 1에 해당합니다.\n2. 왼쪽 열의 3개의 숫자 1, 4, 7을 입력할 때는 왼손 엄지손가락을 사용합니다.\n3. 오른쪽 열의 3개의 숫자 3, 6, 9를 입력할 때는 오른손 엄지손가락을 사용합니다.\n4. 가운데 열의 4개의 숫자 2, 5, 8, 0을 입력할 때는 두 엄지손가락의 현재 키패드의 위치에서 더 가까운 엄지손가락을 사용합니다.\n\t\n\t4-1. 만약 두 엄지손가락의 거리가 같다면, 오른손잡이는 오른손 엄지손가락, 왼손잡이는 왼손 엄지손가락을 사용합니다.\n\n* 순서대로 누를 번호가 담긴 배열 numbers, 왼손잡이인지 오른손잡이인 지를 나타내는 문자열 hand가 매개변수로 주어질 때, 각 번호를 누른 엄지손가락이 왼손인 지 오른손인 지를 나타내는 연속된 문자열 형태로 return 하도록 solution 함수를 완성해주세요.\n\n### [제한사항]\n\n* numbers 배열의 크기는 1 이상 1,000 이하입니다.\n* numbers 배열 원소의 값은 0 이상 9 이하인 정수입니다.\n* hand는 \"left\" 또는 \"ri"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-06-28-최솟값 만들기.md",
    "title": "[lvl2]최솟값 만들기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers>코딩테스트 연습>연습문제>최솟값 만들기](https://school.programmers.co.kr/learn/courses/30/lessons/12941)\n\n## 문제 설명\n\n길이가 같은 배열 A, B 두개가 있습니다. 각 배열은 자연수로 이루어져 있습니다.  \n배열 A, B에서 각각 한 개의 숫자를 뽑아 두 수를 곱합니다. 이러한 과정을 배열의 길이만큼 반복하며, 두 수를 곱한 값을 누적하여 더합니다. 이때 최종적으로 누적된 값이 최소가 되도록 만드는 것이 목표입니다. (단, 각 배열에서 k번째 숫자를 뽑았다면 다음에 k번째 숫자는 다시 뽑을 수 없습니다.)\n\n예를 들어 A = `[1, 4, 2]` , B = `[5, 4, 4]` 라면\n\n- A에서 첫번째 숫자인 1, B에서 첫번째 숫자인 5를 뽑아 곱하여 더합니다. (누적된 값 : 0 + 5(1x5) = 5)\n- A에서 두번째 숫자인 4, B에서 세번째 숫자인 4를 뽑아 곱하여 더합니다. (누적된 값 : 5 + 16(4x4) = 21)\n- A에서 세번째 숫자인 2, B에서 두번째 숫자인 4를 뽑아 곱하여 더합니다. (누적된 값 : 21 + 8(2x4) = 29)\n\n즉, 이 경우가 최소가 되므로 **29**를 return 합니다.\n\n배열 A, B가 주어질 때 최종적으로 누적된 최솟값을 return 하는 solution 함수를 완성해 주세요.\n\n## 제한사항\n\n- 배열 A, B의 크기 : 1,000 이하의 자연수\n- 배열 A, B의 원소의 크기 : 1,000 이하의 자연수\n\n## 입출력 예\n\n|A|B|answer|\n|---|---|---|\n|[1, 4, 2]|[5, 4, 4]|29|\n|[1,2]|[3,4]|10|\n\n## 입출력 예 설명\n\n입출력 예 #1  \n문제의 예시와 같습니다.\n\n입출력 예 #2  \nA에서 첫번째 숫자인 1, B에서 두번째 숫자인 4를 뽑아 곱하여 더합니다. (누적된 값 : 4) 다음, A에서 두번째 숫자인 2, B에서 첫번째 숫자인 3을 뽑아 곱하여 더합"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-03-sql 문제 풀이.md",
    "title": "sql 문제 풀이",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n# 프로그래머스 sql 문제 풀이\n\n출처: [Programmers: 코딩테스트 연습 > sql\n](https://school.programmers.co.kr/learn/courses/30/lessons/59034)\n\n<hr>\n\n## 코딩테스트 연습 > SELECT > 모든 레코드 조회하기\n#### [문제] 동물 보호소에 들어온 모든 동물의 정보를 ANIMAL_ID순으로 조회하는 SQL문을 작성해주세요. SQL을 실행하면 다음과 같이 출력되어야 합니다.\n\t\n```sql\nSELECT * FROM ANIMAL_INS ORDER BY ANIMAL_ID\n```\n<br>\n<hr>\n## 코딩테스트 연습 > SELECT > 역순 정렬하기\n#### [문제] 동물 보호소에 들어온 모든 동물의 이름과 보호 시작일을 조회하는 SQL문을 작성해주세요. 이때 결과는 ANIMAL_ID 역순으로 보여주세요. SQL을 실행하면 다음과 같이 출력되어야 합니다.\n```sql\nSELECT NAME, DATETIME FROM ANIMAL_INS ORDER BY ANIMAL_ID DESC\n```\n<br>\n<hr>\n\n## 코딩테스트 연습 > SELECT > 아픈 동물 찾기\n#### [문제] 동물 보호소에 들어온 동물 중 아픈 동물1의 아이디와 이름을 조회하는 SQL 문을 작성해주세요. 이때 결과는 아이디 순으로 조회해주세요.\n```sql\nSELECT ANIMAL_ID, NAME\nFROM ANIMAL_INS \nWHERE INTAKE_CONDITION =\"Sick\"\n```\n<br>\n<hr>\n\n## 코딩테스트 연습 > SELECT > 어린 동물 찾기\n#### [문제] 동물 보호소에 들어온 동물 중 젊은 동물의 아이디와 이름을 조회하는 SQL 문을 작성해주세요. 이때 결과는 아이디 순으로 조회해주세요.\n```sql\nSELECT ANIMAL_ID, NAME\nFROM ANIMAL_INS\nWHERE INTAKE_CONDITION != \"Aged\"\n```\n<br>\n<hr>\n\n## 코딩테스트 연습 > SELECT "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-02-_lvl1_완주하지 못한 선수.md",
    "title": "[lvl1]완주하지 못한 선수",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers: 완주하지 못한 선수\n](https://school.programmers.co.kr/learn/courses/30/lessons/42576)\n\n## 문제 설명\n\n수많은 마라톤 선수들이 마라톤에 참여하였습니다. 단 한 명의 선수를 제외하고는 모든 선수가 마라톤을 완주하였습니다.\n\n마라톤에 참여한 선수들의 이름이 담긴 배열 participant와 완주한 선수들의 이름이 담긴 배열 completion이 주어질 때, 완주하지 못한 선수의 이름을 return 하도록 solution 함수를 작성해주세요.\n\n### 제한사항:\n* 마라톤 경기에 참여한 선수의 수는 1명 이상 100,000명 이하입니다.\n* completion의 길이는 participant의 길이보다 1 작습니다.\n* 참가자의 이름은 1개 이상 20개 이하의 알파벳 소문자로 이루어져 있습니다.\n* 참가자 중에는 동명이인이 있을 수 있습니다.\n\n### 입출력 예:\n\n| participant                                       | completion                               | return   |\n|---------------------------------------------------|------------------------------------------|----------|\n| [\"leo\", \"kiki\", \"eden\"]                           | [\"eden\", \"kiki\"]                         | \"leo\"    |\n| [\"marina\", \"josipa\", \"nikola\", \"vinko\", \"filipa\"] | [\"josipa\", \"filipa\", \"marina\", \"nikola\"] | \"vinko\"  |\n| [\"mislav\", \"stanko\", \"mislav\", \"ana\"]             | [\"stanko\", \"ana\", \"mislav\"]      "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-05-01-_lvl3__동적계획법(Dynamic Programming)_정수 삼각형.md",
    "title": "[lvl3][동적계획법(Dynamic Programming)]정수 삼각형",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습 > 연습문제 > 동적계획법(Dynamic Programming) > 정수 삼각형\"](https://school.programmers.co.kr/learn/courses/30/lessons/43105)\n\n## 문제 설명:\n\n![img](https://user-images.githubusercontent.com/99532836/235447519-bf03dceb-2564-4962-91d2-18e74dc7b525.png)\n\n위와 같은 삼각형의 꼭대기에서 바닥까지 이어지는 경로 중, 거쳐간 숫자의 합이 가장 큰 경우를 찾아보려고 합니다. 아래 칸으로 이동할 때는 대각선 방향으로 한 칸 오른쪽 또는 왼쪽으로만 이동 가능합니다. 예를 들어 3에서는 그 아래칸의 8 또는 1로만 이동이 가능합니다.\n\n삼각형의 정보가 담긴 배열 triangle이 매개변수로 주어질 때, 거쳐간 숫자의 최댓값을 return 하도록 solution 함수를 완성하세요.\n\n### 제한 사항\n* 삼각형의 높이는 1 이상 500 이하입니다.\n* 삼각형을 이루고 있는 숫자는 0 이상 9,999 이하의 정수입니다.\n\n\t\n### 입출력 예\n\n| triangle                                                | result |\n|---------------------------------------------------------|--------|\n| [[7], [3, 8], [8, 1, 0], [2, 7, 4, 4], [4, 5, 2, 6, 5]] | 30     |\n\n\n<br>\n\n<hr>\n\n## 피드백: \n* 재귀함수 생각하느라 너무 오래걸렷다..\n\n<br>\n\n## 코드 설명:\n* 재귀함수 \n\t\n## 코드:\n\n```python\ndef solution(triangle):\n    memo = {}\n    answer = f(triangle, 0, 0, memo)\n    return answer\n\ndef f(triangle,"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-05-17-_lvl3_야근 지수.md",
    "title": "[lvl3]야근 지수",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습 > 연습문제 > 야근 지수](https://school.programmers.co.kr/learn/courses/30/lessons/12927)\n\n## 문제 설명:\n\n회사원 Demi는 가끔은 야근을 하는데요, 야근을 하면 야근 피로도가 쌓입니다. 야근 피로도는 야근을 시작한 시점에서 남은 일의 작업량을 제곱하여 더한 값입니다. Demi는 N시간 동안 야근 피로도를 최소화하도록 일할 겁니다.Demi가 1시간 동안 작업량 1만큼을 처리할 수 있다고 할 때, 퇴근까지 남은 N 시간과 각 일에 대한 작업량 works에 대해 야근 피로도를 최소화한 값을 리턴하는 함수 solution을 완성해주세요.\n\n## 제한사항:\n- works는 길이 1 이상, 20,000 이하인 배열입니다.\n- works의 원소는 50000 이하인 자연수입니다.\n- n은 1,000,000 이하인 자연수입니다.\n\n\n## 입출력 예:\n\n| works     | n | result |\n|-----------|---|--------|\n| [4, 3, 3] | 4 | 12     |\n| [2, 1, 2] | 1 | 6      |\n| [1,1]     | 3 | 0      |\n\n## 입출력 예에 대한 설명:\n\n### 입출력 예 #1:\n\nn=4 일 때, 남은 일의 작업량이 [4, 3, 3] 이라면 야근 지수를 최소화하기 위해 4시간동안 일을 한 결과는 [2, 2, 2]입니다. 이 때 야근 지수는 $$2^2 + 2^2 + 2^2 = 12$$ 입니다.\n### 입출력 예 #2:\n\nn=1일 때, 남은 일의 작업량이 [2,1,2]라면 야근 지수를 최소화하기 위해 1시간동안 일을 한 결과는 [1,1,2]입니다. 야근지수는 $$1^2 + 1^2 + 2^2 = 6$$ 입니다.\n\n### 입출력 예 #3\n\n남은 작업량이 없으므로 피로도는 0입니다.\n\n<br>\n\n<hr>\n\n## 피드백: \n* heap에 대해서 잘 몰라서 찾아본 뒤에야 풀 수 있었다\n*  heap을 사용하기"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-04-_lvl1__월간 코드 챌린지 시즌2_음양 더하기.md",
    "title": "[lvl1][월간 코드 챌린지 시즌2]음양 더하기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers [월간 코드 챌린지 시즌2]음양 더하기](https://school.programmers.co.kr/learn/courses/30/lessons/76501)\n\n## 문제 설명:\n\n어떤 정수들이 있습니다. 이 정수들의 절댓값을 차례대로 담은 정수 배열 absolutes와 이 정수들의 부호를 차례대로 담은 불리언 배열 signs가 매개변수로 주어집니다. 실제 정수들의 합을 구하여 return 하도록 solution 함수를 완성해주세요.\n\n### [제한사항]\n\n* absolutes의 길이는 1 이상 1,000 이하입니다.\n* absolutes의 모든 수는 각각 1 이상 1,000 이하입니다.\n* signs의 길이는 absolutes의 길이와 같습니다.\n* signs[i] 가 참이면 absolutes[i] 의 실제 정수가 양수임을, 그렇지 않으면 음수임을 의미합니다.\n\n### 입출력 예:\n\n<br>\n\n| absolutes \t| signs \t| result \t|\n|---\t|---\t|---\t|\n| [4,7,12] \t| [true,false,true] \t| 9 \t|\n| [1,2,3] \t| [false,false,true] \t| 0 \t|\n\n<br>\n\n### 입출력 예 설명:\n#### 입출력 예 #1:\n\n* signs가 [true,false,true] 이므로, 실제 수들의 값은 각각 4, -7, 12입니다.\n* 따라서 세 수의 합인 9를 return 해야 합니다.\n\n#### 입출력 예 #2:\n\n* signs가 [false,false,true] 이므로, 실제 수들의 값은 각각 -1, -2, 3입니다.\n* 따라서 세 수의 합인 0을 return 해야 합니다.\n\n\n<br>\n\n<hr>\n\n## 보완해야 할 점: \n* enumerate함수를 썼지만, zip()함수를 써서 사용하는 방법도 고려해볼 만 하다\n\n\n<br>\n\n## 코드설명:\n* enumerate()함수를 이용해 absolute 리스트와 같은 인덱스를 가지는 sig"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-04-_lvl1__월간 코드 챌린지 시즌3_없는 숫자 더하기.md",
    "title": "[lvl1][월간 코드 챌린지 시즌3]없는 숫자 더하기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers [월간 코드 챌린지 시즌3]없는 숫자 더하기](https://school.programmers.co.kr/learn/courses/30/lessons/86051)\n\n## 문제 설명:\n\n0부터 9까지의 숫자 중 일부가 들어있는 정수 배열 numbers가 매개변수로 주어집니다. \n\nnumbers에서 찾을 수 없는 0부터 9까지의 숫자를 모두 찾아 더한 수를 return 하도록 solution 함수를 완성해주세요.\n\n### [제한사항]\n* 1 ≤ numbers의 길이 ≤ 9\n* 0 ≤ numbers의 모든 원소 ≤ 9\n* numbers의 모든 원소는 서로 다릅니다.\n\n### 입출력 예:\n<br>\n\n| numbers \t| result \t|\n|---\t|---\t|\n| [1,2,3,4,6,7,8,0] \t| 14 \t|\n| [5,8,4,0,6,7,9] \t| 6 \t|\n\n<br>\n### 입출력 예 설명:\n\n#### 입출력 예 #1:\n\n* 5, 9가 numbers에 없으므로, 5 + 9 = 14를 return 해야 합니다.\n\n#### 입출력 예 #2:\n\n* 1, 2, 3이 numbers에 없으므로, 1 + 2 + 3 = 6을 return 해야 합니다.\n\n<br>\n\n<hr>\n\n## 보완해야 할 점: \nx\n\n\n<br>\n\n## 코드설명:\n* 0~9까지 숫자를 for문을 돌려 number리스트에 없는것들을 answer리스트에 추가\n* sum함수를 사용하여 answer리스트 요소들의 합을 리턴\n\n## 코드:\n\n```python\ndef solution(numbers):\n    answer = []\n    for i in range(0,10):\n        if i not in numbers:\n            print(i)\n            answer.append(i)\n    \n    return sum(answer)\n```\n\n## 우수답변자 코드:\n* 0~9의 합은 45로 고정되있음을 활용 (참신해서 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-04-_lvl1__2019 카카오 인턴쉽_크레인 인형뽑기 게임.md",
    "title": "[lvl1][2019 카카오 인턴쉽]크레인 인형뽑기 게임",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers: 크레인 인형뽑기 게임\n](https://school.programmers.co.kr/learn/courses/30/lessons/64061?language=python3)\n\n## 문제 설명\n\n게임개발자인 \"죠르디\"는 크레인 인형뽑기 기계를 모바일 게임으로 만들려고 합니다.\n\n\"죠르디\"는 게임의 재미를 높이기 위해 화면 구성과 규칙을 다음과 같이 게임 로직에 반영하려고 합니다.\n\n<p align=\"center\">\n<img width=\"431\" alt=\"image\" src=\"https://user-images.githubusercontent.com/99532836/182839234-c96adf68-8cc4-45a6-9d5a-5d9d1378de34.png\">\n</p>\n\n게임 화면은 \"1 x 1\" 크기의 칸들로 이루어진 \"N x N\" 크기의 정사각 격자이며 위쪽에는 크레인이 있고 오른쪽에는 바구니가 있습니다. (위 그림은 \"5 x 5\" 크기의 예시입니다). 각 격자 칸에는 다양한 인형이 들어 있으며 인형이 없는 칸은 빈칸입니다. 모든 인형은 \"1 x 1\" 크기의 격자 한 칸을 차지하며 격자의 가장 아래 칸부터 차곡차곡 쌓여 있습니다. 게임 사용자는 크레인을 좌우로 움직여서 멈춘 위치에서 가장 위에 있는 인형을 집어 올릴 수 있습니다. 집어 올린 인형은 바구니에 쌓이게 되는 데, 이때 바구니의 가장 아래 칸부터 인형이 순서대로 쌓이게 됩니다. 다음 그림은 [1번, 5번, 3번] 위치에서 순서대로 인형을 집어 올려 바구니에 담은 모습입니다.\n\n<p align=\"center\">\n<img width=\"431\" alt=\"image\" src=\"https://user-images.githubusercontent.com/99532836/182841326-f88ff463-fad7-4260-adf9-f56bb9672013.png\">\n</p>\n\n만약 같은 모양의 인형 두 개가 바구니에 연속해서 쌓이게 되면 두 인형은 터뜨려지면서 바구니에서 사라지게 됩"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-08-04-_lvl1__2022_KAKAO_BLIND_신고 결과 받기.md",
    "title": "[lvl1][2022_KAKAO_BLIND]신고 결과 받기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers: 신고 결과 받기\n](https://school.programmers.co.kr/learn/courses/30/lessons/92334)\n## 문제 설명\n\n신입사원 무지는 게시판 불량 이용자를 신고하고 처리 결과를 메일로 발송하는 시스템을 개발하려 합니다. 무지가 개발하려는 시스템은 다음과 같습니다.\n\n* 각 유저는 한 번에 한 명의 유저를 신고할 수 있습니다.\n * 신고 횟수에 제한은 없습니다. 서로 다른 유저를 계속해서 신고할 수 있습니다.\n * 한 유저를 여러 번 신고할 수도 있지만, 동일한 유저에 대한 신고 횟수는 1회로 처리됩니다.\n* k번 이상 신고된 유저는 게시판 이용이 정지되며, 해당 유저를 신고한 모든 유저에게 정지 사실을 메일로 발송합니다.\n * 유저가 신고한 모든 내용을 취합하여 마지막에 한꺼번에 게시판 이용 정지를 시키면서 정지 메일을 발송합니다.\n\n다음은 전체 유저 목록이 [\"muzi\", \"frodo\", \"apeach\", \"neo\"]이고, k = 2(즉, 2번 이상 신고당하면 이용 정지)인 경우의 예시입니다.\n\n<br>\n\n| 유저 ID \t| 유저가 신고한 ID \t| 설명 \t|\n|---\t|---\t|---\t|\n| \"muzi\" \t| \"frodo\" \t| \"muzi\"가 \"frodo\"를 신고했습니다. \t|\n| \"apeach\" \t| \"frodo\" \t| \"apeach\"가 \"frodo\"를 신고했습니다. \t|\n| \"frodo\" \t| \"neo\" \t| \"frodo\"가 \"neo\"를 신고했습니다. \t|\n| \"muzi\" \t| \"neo\" \t| \"muzi\"가 \"neo\"를 신고했습니다. \t|\n| \"apeach\" \t| \"muzi\" \t| \"apeach\"가 \"muzi\"를 신고했습니다. \t|\n\n<br>\n\n유저 ID\t신고당한 횟수\n\n<br>\n\n| \"muzi\" \t| 1 \t|\n|---\t|---\t|\n| \"frodo\" \t| 2 \t|\n| \"apeach\" \t| 0 \t|\n| \"neo\" \t| 2 \t|\n\n<br>\n\n위 예시에서는 2번 이상 신고당한 \"frodo"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-06-30-이진 변환 반복하기.md",
    "title": "[lvl2]이진 변환 반복하기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습> 월간 코드 챌린지 시즌 1 > 이진 변환 반복하기](https://school.programmers.co.kr/learn/courses/30/lessons/70129)\n\n## 문제 설명:\n0과 1로 이루어진 어떤 문자열 x에 대한 이진 변환을 다음과 같이 정의합니다.\n\n1. x의 모든 0을 제거합니다.\n2. x의 길이를 c라고 하면, x를 \"c를 2진법으로 표현한 문자열\"로 바꿉니다.\n\n예를 들어, `x = \"0111010\"`이라면, x에 이진 변환을 가하면 `x = \"0111010\" -> \"1111\" -> \"100\"` 이 됩니다.\n\n0과 1로 이루어진 문자열 s가 매개변수로 주어집니다. s가 \"1\"이 될 때까지 계속해서 s에 이진 변환을 가했을 때, 이진 변환의 횟수와 변환 과정에서 제거된 모든 0의 개수를 각각 배열에 담아 return 하도록 solution 함수를 완성해주세요.\n\n## 제한사항\n\n- s의 길이는 1 이상 150,000 이하입니다.\n- s에는 '1'이 최소 하나 이상 포함되어 있습니다.\n\n---\n\n## 입출력 예\n\n|s|result|\n|---|---|\n|`\"110010101001\"`|`[3,8]`|\n|`\"01110\"`|`[3,3]`|\n|`\"1111111\"`|`[4,1]`|\n\n---\n\n## 입출력 예 설명\n\n입출력 예 #1\n\n- \"110010101001\"이 \"1\"이 될 때까지 이진 변환을 가하는 과정은 다음과 같습니다.\n\n|회차|이진 변환 이전|제거할 0의 개수|0 제거 후 길이|이진 변환 결과|\n|---|---|---|---|---|\n|1|\"110010101001\"|6|6|\"110\"|\n|2|\"110\"|1|2|\"10\"|\n|3|\"10\"|1|1|\"1\"|\n\n- 3번의 이진 변환을 하는 동안 8개의 0을 제거했으므로, `[3,8]`을 return 해야 합니다.\n\n입출력 예 #2\n\n- \"01110\"이 \"1\"이 될 때까지 이진 변환을 가하는 과정은 다음과 같습니다.\n\n|회차|이진 변환 이전|제거할 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-08-25-lvl3-합승 택시 요금.md",
    "title": "[lvl3]합승 택시 요금",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: \\[Programmers > 코딩테스트 연습 >2021 KAKAO BLIND RECRUITMENT > 합승 택시 요금 (https://school.programmers.co.kr/learn/courses/30/lessons/72413)\n \n## 문제 설명:\n\n**\\[본 문제는 정확성과 효율성 테스트 각각 점수가 있는 문제입니다.]**\n\n밤늦게 귀가할 때 안전을 위해 항상 택시를 이용하던 `무지`는 최근 야근이 잦아져 택시를 더 많이 이용하게 되어 택시비를 아낄 수 있는 방법을 고민하고 있습니다. \"무지\"는 자신이 택시를 이용할 때 동료인 `어피치` 역시 자신과 비슷한 방향으로 가는 택시를 종종 이용하는 것을 알게 되었습니다. \"무지\"는 \"어피치\"와 귀가 방향이 비슷하여 택시 합승을 적절히 이용하면 택시요금을 얼마나 아낄 수 있을 지 계산해 보고 \"어피치\"에게 합승을 제안해 보려고 합니다.\n\n![2021_kakao_taxi_01.png](https://grepp-programmers.s3.ap-northeast-2.amazonaws.com/files/production/715ff493-d1a0-44d8-9273-a785280b3f1e/2021_kakao_taxi_01.png)\n\n위 예시 그림은 택시가 이동 가능한 반경에 있는 6개 지점 사이의 이동 가능한 택시노선과 예상요금을 보여주고 있습니다.  \n그림에서 `A`와 `B` 두 사람은 출발지점인 4번 지점에서 출발해서 택시를 타고 귀가하려고 합니다. `A`의 집은 6번 지점에 있으며 `B`의 집은 2번 지점에 있고 두 사람이 모두 귀가하는 데 소요되는 예상 최저 택시요금이 얼마인 지 계산하려고 합니다.\n\n- 그림의 원은 지점을 나타내며 원 안의 숫자는 지점 번호를 나타냅니다.\n    - 지점이 n개일 때, 지점 번호는 1부터 n까지 사용됩니다.\n- 지점 간에 택시가 이동할 수 있는 경로를 간선이라 하며, 간선에 표시된 숫자는 두 지점 사이의 예상 택시요금을 나타냅니다.\n    - 간선은 편의 상 직선으"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-08-06-lvl2-하노이의 탑.md",
    "title": "[lvl2]하노이의 탑",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습 > 연습문제 > 하노이의 탑](https://school.programmers.co.kr/learn/courses/30/lessons/12946)\n\n\n## 문제 설명:\n\n하노이 탑(Tower of Hanoi)은 퍼즐의 일종입니다. 세 개의 기둥과 이 기동에 꽂을 수 있는 크기가 다양한 원판들이 있고, 퍼즐을 시작하기 전에는 한 기둥에 원판들이 작은 것이 위에 있도록 순서대로 쌓여 있습니다. 게임의 목적은 다음 두 가지 조건을 만족시키면서, 한 기둥에 꽂힌 원판들을 그 순서 그대로 다른 기둥으로 옮겨서 다시 쌓는 것입니다.\n\n1. 한 번에 하나의 원판만 옮길 수 있습니다.\n2. 큰 원판이 작은 원판 위에 있어서는 안됩니다.\n\n하노이 탑의 세 개의 기둥을 왼쪽 부터 1번, 2번, 3번이라고 하겠습니다. 1번에는 n개의 원판이 있고 이 n개의 원판을 3번 원판으로 최소 횟수로 옮기려고 합니다.\n\n1번 기둥에 있는 원판의 개수 n이 매개변수로 주어질 때, n개의 원판을 3번 원판으로 최소로 옮기는 방법을 return하는 solution를 완성해주세요.\n\n### 제한사항\n\n- n은 15이하의 자연수 입니다.\n\n---\n\n### 입출력 예\n\n|n|result|\n|---|---|\n|2|[ [1,2], [1,3], [2,3] ]|\n\n### 입출력 예 설명\n\n#### 입출력 예 #1  \n다음과 같이 옮길 수 있습니다.\n\n![Imgur](https://i.imgur.com/SWEqD08.png)  \n![Imgur](https://i.imgur.com/mrmOzV2.png)  \n![Imgur](https://i.imgur.com/Ent83gA.png)  \n![Imgur](https://i.imgur.com/osJFfhF.png)\n\n\n## 코드:\n\n```python\ndef move(n, start, end, mid):\n    if n == 1:\n        return [[start, end]]\n    return move(n-"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2024-01-17-lvl2_뒤에 있는 큰 수 찾기.md",
    "title": "[lvl2]뒤에 있는 큰 수 찾기",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 뒤에 있는 큰 수 찾기](https://school.programmers.co.kr/learn/courses/30/lessons/154539)\n\n## 문제 설명:\n\n정수로 이루어진 배열 `numbers`가 있습니다. 배열 의 각 원소들에 대해 자신보다 뒤에 있는 숫자 중에서 자신보다 크면서 가장 가까이 있는 수를 뒷 큰수라고 합니다.  \n\n정수 배열 `numbers`가 매개변수로 주어질 때, 모든 원소에 대한 뒷 큰수들을 차례로 담은 배열을 return 하도록 solution 함수를 완성해주세요. 단, 뒷 큰수가 존재하지 않는 원소는 -1을 담습니다.\n\n---\n\n### 제한사항\n\n- 4 ≤ `numbers`의 길이 ≤ 1,000,000\n    - 1 ≤ `numbers[i]` ≤ 1,000,000\n\n---\n\n### 입출력 예\n\n|numbers|result|\n|---|---|\n|[2, 3, 3, 5]|[3, 5, 5, -1]|\n|[9, 1, 5, 3, 6, 2]|[-1, 5, 6, 6, -1, -1]|\n\n---\n\n### 입출력 예 설명\n\n#### 입출력 예 #1  \n2의 뒷 큰수는 3입니다. 첫 번째 3의 뒷 큰수는 5입니다. 두 번째 3 또한 마찬가지입니다. 5는 뒷 큰수가 없으므로 -1입니다. 위 수들을 차례대로 배열에 담으면 \\[3, 5, 5, -1]이 됩니다.\n\n#### 입출력 예 #2  \n9는 뒷 큰수가 없으므로 -1입니다. 1의 뒷 큰수는 5이며, 5와 3의 뒷 큰수는 6입니다. 6과 2는 뒷 큰수가 없으므로 -1입니다. 위 수들을 차례대로 배열에 담으면 \\[-1, 5, 6, 6, -1, -1]이 됩니다.\n## 코드:\n\n```python\ndef solution(numbers):\n    stack = []\n    result = [-1] * len(numbers)\n\n    for i, num in enumerate(numbers):\n        while stack and numbers[stack[-1]] < nu"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-05-16-_lvl3_최고의 집합.md",
    "title": "[lvl3]최고의 집합",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습 > 연습문제 > 최고의 집합](https://school.programmers.co.kr/learn/courses/30/lessons/12938)\n\n## 문제 설명:\n\n자연수 n 개로 이루어진 중복 집합(multi set, 편의상 이후에는 \"집합\"으로 통칭) 중에 다음 두 조건을 만족하는 집합을 최고의 집합이라고 합니다.\n\n각 원소의 합이 S가 되는 수의 집합\n위 조건을 만족하면서 각 원소의 곱 이 최대가 되는 집합\n예를 들어서 자연수 2개로 이루어진 집합 중 합이 9가 되는 집합은 다음과 같이 4개가 있습니다.\n\n{ 1, 8 }, { 2, 7 }, { 3, 6 }, { 4, 5 }\n\n그중 각 원소의 곱이 최대인 { 4, 5 }가 최고의 집합입니다.\n\n집합의 원소의 개수 n과 모든 원소들의 합 s가 매개변수로 주어질 때, 최고의 집합을 return 하는 solution 함수를 완성해주세요.\n\n## [제한사항]\n- 최고의 집합은 오름차순으로 정렬된 1차원 배열(list, vector) 로 return 해주세요.\n- 만약 최고의 집합이 존재하지 않는 경우에 크기가 1인 1차원 배열(list, vector) 에 -1 을 채워서 return 해주세요.\n- 자연수의 개수 n은 1 이상 10,000 이하의 자연수입니다.\n모든 원소들의 합 s는 1 이상, 100,000,000 이하의 자연수입니다.\n\n## 입출력 예:\n\n| n | s | result |\n|---|---|--------|\n| 2 | 9 | [4, 5] |\n| 2 | 1 | [-1]   |\n| 2 | 8 | [4, 4] |\n\n## 입출력 예에 대한 설명:\n\n### 입출력 예 #1:\n\n문제의 예시와 같습니다.\n\n### 입출력 예 #2:\n\n자연수 2개를 가지고는 합이 1인 집합을 만들 수 없습니다. 따라서 -1이 들어있는 배열을 반환합니다.\n\n\n### 입출력 예 #3:\n\n자연수 2개로 이루어진 집합 중 원소의 합이 8인 집합은 다음과 같습니다.\n\n{ 1, 7 }"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2022-09-27-_lvl2_최대값과 최솟값.md",
    "title": "[lvl2]최댓값과 최솟값",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습 > 연습문제 > 최댓값과 최솟값\n](https://school.programmers.co.kr/learn/courses/30/lessons/12939)\n\n## 문제 설명:\n\n문자열 s에는 공백으로 구분된 숫자들이 저장되어 있습니다. str에 나타나는 숫자 중 최소값과 최대값을 찾아 이를 \"(최소값) (최대값)\"형태의 문자열을 반환하는 함수, solution을 완성하세요.\n\n예를들어 s가 \"1 2 3 4\"라면 \"1 4\"를 리턴하고, \"-1 -2 -3 -4\"라면 \"-4 -1\"을 리턴하면 됩니다.\n\n### [제한 조건]\ns에는 둘 이상의 정수가 공백으로 구분되어 있습니다.\n\n### 입출력 예\n\n| s             \t| return  \t|\n|---------------\t|---------\t|\n| \"1 2 3 4\"     \t| \"1 4\"   \t|\n| \"-1 -2 -3 -4\" \t| \"-4 -1\" \t|\n| \"-1 -1\"       \t| \"-1 -1\" \t|\n\n<br>\n\n<hr>\n\n## 피드백: \n* split을 map과 같이 쓰는방법:\n```\ns = list(map(int,s.split()))\n```\n\n\n\n\n<br>\n\n## 코드 설명:\n* split()함수를 사용해 띄어쓰기로 구분된 숫자들을 리스트로 저장\n*  list(map(int, list_a)를 사용해 리스트의 스트링 value들을 int형태로 변환\n*  min, max함수를 사용한 후 string형태로 바꿔서 answer에 저장\n\t\n## 코드:\n\n```python\ndef solution(s):\n    list_a = s.split(' ')\n    list_a = list(map(int, list_a))\n    \n    answer = str(min(list_a)) + \" \" + str(max(list_a))\n                                         \n    return answer\n```\n\n## 우수답변자 코드:\n\n```p"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-07-03-다음 큰 숫자.md",
    "title": "[lvl2]다음 큰 숫자",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습 > 연습문제 > 다음 큰 숫자](https://school.programmers.co.kr/learn/courses/30/lessons/12911)\n\n## 문제 설명:\n\n\n자연수 n이 주어졌을 때, n의 다음 큰 숫자는 다음과 같이 정의 합니다.\n\n- 조건 1. n의 다음 큰 숫자는 n보다 큰 자연수 입니다.\n- 조건 2. n의 다음 큰 숫자와 n은 2진수로 변환했을 때 1의 갯수가 같습니다.\n- 조건 3. n의 다음 큰 숫자는 조건 1, 2를 만족하는 수 중 가장 작은 수 입니다.\n\n예를 들어서 78(1001110)의 다음 큰 숫자는 83(1010011)입니다.\n\n자연수 n이 매개변수로 주어질 때, n의 다음 큰 숫자를 return 하는 solution 함수를 완성해주세요.\n\n## 제한 사항\n\n- n은 1,000,000 이하의 자연수 입니다.\n\n---\n\n## 입출력 예\n\n|n|result|\n|---|---|\n|78|83|\n|15|23|\n\n## 입출력 예 설명\n\n입출력 예#1  \n문제 예시와 같습니다.  \n입출력 예#2  \n15(1111)의 다음 큰 숫자는 23(10111)입니다.\n\n## 코드 설명:\n- collections Counter을 사용\n- bin함수로 2진수로 바꾼 후 앞에 0b를 제거\n- while문을 사용해 자연수를 n보다 1씩 늘려주며 2진수로 변환시 1의 개수가 n의 2진수 변환시 1의 개수와 같다면 리턴\n\n## 코드:\n```python\nfrom collections import Counter\ndef solution(n):\n    number = Counter(bin(n)[2:])['1']\n    answer = n + 1\n    while True:\n        if Counter(bin(answer)[2:])['1'] == number:\n            return answer\n        answer +=1\n```\n\n## 우수답변자 코드:\n```python\ndef nextBi"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Study/Code-Test/2023-08-05-lvl3-네트워크.md",
    "title": "[lvl3]네트워크",
    "description": "",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n출처: [Programmers > 코딩테스트 연습 > 깊이/너비 우선 탐색(DFS/BFS) > 네트워크\n](https://school.programmers.co.kr/learn/courses/30/lessons/43162)\n\n## 문제 설명:\n\n네트워크란 컴퓨터 상호 간에 정보를 교환할 수 있도록 연결된 형태를 의미합니다. 예를 들어, 컴퓨터 A와 컴퓨터 B가 직접적으로 연결되어있고, 컴퓨터 B와 컴퓨터 C가 직접적으로 연결되어 있을 때 컴퓨터 A와 컴퓨터 C도 간접적으로 연결되어 정보를 교환할 수 있습니다. 따라서 컴퓨터 A, B, C는 모두 같은 네트워크 상에 있다고 할 수 있습니다.\n\n컴퓨터의 개수 n, 연결에 대한 정보가 담긴 2차원 배열 computers가 매개변수로 주어질 때, 네트워크의 개수를 return 하도록 solution 함수를 작성하시오.\n\n### 제한사항\n\n- 컴퓨터의 개수 n은 1 이상 200 이하인 자연수입니다.\n- 각 컴퓨터는 0부터 `n-1`인 정수로 표현합니다.\n- i번 컴퓨터와 j번 컴퓨터가 연결되어 있으면 computers[i][j]를 1로 표현합니다.\n- computer[i][i]는 항상 1입니다.\n\n### 입출력 예\n\n|n|computers|return|\n|---|---|---|\n|3|[[1, 1, 0], [1, 1, 0], [0, 0, 1]]|2|\n|3|[[1, 1, 0], [1, 1, 1], [0, 1, 1]]|1|\n\n### 입출력 예 설명\n\n#### 예제 #1  \n아래와 같이 2개의 네트워크가 있습니다.  \n\n![image0.png](https://grepp-programmers.s3.amazonaws.com/files/ybm/5b61d6ca97/cc1e7816-b6d7-4649-98e0-e95ea2007fd7.png)\n\n#### 예제 #2  \n\n아래와 같이 1개의 네트워크가 있습니다.  \n\n![image1.png](https://grepp-programmers.s3.amazonaws.com/files/ybm/7"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/2024-01-28-포텐데이 회고.md",
    "title": "포텐데이 해커톤 회고",
    "description": "비사이드 포텐데이 10일 해커톤 참가 회고 - 기획자, 개발자, 디자이너의 협업 경험",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 비사이드에서 주최한 포텐데이 해커톤에 참가하여 10일간 4-6명의 기획자, 백엔드/프론트엔드 개발자, 디자이너와 팀을 이루어 협업한 경험을 정리한 회고록이다. 프로젝트 기획부터 개발, 발표까지의 전 과정, 팀워크의 중요성, 그리고 배운 점들을 포함한다.\n## Intro: \n\n비사이드에서 진행하는 포텐데이에 참가 신청했다. 포텐데이에서 10일간 총 4-6명의 기획자, 개발자(Back-End), 개발자(Front-End), 디자이너가 팀빌딩 후 협업하여 프로젝트를 진행한다.\n\n## 일정:\n포텐데이측에서 기본적으로 제공하는 일정표이다. 강제적인건 아니지만 구체적이여서 가이드라인으로 사용하기에 적합했다.\n![](https://i.imgur.com/OhjRI0a.png)\n\n### 시작 전:\n참가자들은 슬랙에 초대받았고, 슬랙에서 팀 빌딩을 위해 자기 자신을 소개할 수 있는 채널이 마련되어있었다. 많은 분들이 경력, 참여 의지, 사용 가능 기술 스택, 희망 주제, 등으로 어필하였다. 개인적으로 생각했던것보다 주제를 미리 생각해오신 분들이 없었고, 진행했던 프로젝트를 소개해주신 특정 몇분을 제외하고는 소개해주신 분들 중 차별점을 찾기 어려웠던것 같다는 느낌이 들었다.\n\n기획자 1, 백엔드 2, 프론트엔드 2, 디자이너1 으로 이루어진 팀으로 자동팀빌딩 되었다. 포지션 밸런스가 이상적인 팀에 배정받아서 안심이 되는것 같다.\n### Day-1:\n주요 내용:\n- 자기소개\n- 노션 페이지 제작\n- 그라운드 룰 결정\n- 접속 시간, 회의 가능 시간\n\n첫 회의 시간 일정을 잡았는데 첫날부터 빨리 시작하고 싶은 조급한 마음과는 달리 회의가 저녁 11시에 잡혀서 오전 오후시간에 이건 기수들의 프로젝트를 구경하고, 필요한 기술이 어떤게 있을지, 첫 회의시간엔 무슨 내용을 토의해야할지 고민하며 시간을 보냈던것 같다.\n\n이전 기수들의 노션 페이지를 본 결과, 대부분 포텐데이에서 제공하는 템플렛을 복사하여 쓰는 경우가 많이 보였다. 이전 기수들의 노션페이지를 복제"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/PodlyBot/2024-09-18-메신저봇R 활용 카카오 챗봇 만들기.md",
    "title": "메신저봇R로 카카오톡 챗봇 만들기 기초",
    "description": "메신저봇R을 활용하여 카카오톡 오픈 채팅방 챗봇을 만드는 기본 가이드",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 메신저봇R 앱을 활용하여 카카오톡 오픈 채팅방에서 작동하는 챗봇을 직접 만드는 기초 가이드이다. 디스코드 봇과 유사하면서도 접근성이 좋은 카카오 챗봇의 개발 환경 설정, 기본 스크립트 작성, 메시지 수신/응답 구현 방법을 다룬다.\n\n## Intro:\n\n현재 많은 정보를 얻고 있는 카카오톡 오픈 채팅방에 챗봇이 존재한다. 한 멤버분이 만들어 주셨는데, 디스코드봇을 연상시키면서도 접근성이 좋아 편리해보였다. 어떻게 만드나 궁금해 하던 도중 직접 해보기로 했다.\n\n## PodlyBot 프로젝트\n\n이 튜토리얼을 바탕으로 만든 **PodlyBot**은 안드로이드 공기계에서 24/7 운영되는 카카오톡 LLM 챗봇이다.\n\n### 주요 기능\n- **LLM 대화**: 단체 채팅방에서 즉시 호출 가능한 GPT 기반 대화 기능\n- **URL 자동 요약**: 채팅방에 공유된 URL을 자동으로 감지하고 내용 요약\n- **Notion 자동 정리**: 요약된 내용을 Notion 데이터베이스에 자동 저장\n- **개인 워크플로우 최적화**: 유용한 URL을 카톡으로 보내면 자동으로 정리되어 나중에 Notion에서 확인 가능\n\n### 기술 스택\n- Platform: 메신저봇R (Android)\n- Language: JavaScript (Rhino Engine)\n- AI: OpenAI GPT API\n- Integration: Notion API, Web Scraping\n- Deployment: 안드로이드 듀얼넘버 공기계\n\n### 확장 버전: LabQ Bot\n회사에서는 PodlyBot을 기반으로 **LabQ Bot**을 추가로 개발했다:\n- 회사 자체 LLM 서비스 연동으로 고객사 테스트 지원\n- 회사 Notion 워크스페이스에 팀 지식 자동 정리\n- 팀원들의 협업 및 생산성 향상\n\n이 문서는 이러한 봇들의 기반이 되는 메신저봇R 사용법을 다룬다. \n\n\n### 메신저봇R\n그 과정에 메신저봇R이라는 앱을 사용하는데, 이 앱은 주로 JavaScript를 사용하여 스크립"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/고용노동 공공데이터 활용 공모전/2024-06-13-고용노동 공모전 프로젝트구조.md",
    "title": "고용노동 공모전 프로젝트 아키텍처",
    "description": "고용노동 공모전 프로젝트의 시스템 아키텍처 및 서비스 구조 설계",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 고용노동 공공데이터 활용 공모전 프로젝트의 시스템 아키텍처와 서비스 구조를 정리한 문서이다. FastAPI 기반 백엔드, 프론트엔드, AI 서비스, 데이터베이스, Docker 컨테이너 구성 등 전체 시스템의 기술 스택과 구조를 설명한다.\n\n## Services\n\n\n### Backend(Fast-api)\n\n### DB(MySQL)\n\n### Nginx\n\n\n\n## 구조\n\n#### 각 디렉토리와 파일의 역할 설명\n\n1. **`backend/app/alembic`**: 데이터베이스 마이그레이션을 위한 Alembic 설정.\n2. **`backend/app/core`**: 애플리케이션 설정 및 공통 유틸리티.\n3. **`backend/app/db`**: 데이터베이스 관련 코드 (세션 관리, 초기화 등).\n4. **`backend/app/llm`**: LangChain 관련 코드 (로더, 벡터 데이터베이스, 에이전트, 그래프).\n5. **`backend/app/models`**: SQLAlchemy 모델 정의.\n6. **`backend/app/routers`**: FastAPI 라우터 정의.\n7. **`backend/app/schemas`**: Pydantic 스키마 정의.\n8. **`backend/app/dependencies`**: 의존성 주입 관련 코드.\n\n```\n\n.\n├── alembic.ini\n├── backend\n│   ├── Dockerfile\n│   ├── app\n│   │   ├── __pycache__\n│   │   │   └── main.cpython-312.pyc\n│   │   ├── alembic\n│   │   │   ├── env.py\n│   │   │   └── versions\n│   │   ├── core\n│   │   │   ├── __pycache__\n│   │   │   └── config.py\n│   │   ├── crud\n│   │   │   ├── __pycache__\n│   │   │   └── user"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/고용노동 공공데이터 활용 공모전/2024-06-03-사업계획서_초안.md",
    "title": "고용노동 공모전 사업계획서 초안",
    "description": "취약계층 지원을 위한 고용노동 공공데이터 활용 서비스 사업계획서 초안",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 고용노동 공공데이터 활용 공모전을 위한 사업계획서 초안이다. 복지사와 NGO/NPO가 취약계층을 효과적으로 지원할 수 있도록 고용노동 공공데이터를 활용한 통합 플랫폼 제안을 담고 있으며, 서비스 목적, 기능, 기술 스택, 기대 효과를 포괄적으로 정리한다.\n# 고용노동 공공데이터 활용 공모전 - 사업계획서\n\n## 용어 정의:\n\n- **복지사**: 비정부기구(NGO), 비영리단체(NPO), 사설 복지기관, 병원, 지역사회 센터 등에서 취약계층을 지원하는 사회복지 전문가.\n- **유저**: 복지사의 관리 하에 혜택 정보를 제공받는 개인.\n- **관리자 페이지**: 복지사들이 유저 정보를 입력하고, 챗봇 상담 기록과 알림 내역을 열람할 수 있는 웹 인터페이스.\n- **알림 서비스**: 유저에게 필요한 혜택 정보가 있을 때 카카오톡 등을 통해 실시간으로 알림을 제공하는 기능.\n- **RAG 기반 챗봇 서비스**: Retrieval-Augmented Generation(문서 검색 기반 생성) 기술을 활용하여 유저의 질문에 답변하고 필요한 정보를 제공하는 챗봇.\n- **구독 기반 모델**: 복지사 또는 복지기관이 월간 또는 연간 구독료를 지불하고 서비스를 이용하는 비즈니스 모델.\n- **데이터 분석 서비스**: 수집된 데이터를 분석하여 복지사와 유저에게 유용한 인사이트를 제공하는 서비스.\n- **프리미엄 서비스**: 추가 기능이나 고급 서비스를 제공하는 유료 서비스.\n- 자립청년: 자립준비청년(보호종료아동)이란 아동복지 양육시설(보육원), 공동생활가정, 위탁가정 등의 보호를 받다 보호가 종료돼 홀로 서기에 나서는 만 18~24세 아이들을 뜻합니다. 자립준비청년들은 몸도 마음도 기댈 자리가 필요합니다.\n\n## **1. 제품 및 서비스의 목적 기능 및 특징**\n\n### **1-1. 목적 및 배경**\n\n**자립 청년과 복지사를 위한 서비스 필요성**\n\n- 자립준비청년 및 소외계층은 복지 정보 접근성의 제한으로 인해 필요한 혜택을 놓치는 경우가 많음"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/고용노동 공공데이터 활용 공모전/2024-06-24-고용노동 공모전 계획.md",
    "title": "고용노동 공공데이터 활용 공모전 프로젝트 계획",
    "description": "고용노동 공공데이터 활용 공모전 참가를 위한 프로젝트 계획 및 일정 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 고용노동부 주최 공공데이터 활용 공모전에 참가하기 위한 프로젝트 계획서이다. 응모 일정, 심사 기준, 제출 서류, 프로젝트 아이디어, 그리고 개발 일정을 포함한 전체 참가 전략을 정리한다.\n\n## 응모 일정\n\n- 접수기간 : 2024. 03. 28.(목) ~ 07. 21.(일) 24:00까지\n- 1차 심사 : 2024. 07. 24.(수) ~ 07. 26.(금)\n- 1차 심사 결과발표 : 2024. 08. 02.(금)\n- 2차 심사 : 2024. 08. 19.(월)\n\n* 아이디어 기획: PT\n\n* 제품 및 서비스 개발: PT 및 서비스 시연\n\n- 결과발표 : 2024. 08. 23.(금)\n- 시상식 : 2024. 08. 28(수)\n\n* 주최사 사정에 따라 일정이 일부 조정될 수 있음\n\n\n\n## 일정\n- ERD 온통청년 기준으로\n\n#### 백엔드\n- 유저\n\t- 회원가입\n\t- 로그인, 세션 관리, 로그아웃\n- 게시판\n- 댓글\n- 정책\n- 알람\n- 챗봇\n- Database Class 생성\n- 관리자\n#### 프론트\n- 랜딩 페이지\n- 회원가입\n- 로그인\n- 네비게이션 바\n- 팝업창\n\n#### 데이터\n- 크롤링\n- 전처리\n- DB\n- Vectorstore\n\t- metadata\n\n#### 모델링\n- RAG\n\t- 평가지표\n\t- 테스트 데이터\n- Prompt engineering\n- OPENAI 가져오기"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/고용노동 공공데이터 활용 공모전/2024-06-05-사업계획서-1,2번.md",
    "title": "고용노동 공모전 사업계획서 - 제품 목적 및 기능",
    "description": "고용노동 공공데이터 활용 공모전 사업계획서 - 제품 및 서비스의 목적, 기능, 특징 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 고용노동 공공데이터 활용 공모전 제출용 사업계획서의 핵심 내용이다. 제품 및 서비스의 목적과 배경, 주요 기능, 차별화된 특징, 기대 효과를 구체적으로 정리하여 공공데이터를 활용한 혁신 서비스 제안을 담고 있다.\n\n## 1. 제품 및 서비스의 목적 기능 및 특징\n\n### 1-1. 목적 및 배경\n\n자립 청년과 복지사를 위한 서비스 필요성\n\n- 정보가 여러 곳에 분산되어 있으며, 제공 기관이 다르기 때문에 한 곳에서 통합적으로 확인하기가 어려움이 있음\n    x\n- 복지 혜택 정보의 복잡성과 다양성으로 인해 개인별로 적합한 정보를 찾는 것이 어려움\n    \n\n개개인 맞춤형 복지 알림 및 관리 서비스의 목적\n\n- 자립준비청년에게 맞춤형 복지 혜택 정보를 신속하게 제공하여 복지 서비스 접근성 향상\n    \n- 복지사들이 관리하는 유저들의 데이터를 기반으로 한 맞춤형 정보 제공을 통해 복지 서비스의 효과성 증대\n    \n- RAG(Retrieval-Augmented Generation) 기반 챗봇을 통한 상시 상담 서비스 제공으로 유저의 질문에 신속하고 정확하게 대응\n    \n- 제공하는 정보의 출처를 명확히 하여 신뢰성 향상 및 편의성 제공\n    \n\n서비스 구현을 위한 기술적 요구사항\n\n- 접근 제어 시스템을 통해 관리자와 유저의 권한을 체계적으로 관리\n    \n- 관리자 페이지 개발을 통해 복지사들이 유저 정보 및 챗봇 상담 기록을 효과적으로 관리할 수 있는 인터페이스 제공\n    \n- 다양한 제공 기관에서 분산되어 있는 정보를 한 곳에서 통합하여 실시간으로 업데이트\n    \n\n  \n\n## 4. 제품 및 서비스의 차별성\n\n### 4-1. 기존 서비스와의 차별점\n\n차별화된 맞춤형 알림 시스템\n\n- 사용자의 선호와 이력을 기반으로 필터링된 복지 정보를 실시간으로 전달하는 동적 알림 시스템을 구축\n    \n- 카카오톡 등 일상적으로 사용하는 메신저 서비스를 통해 필요한 혜택 정보를 알림으로 제공\n    \n\n고도화된 LLM + RAG 기반 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Podly/2024-08-17-Podly 백엔드 Todo.md",
    "title": "Podly 백엔드 개발 계획",
    "description": "Podly 프로젝트 백엔드 개발을 위한 상세 작업 계획 및 Todo 리스트",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Podly 프로젝트의 백엔드 개발을 위한 종합 작업 계획이다. 초기 환경 설정부터 API 개발, 데이터베이스 설계, 인증 시스템 구축, 배포 및 테스트까지 전체 백엔드 개발 과정의 체계적인 Todo 리스트를 포함한다.\n\n\n[Backend Todos](https://www.notion.so/53b65841ed204c799a648567d48ed891?pvs=21)\n\n### **1. 초기 환경 설정**\n\n- [ ] **도커 설정**\n    - [ ] Dockerfile 작성 (FastAPI 애플리케이션을 위한)\n    - [ ] 도커 컴포즈(Docker Compose) 파일 작성 (DB, Redis, 애플리케이션 등 구성 요소 포함)\n    - [ ] Docker 환경에서 애플리케이션 빌드 및 실행 테스트\n- [ ] **환경 변수 설정**\n    - [ ] .env 파일 생성 및 환경 변수 관리 (데이터베이스, API 키, OAuth 설정 등)\n- [ ] **GitHub 설정**\n    - [ ] GitHub 리포지토리 생성 및 초기화\n    - [ ] .gitignore 파일 설정 (예: .env, **pycache** 등)\n    - [ ] GitHub 브랜치 전략 설정 (main, dev, feature 브랜치)\n    - [ ] GitHub Actions 설정 (CI/CD 파이프라인)\n\n### **2. 데이터베이스 설계 및 설정**\n\n- [ ] **데이터 모델링**\n    \n    - [ ] 유저 테이블 설계 및 생성\n    - [ ] 뉴스 테이블 설계 및 생성\n    - [ ] 팟캐스트 테이블 설계 및 생성\n- [ ] **데이터베이스 연동**\n    \n    - [ ] Fast-API와 데이터베이스 연결 설정 (PostgreSQL 또는 MongoDB)\n    - [ ] Alembic 설정 및 데이터베이스 마이그레이션 스크립트 작성\n\n### **3. API 설계 및 구현**\n\n- [ ] **사용자 관리 API**\n    - [ "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Podly/2024-08-17-Podly AI Todo.md",
    "title": "Podly AI 개발 계획",
    "description": "Podly 프로젝트 AI 기능 개발을 위한 상세 작업 계획 및 Todo 리스트",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Podly 프로젝트의 AI 기능 개발을 위한 종합 작업 계획이다. LangChain을 활용한 뉴스 요약 및 콘텐츠 생성 모델 개발, RAG 시스템 구현, 프롬프트 엔지니어링, AI 서비스 최적화까지 전체 AI 개발 과정의 체계적인 Todo 리스트를 포함한다.\n\n### **1. AI 모델 설계 및 구현**\n\n- [ ]  **뉴스 요약 및 콘텐츠 생성 모델 개발**\n    - [ ]  LangChain을 사용한 뉴스 요약 모델 설계 및 구현\n    - [ ]  뉴스 요약 및 콘텐츠 생성을 위한 데이터셋 수집 및 전처리\n    - [ ]  모델 훈련 및 성능 평가\n    - [ ]  모델의 하이퍼파라미터 튜닝 및 최적화\n- [ ]  **모델 검증 및 테스트**\n    - [ ]  **임베딩 모델 테스트**\n        - [ ]  Upstage/solar-embedding-1-large 테스트 및 성능 평가\n        - [ ]  OpenAI/text-embedding-3-small 테스트 및 성능 평가\n        - [ ]  intfloat/multilingual-e5-large-instruct 테스트 및 성능 평가\n    - [ ]  **사전 모델 테스트**\n        - [ ]  Upstage/Solar 모델 테스트 및 성능 평가\n        - [ ]  OpenAI/gpt-4o-mini 모델 테스트 및 성능 평가\n    - [ ]  **Groundedness 모델 테스트**\n        - [ ]  Upstage/solar-1-mini-groundedness-check 테스트 및 성능 평가\n    - [ ]  테스트 결과를 바탕으로 최적의 모델 선택 및 통합\n\n### **2. 텍스트 음성 변환 (TTS) 구현**\n\n- [ ]  **TTS 모델 개발 및 통합**\n    - [ ]  Google TTS, Amazon Polly 등의 TTS 엔진 조사 및 선택\n    - [ ]  TTS 엔진을 사용해 팟캐스트 스크립트"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Podly/2024-09-01-Podly_플로우.md",
    "title": "Podly 사용자 플로우 및 시스템 흐름도",
    "description": "Podly 서비스의 사용자 플로우와 시스템 처리 흐름 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Podly 서비스의 전체 사용자 플로우와 시스템 처리 흐름을 정리한 문서이다. 앱 실행부터 로그인, 관심사 선택, 뉴스 수신, 음성 재생까지의 전체 프로세스와 각 단계별 시스템 동작을 시각화하여 설명한다.\n\n\n\n\n- 앱 실행\n    - 프론트: 초기 UI 렌더링\n- 소셜 로그인 버튼 클릭\n    - 프론트: 소셜 로그인 SDK 초기화, 로그인 요청\n- 소셜 제공자 인증\n    - 프론트: 소셜 제공자 페이지로 리다이렉트\n- 앱 복귀, 백엔드로 인증 코드 전송\n    - 프론트: 인증 코드 백엔드로 전송\n    - 백엔드: 인증 코드 수신, 소셜 제공자에 토큰 요청\n- 백엔드에서 token 발급\n    - 백엔드: access/refresh 토큰 생성\n    - 프론트: 토큰 수신\n- 프론트엔드에서 token 저장\n    - 프론트: HttpOnly 쿠키에 토큰 저장\n- 사용자 정보 조회 (/api/users/me)\n    - 프론트: GET 요청 전송\n    - 백엔드: 사용자 정보 조회 및 응답\n- 관심사 설정:\n    - 프론트: 관심사 목록 표시(/api/user_preference/, 선택 UI 제공\n    - 백엔드: 관심사 목록 제공, 선택 정보 저장\n- 메인 화면 진입:\n    - 프론트: 맞춤 콘텐츠 및 'Generate' 버튼 표시\n    - 백엔드: 맞춤 콘텐츠 데이터 제공\n- 'Generate' 버튼 클릭\n    - 프론트: 팟캐스트 생성 요청 전송\n- 백엔드 요청 시작:\n    - 백엔드: 사용자 관심사 조회, 뉴스 크롤링, 스크립트 생성, 채팅방 생성\n- 프론트엔드로 생성된 스크립트 전송\n    - 백엔드: 스크립트 전송\n    - 프론트: 스크립트 수신 및 표시\n- 팟캐스트 생성 시작\n    - 백엔드: 팟캐스트 생성 프로세스 시작\n- 생성 진행상황 실시간 업데이트\n    - 백엔드: 웹소켓으로 진행상황 전송\n    - 프론트: 진행상황 실시간 표시\n- 팟캐스트 생성 완료 및 결과 전송\n    - 백엔드:"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Podly/2024-09-01-Podly_배포.md",
    "title": "Podly 배포 전략 및 인프라 설계",
    "description": "Podly 프로젝트의 배포 서비스 선택과 인프라 구성 전략",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Podly 프로젝트의 배포를 위한 클라우드 서비스 선택과 인프라 구성 전략을 다룬다. AWS, GCP, Azure 등 주요 클라우드 플랫폼 비교, Docker 컨테이너화, CI/CD 파이프라인 구성, 그리고 실제 배포 환경 설정 방법을 포함한다.\n\n\n\n## 배포 서비스\n\n1. AWS\n2. Google Cloud\n3. Microsoft Azure\n4. Naver Cloud\n5. Kamatera\n\n\n\n### 1. **클라우드 호스팅 비용의 기본 개념 및 요소**\n\n- **사용량 기반 과금 모델 (Pay-as-you-go)**: 사용자가 실제로 사용한 리소스에 대해서만 비용을 지불하는 모델로, 전통적인 서버 구축 방식에 비해 비용 효율적입니다.\n- **주요 비용 요소**:\n    - **컴퓨팅**: CPU, 메모리, 스토리지 사용량\n    - **스토리지**: 데이터 저장 공간과 스토리지 유형(SSD, HDD)\n    - **네트워킹**: 데이터 전송량과 네트워크 대역폭\n    - **데이터베이스**: 데이터베이스 크기와 사용량\n    - **기타 서비스**: 로드 밸런서, CDN, 백업, 보안 서비스 등\n\n### 2. **주요 클라우드 호스팅 서비스 비교**\n\n#### **Amazon Web Services (AWS)**\n\n- **장점**:\n    - **광범위한 서비스 제공**: 다양한 컴퓨팅, 스토리지, 네트워킹, 데이터베이스 서비스\n    - **높은 확장성**: 급증하는 트래픽에 신속히 대응 가능\n    - **강력한 에코시스템**: 파트너, 개발 도구, 커뮤니티 지원이 풍부\n    - **글로벌 네트워크**: 전 세계 데이터 센터를 통해 낮은 지연 시간 제공\n- **단점**:\n    - **복잡한 서비스 구조**: 많은 서비스들을 이해하고 관리하는 것이 어려울 수 있음\n    - **비용**: 다른 클라우드 서비스와 비교해 높은 편일 수 있음\n\n#### **Microsoft Azure**\n\n- **장점**:\n    - **M"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Podly/2024-08-16-Podly Github.md",
    "title": "Podly Git 서브모듈 활용 가이드",
    "description": "Podly 프로젝트에서 Git 서브모듈을 활용한 효과적인 컴포넌트 관리 방법",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Podly 프로젝트에서 다양한 컴포넌트를 효과적으로 관리하기 위해 Git 서브모듈을 활용하는 방법을 설명한다. 서브모듈의 사용 목적, 레포지토리 구성, 로컬 환경 설정, 그리고 팀 협업 시 서브모듈 관리 모범 사례를 포함한다.\n### Podly 프로젝트에서 Git 서브모듈 활용하기\n\nPodly 프로젝트에서는 다양한 컴포넌트를 효과적으로 관리하기 위해 Git 서브모듈을 활용하고 있음. 이 글에서는 서브모듈이 어떻게 사용되는지, 레포지토리가 어떻게 구성되어 있는지, 그리고 로컬 환경에서의 구조를 간략히 설명함\n\n#### 1. 서브모듈의 사용 목적\n\nPodly 프로젝트는 여러 독립적인 컴포넌트로 구성되어 있으며, 각 컴포넌트는 별도의 Git 레포지토리로 관리됨. 이를 하나의 메인 레포지토리에서 관리하기 위해 서브모듈을 도입했음. 서브모듈을 통해 각 컴포넌트를 독립적으로 개발, 버전 관리할 수 있으며, 메인 레포지토리에서 이들을 통합하여 관리할 수 있음\n\n#### 2. 레포지토리 구성\n\nPodly 메인 레포지토리는 다음과 같은 구조로 구성되어 있음\n\n\n```\npodly/ \n├── .gitmodules  # 서브모듈 정보가 담긴 파일 \n├── backend/     # 백엔드 서브모듈 디렉토리 \n├── frontend/    # 프론트엔드 서브모듈 디렉토리 \n└── README.md    # 프로젝트 설명 파일\n```\n\n\n- **.gitmodules**: 서브모듈의 경로와 원격 레포지토리 URL이 정의되어 있음\n- **backend/**: 백엔드 관련 코드가 포함된 서브모듈 디렉토리\n- **frontend/**: 프론트엔드 관련 코드가 포함된 서브모듈 디렉토리\n\n#### 3. 로컬 환경에서의 구조\n\n로컬에서 Podly 레포지토리를 클론할 때, 서브모듈도 함께 클론하여 사용함. 로컬 환경에서의 파일 구조는 다음과 같음\n\n\n```\npodly/ \n├── .git/            # Git 관련 디렉토리 \n├── backend/       "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Podly/2024-09-04-Podly_화면.md",
    "title": "Podly 서비스 화면 및 UI 소개",
    "description": "Podly 서비스의 주요 화면 구성과 사용자 인터페이스 소개",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Podly 서비스의 주요 화면을 시각적으로 소개하는 문서이다. 랜딩 페이지, 로그인 화면, 메인 화면, 뉴스 재생 화면 등 핵심 UI 구성 요소와 사용자 경험 설계를 스크린샷과 함께 설명한다.\n## Podly 링크\n\n[https://podly.fun](https://podly.fun)\n## 랜딩페이지 및 로그인\n![](https://i.imgur.com/h7LYcCu.png)\n\n## 챗봇\n![](https://i.imgur.com/bKDPWi3.png)\n\n## 관심 키워드 설정\n![](https://i.imgur.com/hedMwqL.png)\n\n![](https://i.imgur.com/M32oH8M.png)\n\n## 생성 시작\n![](https://i.imgur.com/FKBdkKe.png)\n\n## 생성 화면\n![](https://i.imgur.com/TUofiDC.png)\n\n![](https://i.imgur.com/S2IWfGQ.png)\n\n## TTS 생성 후 화면\n\n![](https://i.imgur.com/IHxe448.png)\n## 추가 질문\n![](https://i.imgur.com/hM9p047.png)\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Podly/2024-08-30-Podly_개발보고서.md",
    "title": "Podly 프로젝트 최종 개발 보고서",
    "description": "AI 기반 맞춤형 음성 뉴스 서비스 Podly 프로젝트 최종 개발 보고서",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> AI 기반 맞춤형 음성 뉴스 및 관심사 정보 제공 서비스 Podly의 최종 개발 보고서이다. 프로젝트 개요, 기술 스택, 시스템 아키텍처, 주요 기능 구현, 개발 과정에서의 문제 해결, 그리고 팀 협업 경험을 포함한 종합 문서이다.\n# Ⅰ 참가 개요\n\n- **참가자(팀)명**: Podly(포들리)\n- **참가작 주제**:\n    - **AI 기반 맞춤형 음성 뉴스 및 관심사 정보 제공 서비스**\n- **참가작 주요 내용 요약**:\n    - **문제 정의**:\n        - 최근 연구들에 따르면, 이동 중 터치스크린 사용의 불편함과 정보 과잉이 사용자 경험에 부정적인 영향을 미치고 있다는 점이 강조되고 있습니다. Jenny et al.의 연구에서는 이동 중 터치스크린 상호작용이 75%의 응답자에게 매우 불편하게 느껴지며, 특히 대중교통 이용 시 이러한 불편함이 더욱 두드러진다고 보고했습니다. 또한, Knight Foundation의 연구는 현대 사회에서 정보 과잉으로 인해 사용자들이 자신에게 맞는 정보를 신속하게 찾기 어려워하며, 특히 출퇴근 시간과 같은 이동 중에는 이 문제가 더욱 심각해진다는 점을 지적하고 있습니다. 이러한 요소들이 결합되어 사용자 경험에 부정적인 영향을 미치고 있는 것으로 나타났습니다.\n    - **프로젝트 목적**:\n        - Podly는 이러한 문제를 해결하기 위해 음성 명령을 통해 손쉽게 정보를 검색하고, AI 기반으로 개인화된 뉴스를 제공하는 서비스를 개발하였습니다. 사용자는 터치 없이도 음성만으로 원하는 정보를 얻을 수 있으며, 맞춤형 뉴스 큐레이션을 통해 이동 중에도 최적화된 정보를 편리하게 청취할 수 있습니다.\n    - **주요 기능 및 서비스**:\n        - **맞춤형 뉴스 큐레이션**: AI가 사용자의 관심사와 이전 검색 기록을 분석하여 맞춤형 뉴스를 제공합니다.\n        - **팟캐스트 형식의 자동 생성**: TTS 기술을 활용해 텍스트 기반 정보를 자연스러운 음성"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Podly/2024-08-31-Podly_Authentication 과정.md",
    "title": "Podly 인증 시스템 구현",
    "description": "Podly 서비스의 소셜 로그인 및 JWT 기반 인증 시스템 구현 과정",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Podly 서비스의 인증 시스템 구현 과정을 정리한 문서이다. 소셜 로그인(OAuth) 초기 인증부터 JWT 토큰 발급, Access Token/Refresh Token 관리, 자동 로그인, 로그아웃 처리까지 전체 인증 프로세스를 단계별로 설명한다.\n\n\n## 1. 소셜 로그인 (초기 인증)\n\n- **프로세스**: 소셜 로그인 버튼 클릭 → 소셜 제공자 인증 → 백엔드로 인증 코드 전송\n- **응답**: \n  ```json\n  {\n    \"access_token\": \"...\",\n    \"refresh_token\": \"...\",\n    \"token_type\": \"bearer\"\n  }\n  ```\n\n## 2. 사용자 정보 조회\n\n- **엔드포인트**: `GET /api/users/me`\n- **헤더**: `Authorization: Bearer {access_token}`\n- **응답**: 사용자 기본 정보 (ID, 이메일, 이름 등)\n\n## 3. 인증된 요청\n\n- 모든 인증 필요 요청에 access token 포함\n- **헤더**: `Authorization: Bearer {access_token}`\n\n## 4. token 갱신\n\n- **엔드포인트**: `POST /api/auth/refresh`\n- **헤더**: `Authorization: Bearer {refresh_token}`\n- **응답**: 새로운 access token과 refresh token\n\n## 5. 로그아웃\n\n- **엔드포인트**: `POST /api/auth/logout`\n- **헤더**: `Authorization: Bearer {access_token}`\n- **프로세스**: 백엔드 token 무효화 → 프론트엔드 token 삭제\n\n## 주요 보안 사항\n\n- HTTPS 사용 필수\n- 클라이언트: token 안전 저장 (HttpOnly 쿠키 권장)\n- 서버: 모든 요청 시 token 검증\n\n## token 수명\n\n- access token: config에서 설"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Men-in-Black/2023-12-19-ZoeDepth.md",
    "title": "ZoeDepth - Zero-shot Depth Estimation 논문 정리",
    "description": "ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth 논문 정리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> ZoeDepth 논문을 정리한 문서이다. Relative Depth와 Metric Depth를 결합하여 Zero-shot Transfer를 달성하는 Depth Estimation 모델의 원리, 아키텍처, 성능 평가, 그리고 Men in Black 프로젝트에서의 활용 가능성을 분석한다.\n\n# ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth\n\n- paper: [https://arxiv.org/pdf/2302.12288.pdf](https://arxiv.org/pdf/2302.12288.pdf)\n- github: [https://github.com/isl-org/ZoeDepth](https://github.com/isl-org/ZoeDepth)\n\n## 요약\n- **결합된 접근 방식:** 상대적 깊이와 메트릭 깊이 추정을 통합하여 일반화 성능과 정확한 메트릭 스케일을 모두 달성하고자 함\n- **다중 데이터셋 사전 훈련 및 미세 조정:** 12개 데이터셋에서 상대적 깊이로 사전 훈련되고, 특정 데이터셋에서 메트릭 깊이로 미세 조정되어 각 도메인에 최적화된 성능을 제공\n- **경량화된 헤드와 자동 경로 설정:** 각 도메인에 맞춤화된 경량화된 헤드와 메트릭 빈 모듈을 사용하며, 입력 이미지를 적절한 헤드로 자동으로 경로 설정하는 잠재 분류기 포함\n- **혁신적인 모델 아키텍처:** 각 도메인별로 특화된 새로운 '메트릭 빈 모듈'을 통해 더 정밀하고 효율적인 깊이 추정을 가능하게 하는 독특한 아키텍처를 채택\n- **향상된 성능 및 일반화:** NYU Depth v2 및 기타 데이터셋에서 상대 절대 오류를 크게 감소시키고, 실내 및 실외 도메인의 여러 데이터셋에 대한 제로샷 일반화 성능을 제공\n\n## 목표\n\n- 상대적 및 측정적 깊이 추정 방법을 통합하여 보다 정밀하고 신뢰할 수 있는 깊이 정보를 제공\n- 다양한 환경에서의 깊이 추정의 정확도를 개선\n- 특히 도시 환경과 "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Men-in-Black/2023-12-05-MiDas v3.md",
    "title": "MiDaS v3 - Depth Estimation 논문 정리",
    "description": "MiDaS v3 Depth Estimation 모델 논문 정리 - Men in Black 프로젝트 적용",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Men in Black 프로젝트에서 블랙박스 차량과 다양한 물체 간의 거리를 구하기 위해 MiDaS v3 Depth Estimation 모델을 연구한 논문 정리이다. Monocular Depth Estimation의 원리, MiDaS의 아키텍처, 그리고 실제 프로젝트 적용 방법을 다룬다.\n\n## Intro: \n\nMen in Black(도로 교통 법규 위반 차량 자동 탐지 & 구분) 프로젝트 중 다양한 물체와 블랙박스 차량간의 거리를 구하기 위해 방법을 찾던 중 MiDas를 참고하고자 정리해보았다.\n\n- paper: https://arxiv.org/abs/2307.14460\n- github: https://github.com/isl-org/MiDaS\n\n\n- youtube using MiDas: https://www.youtube.com/watch?v=MNzdybzH0kM&t=330s\n- youtube: https://www.youtube.com/watch?v=c_WbKfyt8pY\n\t- https://github.com/nicknochnack/CodeTHat-MiDaS\n## MiDaS v3.1 – A Model Zoo for Robust Monocular Relative Depth Estimation\n\n날짜: 2023년 7월 26일\n\n#### Abstract\n - 새로운 encoder backbone을 가진 모델을을 제시\n - 바닐라 ViT와 거의 유사했던 MiDas v3.0과는 달리 BEiT, Wsin, Wsin V2, Next-ViT, LeViT등의 모델이 추가되었다\n - 그 결과 최고 28% 성능 향상\n\n#### Introduction\n- Monocular depth estimation 해결로 generative AI, 3D reconstruction, autonomous driving등의 downstream tasks에 영향 끼침\n- 데이터셋 혼합과 규모 및 이동 불변성 손실 구축이 MiDas의 일반화를 가능케 했다(MiDas"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Men-in-Black/2023-10-29-차량 블랙박스 영상속 도로 교통 법규 위반 차량 감지.md",
    "title": "Men in Black - 차량 블랙박스 영상 기반 교통 법규 위반 감지",
    "description": "블랙박스 영상에서 도로 교통 법규 위반 차량을 자동으로 감지하는 AI 시스템 개발 프로젝트",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 운전 중 도로 교통 법규 위반 차량을 발견해도 즉각 신고가 어려운 현실적 문제를 해결하기 위한 자동 감지 및 신고 시스템 개발 프로젝트이다. 프로젝트 목표, 기술 스택, 시스템 아키텍처, 그리고 구현 과정을 포함한 초기 기획 문서이다.\n\n<!--⚠️Imgur upload failed, check dev console-->\n**운전중 도로 교통 법규 위반 차량을 발견해도 즉각 신고가 현실적으로 어려워 자동 감지 및 신고 시스템을 만들고자 함**\n\n### 프로젝트 목표:\n\n- 실시간 블랙박스 영상속 위반 차량 감지+신고\n- 블랙박스 영상 속에서 실시간으로 특정 위반 사항을 감지하고, 필요한 경우 이를 신고할 수 있는 시스템을 개발\n\n### 주요 구현 요소:\n\n- 위반 사항 분류 (Classification of Violations): 신호위반, 안전모 미착용, 중앙선 침범, 차선 변경 위반과 같은 특정 위반 사항을 식별하고 분류\n- Object Tracking (객체 추적): 감지된 객체를 연속적으로 추적하여, 해당 객체의 움직임을 모니터링\n- Object Detection (객체 감지): 블랙박스 영상에서 차량 및 사람과 같은 객체를 감지    \n\n### 시각화용 데이터:\n1. 서울시 법규위반별 교통사고 현황 통계:\n\t- [https://data.seoul.go.kr/dataList/10865/S/2/datasetView.do](https://data.seoul.go.kr/dataList/10865/S/2/datasetView.do)\n2. 법규위반별 교통사고 현황:\n\t- [https://stat.eseoul.go.kr/statHtml/statHtml.do?orgId=201&tblId=DT_201004_L050013&conn_path=I2&obj_var_id=&up_itm_id=](https://stat.eseoul.go.kr/statHtml/statHtml.do?orgId=201&tblId=DT_201004_L050013&conn_"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Men-in-Black/2023-11-19-Men in Black readme file.md",
    "title": "Men in Black - 도로 교통 법규 위반 차량 자동 감지 시스템",
    "description": "블랙박스 영상에서 교통 법규 위반 차량을 자동으로 감지하고 신고하는 AI 시스템 프로젝트",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> 운전 중 발견한 도로 교통 법규 위반 차량을 즉각 신고하기 어려운 문제를 해결하기 위한 자동 감지 및 신고 시스템 프로젝트이다. YOLOv8을 활용한 차량 및 번호판 감지, EasyOCR을 통한 번호판 인식, ZoeDepth/MiDaS를 활용한 거리 추정 등 종합적인 Computer Vision 기술을 적용하여 교통 법규 위반을 자동으로 탐지한다.\n# Men-in-Black\n\n## 1. 개요\n- 도로 교통 법규 위반 차량 감지\n- 도로 위의 일상적인 교통 법규 위반, 특히 주요 도로에서의 끼어들기 같은 행위는 많은 운전자들에게 불편함과 안전 위험을 초래합니다. 하지만 위반 행위를 목격하여도, 주행 중 신고가 어려워 신고를 미루다 결국 하지 않게 되는 경우가 많습니다.\n- 따라서 본 프로젝트에서 영상을 통해 교통 법규 위반을 자동으로 탐지하고 분류하는 모델을 개발하고자 했습니다.\n- 이 모델을 다양한 법규 위반 상황을 식별하고 자동 신고 기능을 포함하여, 안전하고 공장한 도로 환경 조성에 기여하고자 합니다.\n\n## 2. 프로젝트 구성 및 담당자\n\n### [Line Violation Detection](https://github.com/SeSAC-Men-in-Black/Men-in-Black/tree/074ad63391bab45290966de5b0f9d747f9a252ae/Line%20violation%20detection) by [진한별](https://github.com/Moonbyeol)\n<details>\n<summary>Details</summary>\n\n## 진행 과정:\n\n1. 차량 인식\n2. 차선 인식\n3. 위반 탐지지\n\n## 모델 구성 및 분류:\n\n### 1. 차량 인식 모델\n   \n    a. 모델 구성\n   \n       ⅰ. Detection Model : Mask R-CNN\n   \n       ⅱ. BackBone Network : ResNet101\n   \n       ⅲ. BackBone Pre-trained : "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/LangChain Open Tutorial/2025-02-24-project-retrospective.md",
    "title": "LangChain Open Tutorial Project Retrospective (English)",
    "description": "LangChain Open Tutorial open-source project 7-week contribution retrospective (English version)",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> A retrospective of my 7-week contribution to TeddyNote's LangChain open-source tutorial project. This English version covers my experience translating tutorials, creating new content, implementing code in a highly active project with over 2,000 commits, and the valuable lessons learned about open-source collaboration.\n## Background\n\nI recently came across the news that **TeddyNote**, a YouTuber I follow, was recruiting contributors for the **LangChain open-source tutorial** on **Retrieval-Augmented Generation (RAG)**—a topic I was particularly interested in. This was an exciting opportunity, not just as a fan, but as a chance to **actively contribute to a topic I’m passionate about**. Since it was my first time participating in a large-scale open-source project and collaborating with various contributors, I was even more eager to take part.\n\nThe tutorial contribution process lasted about **seven weeks**, during which the project saw **over 2,000 commits**, reflecting i"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/LangChain Open Tutorial/2024-12-30-workflow.md",
    "title": "LangChain Open Tutorial - 기여 워크플로우",
    "description": "LangChain Open Tutorial 프로젝트 기여를 위한 Git 워크플로우 및 환경 설정 가이드",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> LangChain Open Tutorial 오픈소스 프로젝트에 기여하기 위한 Git 워크플로우와 개발 환경 설정 가이드이다. Fork, 커밋, Pull Request 작성 방법, 환경 및 패키지 설정, 그리고 협업을 위한 모범 사례를 포함한다.\n## 기본 커밋 방식\n1. [LangChain-OpenTutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial) fork\n2. \n\n## Environment & Package\n- Python 3.11 사용\n\n### Poetry Env 사용\n\n- 기본적인 package는 사전 구성\n- 추가 패키지는 프로젝트 진행하면서 추가\n- 중앙 관리팀 존재(충돌 방지)\n\t- Package 추가 희망 시 중앙 팀에게 요청\n\n## Workflow\n1. [LangChain-OpenTutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)Fork\n2. 각자 개인 Fork에서 작업\n3. Main(original) repository에 PR(pull request)\n4. PEER 리뷰(2명)\n5. Merge\n\n\n![](https://i.imgur.com/iBaH2cy.png)\n\n\n## Commit Message\n\n```markdown\n[Team] {소속팀}\n[Title] {작업 제목 요약}\n[Version] {initial / revision / bugfix / other}\n[Language] {KO / ENG}\n[Packages] {사용한 주요 패키지 목록}\n\n{상세 설명}\n```\n\n- packages(참고용): 정확하게 안적어도 됨. 콤마 구분자로 작성\n- 상세 설명: 생략 가능, 간단하게 한줄\n\n## Template\n\n### Title\n```markdown\n# Title\n- Author: [Teddy](https://github.com/teddylee777)"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/LangChain Open Tutorial/2025-02-12-cot-web-search.md",
    "title": "LangChain Open Tutorial - CoT 기반 스마트 웹 검색",
    "description": "Chain-of-Thought를 활용한 스마트 웹 검색 시스템 튜토리얼",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> LangChain Open Tutorial에서 작성한 Chain-of-Thought 기반 스마트 웹 검색 시스템 튜토리얼이다. CoT 추론을 활용하여 사용자 질의를 분석하고, 효과적인 검색 전략을 수립하며, 정확한 답변을 생성하는 전체 프로세스를 상세한 코드와 함께 설명한다.\n# CoT Based Smart Web Search\n\n  \n\n- Author: [syshin0116](https://github.com/syshin0116)\n\n- Design:\n\n- Peer Review:\n\n- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n\n  \n\n[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/19-Cookbook/07-Agent/15-CoT-basedSmartWebSearch.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/19-Cookbook/07-Agent/15-CoT-basedSmartWebSearch.ipynb)\n\n  \n\n## Overview\n\nThis tutorial demonstrates a chain-of-thought (**CoT**) based smart web search approach designed"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/LangChain Open Tutorial/2025-01-18-web-search.md",
    "title": "LangChain Open Tutorial - Web Search 연구",
    "description": "LangChain 기반 Web Search 시스템 연구 - Language Agent Tree Search, Plan-and-Execute",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> LangChain Open Tutorial에서 Web Search 시스템을 개발하기 위한 연구 자료 정리이다. Language Agent Tree Search, WebLangChain, Plan-and-Execute Agents 등 주요 논문과 기술을 분석하여 효과적인 웹 검색 에이전트 구현 방법을 탐구한다.\n## Research\n\n- [Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models](https://arxiv.org/abs/2310.04406)\n- [Building (and Breaking) WebLangChain](https://blog.langchain.dev/weblangchain/)\n- [Plan-and-Execute Agents](https://blog.langchain.dev/planning-agents/)\n\n### Paper\n- [An LLM Compiler for Parallel Function Calling](https://arxiv.org/abs/2312.04511)\n\n### Notebooks\n- [Reasoning without Observation](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/rewoo/rewoo.ipynb)\n- [LLMCompiler](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/llm-compiler/LLMCompiler.ipynb)\n- [Plan-and-Execute](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/plan-and-execute/plan-and-execute.ipynb)\n\n\n\n# Plan-and-Execute Agents\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/LangChain Open Tutorial/2025-01-05-peer-review.md",
    "title": "LangChain Open Tutorial - Week 2 Peer Review",
    "description": "LangChain Open Tutorial Week 2 GraphRAG 및 Academic Search System 피어 리뷰",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> LangChain Open Tutorial 프로젝트 Week 2에서 진행한 GraphRAG와 Academic Search System에 대한 피어 리뷰 내용이다. 코드 개선 제안, 구조 최적화, 문서화 피드백 등 동료 기여자들의 작업에 대한 건설적인 리뷰를 포함한다.\n\n\n## 04-GraphRAG / 07-AcademicSearchSystem\n\n생각나는대로 냅다 다 적겠습니다ㅎㅎ가벼운 마음으로 고려해주시면 감사하겠습니다!\n\n#### 1. Overview\n\n1. 설명해야할 내용이 너무 많은 주제라 고민이 많으셨을것 같아요. 핵심만 잘 정리중이신 느낌이라 좋지만 `Knowledge Graph`와 같이 중요하지만 한마디로 설명하기엔 너무 복잡한 내용은 잘 설명된 곳으로 링크 보내면 좀 더 친절한 글이 될 것 같습니다\n    \n2. GraphRAG의 장점을 잘 설명해주셨는데, 구축 난이도와 같은 단점은? 이라는 생각이 일부러 안넣으신건가? 라는 생각과 함께 들었습니다.\n    \n\n#### 2. Environment Setup:\n\n사소하지만, `!pip install` 임시방편 부분들 공통부분에 넣으면 되는걸로 알고있습니다ㅎ\n\n```python\n# Install required packages\nfrom langchain_opentutorial import package\n\npackage.install(\n    [\n        \"langchain-neo4j\",\n        \"pyalex\"\n    ],\n    verbose=False,\n    upgrade=False,\n)\n```\n\n#### 3. 데이터\n\n1. 노드에 대한 설명은 잘 해주셨으나, 엣지는 어떻게 구성되어있는지 한번에 볼 수 있는 그림이 있으면 좋을것 같다는 생각이 들었습니다.\n    \n2. json 파일 내용도 어떻게 구성되어있는지 살짝 보여주시면 좋을것 같습니다.\n    \n\n#### 4. 실행 코드\n\n마지막에서 두번째 셀\n\n```python\nchain = GraphCypher"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/LangChain Open Tutorial/2025-01-12-llamaparse.md",
    "title": "LangChain Open Tutorial - LlamaParse 튜토리얼",
    "description": "LlamaParse를 활용한 문서 파싱 튜토리얼 - PDF 및 다양한 문서 형식 처리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> LangChain Open Tutorial 프로젝트에서 작성한 LlamaParse 튜토리얼이다. PDF를 포함한 다양한 문서 형식을 효과적으로 파싱하는 방법, LlamaParse API 사용법, 실전 예제 코드, 그리고 피어 리뷰를 통해 개선된 완성본을 포함한다.\n# LlamaParse\n\n- Author: [syshin0116](https://github.com/syshin0116)\n- Design: \n- Peer Review: [JoonHo Kim](https://github.com/jhboyo), [Jaemin Hong](https://github.com/geminii01), [leebeanbin](https://github.com/leebeanbin), [Taylor(Jihyun Kim)](https://github.com/Taylor0819), [Dooil Kwak](https://github.com/back2zion)\n- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n\n[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/06-DocumentLoader/13-LlamaParse.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/b"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/LangChain Open Tutorial/2025-01-05-brainstorm.md",
    "title": "LangChain Open Tutorial - Week 2 브레인스토밍",
    "description": "LangChain Open Tutorial Week 2 신규 튜토리얼 개발을 위한 브레인스토밍 세션",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> LangChain Open Tutorial Week 2에서 진행한 신규 튜토리얼 개발을 위한 브레인스토밍 세션 기록이다. 팀 구성원들과 함께 튜토리얼 주제 선정, 제출 항목 정리, 아이디어 논의 과정을 통해 프로젝트 방향성을 수립한 내용을 포함한다.\n\n## 신규 튜토리얼 개발자 1팀\n\n### 제출 항목:\n\n- 기능명: 기능의 제목 또는 이름 \n- 기능 설명: 목적과 핵심 내용 2~3줄 요약 \n- 필요 데이터: 기능 구현에 필요한 데이터 형식이나 예시. (모든 활용 데이터는 영어로 작성되어야 합니다.)\n\n\n## BrainStorm\n\n### GraphRAG\n- Neo4j 활용 그래프 레그\n\n#### Datasets\n- Harry Potter \n- Movies\n- 맛집\n\n\n- [LangChain: Neo4j](https://python.langchain.com/docs/integrations/graphs/neo4j_cypher/)\n- [Neo4j: Turn a Harry Potter Book into a Knowledge Graph](https://neo4j.com/developer-blog/turn-a-harry-potter-book-into-a-knowledge-graph/)\n- [Neo4j: Example Datasets](https://neo4j.com/docs/getting-started/appendix/example-data/)\n\n\n제가 알기로 LangGraph 챕터가 이미 있어서, 새로 제안하는 아이디어가 어디에 들어가야 할지 애매한 부분이 있다고 생각합니다.\n\n제가 생각하는 아이디어는 short-term과 long-term 메모리 기능인데, 이 기능을 LangGraph로 구현하다 보니 자연스럽게 LangGraph 챕터 아래로 포함시키는 게 맞는지 고민됩니다.\n\n이런 주제여도 괜찮은지, 아니면 따로 새로운 섹션으로 구성하는 것이 더 적절할지 검토 부탁드립니다.\n\n---\n기능명: Short-term, Long-term Mem"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/LangChain Open Tutorial/2025-02-24-retrospective.md",
    "title": "LangChain Open Tutorial 프로젝트 회고록",
    "description": "LangChain Open Tutorial 오픈소스 프로젝트 7주간의 기여 경험 회고록",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> TeddyNote의 LangChain 오픈소스 튜토리얼 프로젝트에 7주간 기여한 경험을 정리한 회고록이다. 2,000+ 커밋의 활발한 프로젝트에서 튜토리얼 번역, 새로운 콘텐츠 작성, 코드 구현을 담당하며 얻은 배움과 성장, 그리고 오픈소스 협업의 가치를 공유한다.\n\n## 배경\n\n유튜버 **TeddyNote님**이 최근 가장 관심 있어하는 **RAG(Retrieval-Augmented Generation)** 관련 **LangChain 오픈소스 튜토리얼** 기여자를 모집한다는 소식을 접했다. 단순히 팬으로서가 아니라, **관심 있는 주제에 직접 기여할 수 있는 기회**라는 점에서 매력적이었다. 특히, 규모 있는 오픈소스 프로젝트에 참여하고, 다양한 사람들과 협업하는 경험이 처음이라 더욱 기대되었다.\n\n튜토리얼 기여 과정은 약 7주 동안 진행되었으며, 전체 프로젝트에서 **2000개 이상의 커밋**이 쌓일 정도로 활발하게 진행되었다. 첫 주에는 모든 기여자가 공통적으로 기존 튜토리얼을 검토하고 번역하는 작업을 수행했다. 이후부터는 최대한 **신규 튜토리얼 제작에 집중적으로 참여**하며, 직접 내용을 구성하고 구현하는 작업을 맡았다.\n\nGitbook: [🦜️🔗 The LangChain Open Tutorial for Everyone](https://langchain-opentutorial.gitbook.io/langchain-opentutorial)\nGithub: [LangChain-OpenTutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n\n\n## 기여 튜토리얼\n\n### LlamaParse 튜토리얼\n- **GitBook:** [LlamaParse Gitbook](https://langchain-opentutorial.gitbook.io/langchain-opentutorial/06-documentloader/12-llamaparse)\n- **GitH"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/LangChain Open Tutorial/2025-02-01-conversation-memory.md",
    "title": "LangChain Open Tutorial - 대화 메모리 관리 시스템",
    "description": "LangChain을 활용한 대화 메모리 관리 시스템 튜토리얼",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> LangChain Open Tutorial에서 작성한 대화 메모리 관리 시스템 튜토리얼이다. 챗봇이 이전 대화 내용을 기억하고 맥락을 유지하면서 자연스러운 대화를 이어가기 위한 다양한 메모리 관리 기법, 구현 코드, 그리고 실전 활용 방법을 포함한다.\n\n# ConversationMemoryManagementSystem\n\n- Author: [syshin0116](https://github.com/syshin0116)\n\n- Design:\n\n- Peer Review:\n\n- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n\n  \n\n[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/19-Cookbook/05-AIMemoryManagementSystem/09-ConversationMemoryManagementSystem.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/19-Cookbook/05-AIMemoryManagementSystem/09-ConversationMemoryManagementSystem.ipynb)\n\n  \n\n## Overview\n\n  \n\nIn modern AI systems, **memory management"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Modular-RAG/2024-11-25-Modular RAG - RDBMS vs NoSQL.md",
    "title": "Modular RAG - RDBMS vs NoSQL 선택",
    "description": "Modular RAG 프로젝트를 위한 RDBMS와 NoSQL 비교 및 최적 데이터베이스 선택",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Modular RAG 프로젝트에 적합한 데이터베이스를 선택하기 위해 RDBMS와 NoSQL의 특성을 비교 분석한 내용이다. 유연성과 확장성을 중요시하는 Modular RAG의 특성을 고려하여 각 데이터베이스의 장단점, 적합한 사용 사례, 성능 특성을 평가하고 최종 선택을 제시한다.\n### **RDBMS와 NoSQL의 차이점 및 Modular RAG에 적합한 선택**\n\nModular RAG는 다양한 모듈을 조합하며 유연성과 확장성을 중요하게 여기는 프로젝트다. 이를 구현하기 위한 데이터베이스 선택에서 RDBMS와 NoSQL의 특성을 비교하고, Modular RAG에 더 적합한 데이터베이스를 선택하고자 한다.\n\n---\n\n### **RDBMS vs NoSQL: 비교 테이블**\n\n| **특징**         | **RDBMS**                           | **NoSQL**                           |\n| -------------- | ----------------------------------- | ----------------------------------- |\n| **데이터 구조**     | 정형 데이터를 스키마 기반으로 저장                 | 스키마 없이 비정형 데이터를 유연하게 저장             |\n| **확장성**        | 수직적 확장(서버 성능 업그레이드) 중심              | 수평적 확장(샤딩과 클러스터링 지원)에 적합            |\n| **데이터 일관성**    | ACID 트랜잭션을 통해 강력한 데이터 무결성 보장        | eventual consistency로 일부 데이터 불일치 허용 |\n| **처리 속도**      | 읽기와 쓰기 성능이 균형 잡혀 있으나 대규모 데이터 처리에 한계 | 빠른 쓰기 성능, 대규모 데이터 처리에 최적화           |\n| **관계형 데이터 관리** | 복잡한 관계형 데이터 처"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Modular-RAG/2024-10-20-Modular RAG 구조.md",
    "title": "Modular RAG 아키텍처 설계",
    "description": "LEGO 블록처럼 조합 가능한 Modular RAG 시스템 설계 - 재사용 가능한 RAG 모듈 구축",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Naive RAG와 Advanced RAG를 넘어 Modular RAG 방식으로 진화한 설계 내용이다. LEGO 블록처럼 모듈을 조합하여 재사용 가능한 RAG 자산을 구축하는 것이 목표이며, 시스템의 유연성과 확장성을 크게 향상시켜 다양한 애플리케이션 요구사항에 맞게 모듈을 조합하고 최적화할 수 있는 아키텍처를 제시한다.\nNaive RAG에 여러 RAG를 하기 위해 Advanced RAG를 충분히 다뤘다고 생각한다. 하지만, 점점 더 복잡한 작업을 최소화하고 효율성을 높이기 위해 Modular RAG 방식을 적용하고자 한다. 마치 LEGO 블록처럼 모듈들을 쌓아가며 나만의 재사용 가능한 RAG 자산을 구축하는 것이 목표다. Modular RAG는 시스템의 유연성과 확장성을 크게 향상시킬 수 있어, 이를 통해 다양한 애플리케이션 요구 사항에 맞게 모듈을 조합하고 최적화하는 방향으로 발전시키고자 한다\n\nModular RAG 논문: [https://arxiv.org/html/2407.21059v1](https://arxiv.org/html/2407.21059v1)\n\n![](https://i.imgur.com/Vh7vEHw.png)\n\n![](https://i.imgur.com/kqjz87X.png)\n\n![](https://i.imgur.com/HUHBVIJ.png)\n\n\n### 기술 스택\n\n이 프로젝트에서는 다양한 기술을 활용하여 **모듈화된 RAG 시스템**을 구축함. 주요 기술 스택은 다음과 같음:\n\n- **FastAPI**: API 서버 프레임워크로 사용. 비동기 처리를 지원하며, 고성능 API를 쉽게 구축할 수 있음\n- **Docker**: 각 서비스를 독립된 컨테이너로 관리하고, 배포 환경을 쉽게 설정할 수 있도록 사용. 나중에 DB와 Redis 같은 서비스도 Docker Compose를 통해 관리 예정\n- **Poetry**: 의존성 관리 및 패키지 관리를 위해 사용. Python 패키지 관리의 안정성과 유연성을 제공\n- **L"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Modular-RAG/2024-11-17-Modular RAG - Chat History.md",
    "title": "Modular RAG - Chat History 설계",
    "description": "효율적인 채팅 기록 저장과 확장 가능한 구조 설계 - Chat Session과 Messages 분리",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Modular RAG 챗봇의 효율적인 채팅 기록 저장 방식을 설계한 내용이다. Chat Session과 Chat Messages를 분리하여 저장하는 구조, 일반 챗봇과 카카오톡 봇 모두에 적합한 설계, 확장 가능한 데이터베이스 스키마, 그리고 실시간 채팅과 히스토리 조회를 모두 지원하는 아키텍처를 포함한다.\n\n## 효율적인 Chat History 저장과 확장 가능한 구조 설계\n\n챗봇을 설계하다, 기본적인 채팅 기록 저장 방식에 대해 고민하게 되었다. 일반적으로 채팅 기록을 저장하는 방법은 **Chat Session**과 **Chat Messages**로 나눌 수 있다. 기본적인 저장 방식에 추가로 고려한 기능, 이를 구현하기 위한 구조, 그리고 일반적인 챗봇과 카카오톡 봇 모두에 적합한 설계를 정리해 보았다.\n\n\n### 기본적인 Chat History 저장 방법\n#### 1. Chat Session\n- 채팅 세션 단위로 저장\n- 각 세션은 시작 시간, 참여자, 그리고 채팅방에 대한 내용을 포함\n- ex) 사용자와 봇 간의 대화는 하나의 세션으로 기록\n\n#### 2. Chat Messages\n- 각 메시지를 독립적으로 저장\n- 메시지는 대화의 흐름을 기록하며, 발신자(사용자 또는 봇), 내용, 타임스탬프 등의 정보를 기록\n- 세션 ID를 외래 키로 사용해, 각 메시지가 어떤 세션에 속해 있는지 명확히 연결\n\n### 추가 기능\n\n기본적인 저장 방식 외에도, 효율적이고 확장 가능한 구조를 위해 다음과 같은 기능을 추가하고 싶었다.\n\n#### 1. 메타데이터 관리\n\n- 각 세션에 메타데이터를 추가하여 요약, 중요 정보, 일정, 준비물 등을 저장할 수 있도록 설계\n\t- ex) 대화 중 중요한 일정이 언급되면 이를 자동으로 추출해 메타데이터에 추가\n\n#### 2. 요약 기능\n\n- 메시지가 많아질 경우, 이전 메시지를 요약해 세션에 저장하여 대화 기록을 간결하게 관리\n- 요약은 세션의 메타데이터로 저장되며, 필요할 때 이를 참조\n\n#### 3"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Modular-RAG/2024-12-22-Modular RAG - Short Term, Long Term Memory.md",
    "title": "Modular RAG - Short Term & Long Term Memory 구현",
    "description": "챗봇의 단기 기억과 장기 기억 구현 - 사람처럼 기억하는 AI 시스템 설계",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n> Modular RAG 챗봇이 사람처럼 기억할 수 있도록 Short Term Memory와 Long Term Memory를 구현한 설계 내용이다. 각 채팅방에서 최신 정보는 단기 기억으로, 중요한 정보는 장기 기억으로 저장하여 효율적인 메모리 관리와 자연스러운 대화 경험을 제공하는 방법을 다룬다.\n\n## Intro\nMemory 기능을 구현하는데 어떻게 하면 챗봇이 사람처럼 기억을 할 수 있을까, 어떻게 구현하면 가장 도움이 될까 고민했다. 고민 결과, 각 채팅방에 중요 정보는 Long Term memory로, 최신 정보는 Shot Term memory로 구현하고자 한다.\n\n## 정보\n### 기본 Memory의 유형\n\n#### 단기 기억 (Short-term memory)\n\n- 하나의 대화 스레드 내에서 기억을 유지\n- 대화 이력을 기반으로 에이전트의 상태를 관리\n- 대화가 길어지면 메모리의 효율성을 유지하기 위해 메시지 리스트를 관리하거나 요약\n\n#### 장기 기억 (Long-term memory)\n\n- 여러 대화 스레드에서 정보를 공유하며, 스레드 간 경계를 넘어 기억할 수 있다\n- 사용자, 조직, 또는 특정 문맥(namespace)을 기반으로 기억을 저장하며, JSON 문서 형태로 관리\n\n### 심리학적 Memory 유형\n#### Semantic Memory\n\n- Vectorstore에서 주로 사용하는 Semantic search와 헷갈려 하기 쉽지만 엄연히 다른 용어다.\n- Semactic Memory는 심리학에서 기반한 기억 저장 방법으로 사용자에 대한 사실 및 지식을 저장한다\n\n![](https://i.imgur.com/56d6RXa.png)\n\n\n\n## 구현 방법\n\n우선, 공부를 하면서 구현을 해야하는 상황이기 때문에, Short Term Memory를 Redis로 먼저 구현하고, 공부하면서 차차 발전해나갈 생각이다.\n\n\n\n\n## 출처\n- [https://langchain-ai.github.io/langgraph/conce"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/AppHub/2025-10-12-pgvector-활용-벡터베이스-구현.md",
    "title": "PostgreSQL 18 + pgvector를 활용한 블로그 벡터 검색 시스템 구축",
    "description": "Quartz 블로그를 PostgreSQL 18과 pgvector를 활용하여 벡터화하고, Dense + Sparse Hybrid Search를 구현하는 과정을 기록한다. Parent-Child Document 구조와 헤딩 기반 청킹, Multi-Query + Reranker를 통한 고도화된 검색 시스템 구축을 다룬다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> Quartz 기반 기술 블로그를 PostgreSQL 18과 pgvector를 활용하여 벡터화하고 지능형 검색 시스템을 구축하는 프로젝트다. [[한국자동차공학회 논문 특화 파서 시스템 분석|이전 Qdrant 기반 구현]]을 개선하여 Dense(벡터) + Sparse(BM25) Hybrid Search를 SQL 네이티브로 구현하고, Parent-Child Document 구조로 문서 계층을 유지하며, 헤딩 기반 의미적 청킹으로 검색 품질을 극대화한다. PostgreSQL 단일 데이터베이스로 벡터, 메타데이터, 관계형 데이터를 통합 관리하여 복잡한 쿼리와 트랜잭션을 지원한다.\n\n## 프로젝트 배경\n\n### 벡터 스토어 선택 과정\n\n개인적으로 경험해보고 싶었던 로컬에서 구축 가능한 벡터 스토어는 크게 세 가지가 있다:\n\n1. **Qdrant**: 고성능 벡터 검색에 특화, 현재 진행 중인 다른 두 프로젝트에서 이미 사용 중\n2. **Milvus**: 대규모 엔터프라이즈급 벡터 DB, 수백만~수십억 개의 벡터를 다루는 대규모 시스템에 적합\n3. **pgvector**: PostgreSQL 익스텐션, 관계형 DB의 장점과 벡터 검색을 결합\n\n이번 블로그 프로젝트에서는 **pgvector**를 선택했다. Qdrant는 다른 프로젝트에서 이미 사용 중이어서 새로운 기술 스택을 경험하고 싶었고, Milvus는 개인 블로그 규모(수백 개 문서)에는 과도한 스펙이다. 마침 PostgreSQL을 이번 AppHub 프로젝트의 메인 데이터베이스로 사용하기로 했기 때문에, 벡터 검색까지 통합할 수 있는 pgvector가 가장 적합했다.\n\n### PostgreSQL 18 + pgvector의 장점\n\n**통합 데이터 관리:**\n- 벡터, 메타데이터, 관계형 데이터를 단일 DB에서 관리\n- 별도 벡터 DB 불필요, 운영 복잡도 감소\n- ACID 트랜잭션으로 데이터 일관성 보장\n\n**진정한 Hybrid Search:**\n- Dense Search (벡터 코사인"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/AppHub/2025-10-14-Qdrant-Neo4j-하이브리드-검색-아키텍처.md",
    "title": "Qdrant + Neo4j: 하이브리드 검색 아키텍처로의 전환",
    "description": "pgvector에서 Qdrant + Neo4j 조합으로 전환한 이유와 각 검색 방식(키워드, 임베딩, 그래프)의 상호 보완 전략을 다룬다. 벡터 검색, 그래프 탐색, 키워드 매칭을 통합하여 더 강력한 지식 검색 시스템을 구축한다.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary]\n>\n> [[2025-10-12-pgvector-활용-벡터베이스-구현|이전 pgvector 기반 설계]]에서 **Qdrant + Neo4j** 조합으로 전환했다. pgvector의 장점(PostgreSQL 통합, 트랜잭션 일관성)보다 **전문 벡터 DB의 성능**, **그래프 검색의 관계 탐색 능력**, 그리고 **각 검색 방식의 독립적 확장성**이 더 중요하다고 판단했기 때문이다. 키워드 검색, 임베딩 검색, 그래프 검색은 각각 다른 강점이 있으며, 이들을 결합한 하이브리드 아키텍처가 가장 강력한 검색 경험을 제공한다.\n\n## 전환 배경\n\n### pgvector의 한계\n\n[[2025-10-12-pgvector-활용-벡터베이스-구현|이전 문서]]에서 pgvector를 선택한 이유는 다음과 같았다:\n\n1. **PostgreSQL 통합**: 벡터 + 관계형 데이터를 단일 DB에서 관리\n2. **높은 동시접속 처리**: 트래픽이 많을 때 유리\n3. **트랜잭션 일관성**: ACID 보장\n4. **운영 복잡도 감소**: 별도 벡터 DB 불필요\n\n그러나 실제 프로젝트 요구사항을 더 깊이 분석한 결과, **다음과 같은 문제점**을 발견했다:\n\n#### 1. 벡터 검색 성능이 Qdrant보다 떨어진다\n\n**pgvector의 한계:**\n- HNSW 인덱스가 있지만 전문 벡터 DB 대비 성능 차이\n- 벡터 연산 최적화가 Qdrant보다 부족\n- 필터링 + 벡터 검색 결합 시 성능 저하\n\n**벤치마크 비교 (대략적):**\n\n| 항목 | pgvector | Qdrant | 차이 |\n|------|----------|--------|------|\n| 검색 속도 (10K 벡터) | ~50ms | ~5ms | **10배** |\n| 필터링 + 검색 | ~150ms | ~15ms | **10배** |\n| 인덱싱 시간 | 느림 | 빠름 | **2-3배** |\n| 메모리 효율 | 보통 | 우수 | - |\n\n#### 2. 그래프 검색이 불가능하다\n\n**필요한 쿼리들:*"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/AppHub/2025-10-07-AppHub-구조-및-기술-스택.md",
    "title": "AppHub 구조 및 기술 스택",
    "description": "AppHub 프로젝트의 구체적인 기술 스택 선택 과정과 시스템 아키텍처 설계. NextJS 15, React 19, LangGraph Python, 최신 개발 도구들(Biome, Bun, Drizzle ORM, better-auth)을 활용한 기술적 구현 방안과 각 선택의 근거",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary] **AppHub 기술 스택 결정 과정**\n> \"최신 기술을 경험해보고 싶고, 세세하게 컨트롤할 수 있는 개발\"이라는 핵심 동기에서 출발한 기술 선택 스토리다. 2025년 10월 기준 최신 도구들과 프레임워크를 반영하여, 각 기술의 **선택 근거와 고민 과정**을 상세히 기록하고, 실제 구현에 필요한 아키텍처와 도구들을 정리한다. 프로젝트 기획과 비즈니스 로직은 [[2025-10-06-AppHub-개인-프로젝트-플랫폼-기획]]에서 다룬다.\n\n## 시스템 아키텍처 개요\n\n> [!abstract] **구현 중심 접근**\n> 비즈니스 요구사항과 사용자 경험은 [[2025-10-06-AppHub-개인-프로젝트-플랫폼-기획]]에서 정의했으므로, 여기서는 **구체적인 기술 구현**에 집중한다.\n\n### 주요 컴포넌트 구성\n\n![](https://i.imgur.com/sg4zOY1.png)\n\n![](https://i.imgur.com/4FR7m5g.png)\n\n| 레이어 | 컴포넌트 | 기술 스택 | 역할 |\n|--------|----------|-----------|------|\n| Frontend | Web Application | NextJS 15 + React 19 + TypeScript 5.x | 사용자 인터페이스 |\n| Frontend | UI Framework | ShadCN + Tailwind CSS | 기본 컴포넌트 및 스타일링 |\n| Frontend | AI UI Components | prompt-kit | AI 챗봇 인터페이스 (PromptInput, Message, CodeBlock 등) |\n| Frontend | State Management | Zustand / Jotai (검토 중) + TanStack Query | 전역 상태 및 서버 상태 |\n| Backend | AI Service | LangGraph Python + FastAPI | AI 로직 및 에이전트 |\n| Backend | Web API | NextJS AP"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/AppHub/2025-10-06-AppHub-개인-프로젝트-플랫폼-기획.md",
    "title": "AppHub 개인 프로젝트 플랫폼 기획",
    "description": "개인 프로젝트들을 통합 관리하고 효과적으로 서빙할 수 있는 Living Portfolio 플랫폼의 핵심 아이디어와 비즈니스 로직, 사용자 경험 설계 및 프로젝트 목표 정의 (2025년 10월 업데이트)",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary] **AppHub Living Portfolio 기획**\n> 기존 정적 포트폴리오를 넘어 **실제 동작하는 프로젝트들을 통합 관리**하는 Living Portfolio 플랫폼이다. 사용자가 직접 체험할 수 있는 프로젝트들을 한 곳에서 관리하고, 공통 인프라를 재사용하여 개발 효율성을 극대화한다. 최신 기술 스택과 개발 트렌드를 반영하여 2025년 10월 기준으로 재검토하였다. 기술적 구현은 [[2025-10-07-AppHub-구조-및-기술-스택]]에서 상세히 다룬다.\n\n## 프로젝트 개요\n\n**공통 인프라 플랫폼 구축** - 모든 개인 프로젝트에서 재사용할 수 있는 통합 기반 시스템\n\n### 핵심 아이디어\n개별 프로젝트마다 반복적으로 구현하는 공통 기능들(인증, 데이터베이스, RAG, 챗봇 등)을 하나의 플랫폼으로 통합하여, 이후 모든 프로젝트가 이 기반 위에서 개발될 수 있도록 하는 **공용 인프라 시스템**\n\n## 일반 포트폴리오 사이트 vs AppHub 플랫폼\n\n### 포트폴리오 사이트 비교 분석\n\n| 구분 | 기존 포트폴리오 사이트 | AppHub Living Portfolio |\n|------|-------------------|----------------------|\n| **콘텐츠 형태** | 정적 소개 페이지, 스크린샷 | 실제 동작하는 애플리케이션 |\n| **사용자 상호작용** | 읽기 전용, 링크 클릭 | 직접 체험, 실시간 테스트 |\n| **프로젝트 접근** | 깃허브 링크, 외부 사이트 | 통합 플랫폼 내 원클릭 접근 |\n| **기술 증명 방식** | \"만들 수 있어요\" | \"만들어서 운영하고 있어요\" |\n| **면접관 경험** | 설명 듣기, 스크린샷 보기 | 직접 사용해보기, 실시간 피드백 |\n| **유지보수** | 업데이트 필요 없음 | 지속적 운영 및 개선 |\n| **기술적 깊이** | 코드 스니펫, 문서 | 실제 서비스 운영 경험 |\n| **차별화 요소** | 디자인, 글쓰기 | 기능성, 사용자 경험 |\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/AppHub/2025-10-08-AppHub-프로젝트-구조-설계.md",
    "title": "AppHub 프로젝트 구조 설계 - 처음부터 다시 시작",
    "description": "몇 달 만에 다시 시작하는 AppHub 프로젝트. 기획을 업데이트하고 프로젝트를 처음부터 깔끔하게 재구성하는 과정 기록. Bun + Turborepo 기반 Monorepo 구조와 Docker 컨테이너 설계.",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary] **AppHub 프로젝트 구조 재설계**\n> 몇 달 전 시작했다가 멈췄던 AppHub 프로젝트를 처음부터 다시 시작한다. docs만 남기고 전체 초기화 후, **5개의 Docker 컨테이너**(Traefik, PostgreSQL+pgvector, Redis, ai-service, web)와 **Bun 기반 Monorepo** 구조로 재구성. Python은 uv, TypeScript는 Bun을 사용하며, LangGraph 기반 블로그 검색 기능을 ai-service에 통합하는 방식으로 설계했다.\n\n## 프로젝트 구조 한눈에 보기\n\n### Docker 컨테이너 (총 3개)\n```yaml\nservices:\n  postgres      # PostgreSQL 18 + pgvector (포트 5432)\n  redis         # 캐시 & 세션 (포트 6379)\n  ai-service    # Python LangGraph + LangChain (포트 2024)\n  # web은 로컬 개발 서버로 실행 (포트 3000)\n```\n\n### 디렉토리 구조\n```\napphub/\n├── apps/\n│   ├── web/                    # Next.js 15 Monorepo (내부에 apps/, packages/)\n│   │   ├── apps/               # Next.js 앱들\n│   │   └── packages/           # 공유 패키지 (ui, config 등)\n│   └── ai-service/             # Python LangGraph + LangChain\n│       ├── src/                # Python 소스 코드\n│       ├── pyproject.toml      # Python 의존성 (uv)\n│       └── Dockerfile          # AI 서비스 컨테이너 설정\n├── compose.yaml                # Docker "
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/AppHub/2025-10-06-AppHub-Quartz-통합-전략.md",
    "title": "AppHub와 Quartz 블로그 통합 전략",
    "description": "Obsidian Quartz 블로그를 AppHub 플랫폼에 통합하는 전략. Obsidian의 강력한 기능들을 유지하면서 Next.js 기반 통합 플랫폼의 일부로 만드는 방법과 RAG 시스템 구축 계획",
    "summary": "",
    "has_summary_callout": true,
    "body_preview": "\n\n> [!summary] **Quartz 블로그 + AppHub 통합**\n> 기존 Quartz로 운영 중인 Obsidian 블로그를 AppHub의 첫 번째 프로젝트로 통합한다. Obsidian의 핵심 기능들(위키링크, 백링크, 그래프 뷰)을 유지하면서, AppHub의 통합 UI/UX와 RAG 챗봇을 결합하여 **살아있는 지식 베이스**를 구축한다.\n\n## 프로젝트 배경\n\n### 현재 상황\n\n**Quartz 블로그 (syshin0116.github.io)**\n- Obsidian vault를 웹으로 퍼블리싱\n- 위키링크 `[[]]`, 백링크, 그래프 뷰 등 Obsidian 기능 완벽 지원\n- SPA 라우팅, Popover 미리보기, 전체 텍스트 검색\n- GitHub Pages로 배포\n\n**AppHub의 첫 번째 프로젝트: 블로그 RAG 시스템**\n- 내 블로그 포스트들을 RAG로 검색 가능하게\n- LangGraph + pgvector 기반 AI 챗봇\n- \"이 개발자가 어떤 기술을 다뤘나요?\" 같은 질문에 답변\n\n### 핵심 과제\n\n> [!question] **어떻게 통합할 것인가?**\n> Quartz의 강력한 Obsidian 기능들을 포기하지 않으면서, AppHub의 통합된 경험을 제공할 수 있을까?\n\n## Quartz를 선택한 이유 (유지해야 할 가치)\n\n### 1. Obsidian 기능의 완벽한 웹 구현\n\n| 기능 | Obsidian | Quartz | 일반 블로그 |\n|------|----------|--------|------------|\n| 위키링크 `[[]]` | ✅ | ✅ | ❌ |\n| 양방향 백링크 | ✅ | ✅ | ❌ |\n| 그래프 뷰 | ✅ | ✅ (D3.js) | ❌ |\n| 태그 시스템 | ✅ | ✅ | 제한적 |\n| Callout/Admonition | ✅ | ✅ | ❌ |\n| Popover 미리보기 | ❌ | ✅ | ❌ |\n\n### 2. 개발자 친화적 워크플로우\n\n```\nObsidian에서 작성 → Git Push → 자동 배포\n```\n\n"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Hostit/Hostit 구조.md",
    "title": "Hostit 구조",
    "description": "Hostit 프로젝트의 파일 구조와 아키텍처 설계에 대한 상세 가이드",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n### Hostit 구조\nsrc/\n├── lib/\n│   ├── core/                        👈 핵심 기능\n│   │   ├── store.ts                 👈 단일 스토어\n│   │   ├── config.ts                👈 전역 설정 정의\n│   │   └── types/                   👈 공통 타입 정의\n│   │       ├── index.ts             👈 공통 타입 내보내기\n│   │       ├── chat.ts              👈 채팅 관련 타입\n│   │       └── api.ts               👈 API 관련 타입\n│   │\n│   ├── mcp/                         👈 MCP 기능\n│   │   ├── client.ts                👈 MCP 클라이언트\n│   │   ├── registry.ts              👈 도구 등록 관리\n│   │   ├── connector.ts             👈 도구 연결 관리 \n│   │   ├── status.ts                👈 연결 상태 관리 (신규)\n│   │   ├── types.ts                 👈 MCP 관련 타입\n│   │   └── adapters/                👈 다양한 도구 어댑터 (신규)\n│   │       ├── stdio.ts             👈 stdio 어댑터\n│   │       └── sse.ts               👈 SSE 어댑터\n│   │\n│   ├── ai/                          👈 AI 관련\n│   │   ├── models/                  👈 모델 관리\n│   │   │   ├── index.ts             👈 모델 공통 인터페이스\n│   │   │   ├── anthropic.ts         👈"
  },
  {
    "path": "/home/user/syshin0116.github.io/content/Projects/Hostit/Hostit README.md",
    "title": "Hostit README",
    "description": "MCP 도구를 쉽게 호스팅하고 사용할 수 있는 플랫폼 Hostit의 설치 및 사용 가이드",
    "summary": "",
    "has_summary_callout": false,
    "body_preview": "\n\n# Host it!\n\n<p align=\"center\">\n  <img src=\"./src/app/assets/hostit.png\" alt=\"Host it! Logo\" width=\"150\" />\n</p>\n\n## English\n\nHost it! is a platform that allows you to easily host and use MCP (Model Context Protocol) tools. Even non-developers can interact with AI through a chat interface and utilize various tools without any technical knowledge.\n\n### Key Features\n\n- **Easy MCP Tool Hosting**: Host and manage various MCP tools with ease.\n- **Intuitive Chat Interface**: Interact with AI and utilize tools through conversation without development knowledge.\n- **Tool Management System**: Easily check and manage available tools.\n- **API Key Settings**: Manage API keys through a simple settings screen.\n\n### Getting Started\n\n#### Prerequisites\n\n- Node.js 18.0.0 or higher\n- npm or yarn\n\n#### Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/jioni-jioni/web.git\ncd web\n\n# Install dependencies\nnpm install\n# or\nyarn install\n\n# Run the development server\nnpm run dev\n# or\nya"
  }
]