---
layout: post
title: 데이스쿨 랭커 특강 정리
date: 2024-01-22 19:12 +0900
categories:
  - ETC
  - 온라인 강의
tags: 
math: true
---
### 대회 주제 파악

대회 목적에 맞는 모델을 찾기 위한 체크 리스트
1. 대회의 목적
2. 대회 목적에 맞는 tast는 무엇인가?
	- 모르는 task라면 review 논문을 읽으며 이해
3. 해당 task의 SOTA모델은 무엇인가?
4. 해당 SOTA 모델의 코드가 존재하는가?
	- 없으면 다른 모델은 코드가 있는지 확인
	- 있으면 코드에서 모델을 가져와서 적용할 수 있는지 확인
	- 해당 모델이 Huggingface에 존재하는지 확인

> paperswith code에서 SOTA모델을 인용한 논문을 찾으면 더 좋은 성능의 초신 모델 논문을 더러 발견할 수 있다

### 데이터셋 분석
데이터 분석을 통한 모델 적용 가능성 확인 및 특징 확인 체크리스트
1. 대회에서 제공한 데이터셋은 어떠한 format으로 구성되어 있는가?
	- 찾은 모델을 그래도 사용 간으한지 혹은 output layer에 변경이 필요한지 확인 
2. 데이터들의 분포가 어떻게 되어 있는가?
	- Target data의 분포를 확인하여 다양한 클래스 불균형 해소 방법 적용 가능
3. EDA를 통해 어떠한 특징을 도출해냏 수 있는가?
	- EDA를 통해 결측치 등 확인하여 데이터 전처리

> 주로 tuning하는 부분은 output layer

### 다양한 학습 기법 적용

성능 고도화를 위한 전략
1. \[대회주제 파악]을 통해 주사한 모델 적용
2. 성능을 올리기 위한 다양한 augmentation, feature engineering방법 조사 및 적용
3. 모델의 일반화 성능 고도화를 위해, 다양한 방법 조사 및 적용
	- 데이터셋을 train/valid setdmfh 분할할 때, KFold / StratifiedKfold등 적용
	- 기본적으로 CrossentropyLoss를 사용하지만, 클래스 불균형 해소를 위한 다양한 Loss 적용
	- SGD, Adam, AdamW등 다양한 Optimization에서 파라미터를 변경하며 최적화

> AdamW가 클래스 불균형을 가진 데이터를 적용했을 때 성능이 더 좋았음


### 프레임워크 또는 task 변경

- 프레임워크 또는 task를 변경하여 더 높은 성능을 달성할 수 있는 경우가 있음

### 요약 및 팁
- Python 프로그래밍 능력 필요함 
	- 프로그래머스 레벨 2~3레벨 정도 
- 다양한 코딩 tool 활용하면 빠르게 코딩 가능
	- Github Copliot, ChatGPT 등
- kaaggle에 키워드로 검색하여 다양한 코드를 확인할 수 있음
- 끝난 대회에서 수상자들의 코드를 확인하며 공부하는 것이 중요 
- 모델의 일반화 성능을 높인다면, Public과 Private 리더보드 간의 변동이 크게 차이나지 않음
- **사용하는 모든 방법들에 '왜 이런 방법을 사용했는가?'에 대한 답을 할 수 있어야함**

#### 추가
- python joblic 라이브러리를 사용하여 cpu 병렬 프로그래밍 하는 방법이 있다
- 대용량 데이터일 때를 제외하고는 AutoML 사용이 도움됐다


- 불균형이 심할때 ASLLoss 
- SAM optimizer: public score와 private score의 차이가 심할 경우 사용
	- loss를 계산할때 주변 평균 loss를 계산함으로써 local minima에 빠질 위험을 줄여준다
- ASAM: SAM optimizer을 더 발전시킨 모델
	- 단점: 두 스텝으로 진행되기 떄문에 학습 시간이 오래걸림