---
title: LLM 개발 및 학습 강의 정리
date: 2024-02-24
tags:
  - llm
  - nlp
  - deep-learning
  - pretrain
  - fine-tuning
  - transfer-learning
  - llm-training
draft: false
enableToc: true
description: "LLM(대규모 언어 모델)의 사전 학습, 파인튜닝, 도메인 적응 전략 강의 정리"
published: 2024-02-24
modified: 2024-02-24
---

> [!summary]
> LLM 개발 및 학습 전략에 대한 강의 내용을 정리한 노트이다. 사전 학습(Pretrain)과 파인튜닝(Fine-tuning)의 차이, 추가 사전 학습이 필요한 경우(도메인 특화, 새로운 언어), 효율적인 파인튜닝 기법(LoRA, QLoRA), Transfer Learning 전략, 그리고 실무에서 LLM을 적용할 때의 고려사항을 다룬다.

![](https://i.imgur.com/OwheGkg.png)


![](https://i.imgur.com/cpXoCYf.png)


![](https://i.imgur.com/5QCtzpx.png)

![](https://i.imgur.com/2LARpuo.png)

![](https://i.imgur.com/o3tpqgX.png)


## Pretrian을 더 시켜야 하는 경우

![](https://i.imgur.com/QSUEIFh.png)

![](https://i.imgur.com/0EkqSvi.png)

+ 한국어 추가 학습


![](https://i.imgur.com/n7Cz5UG.png)

![](https://i.imgur.com/jaWHNiN.png)

![](https://i.imgur.com/oEuWV4a.png)


### RLHF (Reinforcement Learning with Human Feedback)
![](https://i.imgur.com/Bvx5WOO.png)

리워드 모델을 통해 평가
- ex) 이 답변이 다른 답변보다 좋은 답변일 확률이 0.2

#### 두가지 문제접
- Reward Model 학습이 어려움
- 강화학습을 이용했을대 생기는 불안정성


### DPO(Direct Preference Optimization)
![](https://i.imgur.com/9CDIYGK.png)

#### RLHF에서 보완된 방식
- Reward Model을 없앰
- 강화학습 불안전성 완화

### 프롬프트 엔지니어링

![](https://i.imgur.com/21OR2oL.png)


![](https://i.imgur.com/0DICcUT.png)

![](https://i.imgur.com/Bex59KB.png)

