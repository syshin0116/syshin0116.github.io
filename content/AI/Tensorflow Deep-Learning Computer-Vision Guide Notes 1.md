---
title: "Tensorflow Deep-Learning Computer-Vision Guide Notes 1"
date: 2022-07-25
tags: deep-learning, computer-vision, tensorflow, object-detection, segmentation
draft: false
enableToc: true
description: 딥러닝 기반 컴퓨터 비전의 객체 탐지(Object Detection)와 세그멘테이션(Segmentation)에 대한 기본 개념과 발전 과정을 정리한 글이다.
published: 2022-07-25
modified: 2022-07-25
---

> [!summary]
> 
> 컴퓨터 비전에서 핵심 기술인 객체 탐지(Object Detection)와 세그멘테이션(Segmentation)의 기본 개념과 주요 구성 요소를 정리했다. 딥러닝 기반 방법론의 발전 과정과 One-stage/Two-stage detector의 특징, 그리고 이 분야가 직면한 주요 난제를 다룬다.

## 서론

딥러닝 기반 컴퓨터 비전은 2012년 AlexNet이 PASCAL VOC 대회에서 CNN 기반으로 우승한 이후 급속도로 발전해왔다. 특히 객체 탐지(Object Detection)와 세그멘테이션(Segmentation) 분야는 실생활 응용 가능성이 높아 많은 연구가 이루어지고 있다.

이 문서에서는 다음 내용을 다룬다:
1. Object Detection, Segmentation의 이론적 이해
2. 주요 구현 패키지와 실습 방법

---

## 구현 및 실습 도구

### 구현 패키지
1. **MMDetection**: 다양한 객체 탐지 알고리즘을 제공하는 오픈소스 프레임워크
2. **Ultralytics YOLO V3**: 실시간 객체 탐지에 최적화된 YOLO 구현체
3. **AutoML EfficientDet**: 구글의 EfficientDet 구현체로 효율적인 객체 탐지 모델

### 범용 인터페이스 API
1. **OpenCV**: 컴퓨터 비전을 위한 오픈소스 라이브러리
2. **TensorFlow Hub**: 사전 훈련된 모델을 쉽게 활용할 수 있는 TensorFlow 확장

> [!Note]
> 실습은 Colab이나 Kaggle Kernel과 같은 클라우드 기반 환경에서 진행하면 편리하다.

---

## Object Detection과 Segmentation의 이해

컴퓨터 비전 작업은 복잡도에 따라 다음과 같이 분류할 수 있다:
**Classification → Localization → Detection → Segmentation**

각 단계별 특징:

### 1. 이미지 분류(Classification)
- 이미지에 무엇이 있는지 분류하는 기본 작업

### 2. 위치 추정(Localization)
- 하나의 이미지에 하나의 객체가 있을 때 그 위치를 bounding box로 표시
- [[Tensorflow Deep-Learning Computer-Vision Guide Notes 2|더 복잡한 모델]]과 비교할 때 상대적으로 간단한 작업

### 3. 객체 탐지(Detection)
- 여러 객체를 동시에 찾고 각각에 bounding box를 표시
- 각 객체의 클래스도 예측

### 4. 세그멘테이션(Segmentation)
- Bounding box가 아닌 픽셀 단위로 정밀하게 객체를 구분
- 가장 상세한 수준의 객체 인식 작업

![객체 탐지 발전 과정](https://i.imgur.com/DsZlEPl.png)

---

## 딥러닝 기반 객체 탐지 방법론

객체 탐지 방법론은 크게 두 가지로 나눌 수 있다:

### One-stage detector
- **YOLO(You Only Look Once)**: 2015년 등장한 혁신적인 실시간 객체 탐지 모델
- **SSD(Single Shot Detector)**: 다양한 스케일의 객체를 효과적으로 탐지
- **Retina-Net**: Focal Loss를 도입하여 클래스 불균형 문제 해결
- **EfficientDet**: 효율적인 리소스 사용으로 높은 정확도 달성

**특징**: 속도가 빠르고 실시간 적용에 유리하다.

### Two-stage detector
- **R-CNN 계열**: R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN 등
- 먼저 객체의 대략적인 위치(Region Proposal)를 찾고, 그 다음 분류를 수행

**특징**: 정확도가 높지만 속도가 상대적으로 느려 실시간 비디오 처리에 제약이 있다.

---

## 객체 탐지의 주요 구성 요소

### 1. Region Proposal
- 객체가 있을 법한 영역을 추정하는 과정
- Selective Search, RPN(Region Proposal Network) 등의 방법 사용

### 2. 특징 추출(Feature Extraction)과 네트워크 구성
- **Backbone**: ResNet, VGG 등 기본 특징 추출기
- **Neck**: FPN(Feature Pyramid Network) 등을 통한 다양한 스케일 처리
- **Head**: 분류(Classification)와 경계 상자 회귀(Bbox Regression) 담당

### 3. 평가 및 보조 기술
- **IOU(Intersection Over Union)**: 예측과 실제 박스의 겹치는 정도 측정
- **NMS(Non-Maximum Suppression)**: 중복 박스 제거
- **mAP(mean Average Precision)**: 객체 탐지 성능 평가 지표
- **Anchor box**: 다양한 크기와 비율의 사전 정의된 박스로 예측 시작점 제공

![일반적인 객체 탐지 모델 구조](https://i.imgur.com/JHWTlFI.png)

---

## 객체 탐지의 난제

### 복합적 문제 해결
- Classification(분류)와 Regression(위치 추정)을 동시에 수행해야 함
- 이는 모델 설계와 학습 과정을 복잡하게 만듦

### 다양한 객체 처리
- 크기가 다양하고 형태가 다른 객체들을 동시에 다뤄야 함
- 작은 객체와 큰 객체 모두 효과적으로 탐지해야 함

### 실시간 처리 요구
- 자율주행, 로봇 비전 등에서는 빠른 처리 속도가 필수적
- 정확도와 속도 사이의 균형이 중요

### 데이터 품질 문제
- 객체가 명확하지 않거나 전체 이미지에서 차지하는 비중이 작은 경우가 많음
- 배경이 복잡하거나 조명 조건이 다양한 상황에서도 작동해야 함

### 데이터셋 부족
- 훈련에 필요한 충분한 레이블링된 데이터 확보가 어려움
- MS COCO(80개 클래스), Google Open Image(500개 클래스) 등이 있지만
- 새로운 도메인에 맞는 데이터셋 구축은 많은 노력이 필요

## 결론

객체 탐지와 세그멘테이션은 컴퓨터 비전의 핵심 기술로, 2012년 이후 딥러닝의 발전과 함께 급속도로 발전해왔다. 현재는 One-stage detector와 Two-stage detector의 장점을 결합하거나 새로운 접근 방식을 탐색하는 연구가 활발히 진행되고 있다.

다음 글 [[Tensowflow Deep-Learning Computer-Vision Guide Notes 2|Part 2]]에서는 더 심화된 모델 아키텍처와 실제 구현 방법에 대해 다룰 예정이다. 또한 [[Anomaly Detection|이상 탐지]]와 객체 탐지를 결합한 응용 사례도 살펴볼 것이다.