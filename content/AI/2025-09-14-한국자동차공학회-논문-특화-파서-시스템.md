---
title: "한국자동차공학회 논문 특화 파서 시스템 분석"
date: 2025-09-14
tags:
  - AI
  - PDF-Parser
  - RAG
  - Document-Processing
  - Multi-Modal
  - Vector-Database
  - Qdrant
  - OpenAI
  - UPSTAGE
  - GPT-4o
  - Academic-Papers
  - NLP
  - Data-Pipeline
  - Information-Retrieval
  - Semantic-Search
draft: false
enableToc: true
description: "한국자동차공학회 논문을 위한 전문 문서 파싱 및 RAG 시스템 구축 프로젝트 분석. UPSTAGE Document AI와 LLM을 활용한 고품질 멀티모달 콘텐츠 추출, 벡터 데이터베이스 구축, 그리고 Multi-Query + Reranker 기반 하이브리드 검색 시스템 구현까지 포괄적으로 다룬다."
published: 2025-09-14
modified: 2025-09-14
---

> [!summary]
> 
> 한국자동차공학회(KSAE) 논문 1,261개를 대상으로 한 전문 문서 파싱 및 RAG 시스템 구축 프로젝트다. UPSTAGE Document AI와 LLM을 결합한 이중 파싱 파이프라인을 통해 멀티모달 콘텐츠(텍스트, 이미지, 테이블)를 정확하게 추출하고, LangChain MarkdownHeaderTextSplitter로 의미적 청킹을 수행한다. 15,818개 벡터 포인트를 Qdrant에 저장하여 Parent-Child Document 구조를 구현했으며, Multi-Query + Reranker 기반 하이브리드 검색으로 검색 정확도를 극대화했다. 학술 논문 처리에 최적화된 완전 자동화 파이프라인으로 RAG 시스템 즉시 활용이 가능하다.

## 프로젝트 개요

학술 연구를 위한 전문적인 문서 처리 시스템을 구축하면서 한국자동차공학회(KSAE) 논문을 대상으로 한 특화 파서를 개발했다. 2019년부터 2024년까지의 학술지 논문 1,261개를 체계적으로 수집, 파싱, 구조화하여 고품질 RAG 시스템의 기반을 마련했다.

[[MinerU - PDF Parser|MinerU]]나 [[문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용|기존 PDF 파서들]]과 차별화되는 점은 학술 논문에 특화된 전처리 파이프라인과 완전 자동화된 메타데이터 추출, 그리고 Multi-Query + Reranker 기반 하이브리드 검색 시스템이다.

> [!info] 프로젝트 핵심 가치
> 단순한 PDF 텍스트 추출을 넘어서, 학술 논문의 구조적 특성을 완벽히 이해하고 효과적인 연구 정보 검색을 위한 **지능형 문서 검색 시스템**을 구축하는 것이 목표다.



## 시스템 구성 요소

### 1. **PDF 파서 클라이언트** (`parser-api-client/`)

학술 논문 PDF를 구조화된 마크다운으로 변환하는 핵심 엔진이다. UPSTAGE Document AI의 강력한 레이아웃 분석 능력과 LLM의 텍스트 정제 기능을 결합하여 최고 품질의 파싱 결과를 달성한다.

**핵심 기능:**
- **이중 파싱 전략**: UPSTAGE 기본 추출 + LLM 후처리로 정확도 극대화
- **멀티모달 콘텐츠 추출**: 텍스트, 이미지(차트/그림/테이블), 테이블 데이터 분류 저장
- **구조화된 데이터 조직**: 논문 섹션별 계층적 구조 유지
- **메타데이터 자동 생성**: AI 기반 제목, 저자, 키워드, 요약 추출

### 2. **DOI 추출 및 크롤링 도구** (`parse_paper_with_doi/`)

웹 크롤링을 통한 보완 데이터 수집 시스템으로, 파싱 실패나 품질 저하 시 대안적 데이터 소스를 제공한다.

**핵심 기능:**
- **DOI 기반 메타데이터 추출**: 논문 식별자를 통한 정확한 정보 수집
- **OCR 백업 처리**: 스캔 PDF나 이미지 기반 문서 처리
- **멀티프로세싱 대량 처리**: 수천 개 논문 동시 처리 지원
- **BeautifulSoup 웹 크롤링**: 학회 웹사이트에서 직접 메타데이터 수집


## 기술 아키텍처: 6단계 처리 파이프라인

![](https://i.imgur.com/I4kei9F.png)


### Phase 1: UPSTAGE 기반 초기 파싱

```
PDF 입력 → UPSTAGE Document AI → 배치 처리 (50페이지 단위) → 멀티모달 추출
```

UPSTAGE Document AI를 활용한 1차 파싱으로 PDF의 기본 구조와 콘텐츠를 추출한다. 50페이지 단위 배치 처리를 통해 대용량 논문도 안정적으로 처리한다.

**출력 형식:**
- `job_id_filename.md`: 구조화된 마크다운
- `job_id_filename.html`: HTML 형식 (테이블 구조 보존)
- `job_id_filename.pkl`: 메타데이터 pickle
- `images/`: 분류된 이미지 (chart, figure, table)
- `tables/`: CSV 형식 테이블 데이터

### Phase 2: LLM 기반 후처리

```
원본 파싱 결과 → 텍스트 정제 → 메타데이터 추출 → 구조 개선 → 최종 형태
```

UPSTAGE 결과를 LLM으로 정제하여 파싱 정확도를 극대화한다. 15,000자 단위로 분할하여 처리하며, 학술 논문에 특화된 프롬프트를 사용한다.

**처리 과정:**
- **텍스트 복원**: 깨진 텍스트나 인코딩 오류 수정
- **메타데이터 추출**: JSON 형식으로 구조화된 논문 정보 생성
- **논문 요약 생성**: AI가 전체 논문을 읽고 핵심 내용 요약
- **구조 개선**: 헤딩 레벨 조정, 목차 구조 최적화

### Phase 3: 문서 청킹 및 구조화

**LangChain MarkdownHeaderTextSplitter 활용:**

학술 논문의 구조적 특성을 고려한 의미적 분할을 수행한다. 단순한 길이 기반 분할이 아닌 논문의 섹션 구조를 이해하여 청킹한다.

- **헤딩 기준 의미적 분할**: H1, H2, H3 레벨 인식으로 섹션별 분할
- **Abstract 특별 처리**: 첫 번째 청크로 고정하여 논문 개요 우선 제공
- **메타데이터 연결**: 각 청크에 섹션 및 서브섹션 정보 자동 연결
- **TOC 자동 생성**: 마크다운 헤더 구조 기반 목차 생성

### Phase 4: 임베딩 및 벡터화

**OpenAI 임베딩 모델 활용:**

고품질 의미 검색을 위해 최신 임베딩 모델을 사용하여 텍스트를 벡터로 변환한다.

- **모델**: text-embedding-3-large (3072차원, 다국어 성능 향상)
- **청킹된 섹션 벡터화**: 각 의미적 단위를 독립적으로 벡터화
- **메타데이터 임베딩**: 제목, 키워드 등 메타데이터도 임베딩에 포함
- **멀티모달 콘텐츠 임베딩**: 이미지 description과 테이블 설명도 함께 벡터화
- **통합 벡터 생성**: 텍스트 + 이미지 설명 + 테이블 설명을 결합한 종합적 임베딩
- **배치 처리**: API 효율성을 위한 배치 임베딩

### Phase 5: 벡터 데이터베이스 적재

**Qdrant 로컬 저장소 구축:**

대규모 벡터 검색을 위한 전문 벡터 데이터베이스에 모든 데이터를 체계적으로 저장한다.

- **컬렉션**: 'ksae' (한국자동차공학회 논문 전용)
- **벡터 포인트**: 총 15,818개 저장 (Child Document 벡터)
- **Parent-Child Document 구조**: 1,261개 Parent + 15,818개 Child 문서 계층 구조
- **관계 매핑**: 각 Child 벡터에 Parent ID 연결로 전체 문서 정보 접근 가능
- **메타데이터 동기화**: 벡터와 메타데이터 완벽 연동

### Phase 6: 메타데이터 저장소 구축

**RDB 기반 논문 메타데이터 관리:**

빠른 검색과 필터링을 위해 구조화된 메타데이터를 별도로 저장한다.

- **논문 정보**: 총 1,261개 논문 메타데이터 저장
- **상세 정보**: 제목, 저자, 키워드, 요약, DOI 등
- **JSON TOC**: 계층적 목차 구조 저장
- **인덱싱**: 빠른 검색을 위한 다중 인덱스 구성

**최종 출력 구조:**
```
PDF_Name/
├── PDF_Name.md              # 구조화된 마크다운
├── PDF_Name_metadata.json   # 메타데이터 (제목, 저자, 키워드 등)
├── images/                  # 분류된 이미지
│   ├── chart/              # 차트, 그래프
│   ├── figure/             # 그림, 다이어그램  
│   └── table/              # 테이블 이미지
└── tables/                 # 테이블 데이터
    ├── table1.csv          # 구조화된 테이블 데이터
    └── table2.csv
```



## 멀티모달 콘텐츠 처리

### 이미지 추출 및 분류

학술 논문의 시각적 요소를 체계적으로 분류하고 저장한다. [[문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용|멀티모달 RAG]]를 위한 기반 데이터를 구축한다.

- **자동 분류**: CHART(차트/그래프), FIGURE(그림/다이어그램), TABLE(테이블) 3가지 타입
- **명명 규칙**: `{JOB_ID}_{PDF_NAME}_{TYPE}_Page_{페이지}_Index_{인덱스}.png`
- **마크다운 연결**: 상대 경로를 통한 이미지 참조로 문서 완성도 향상
- **해상도 최적화**: 원본 품질 유지하면서 파일 크기 최적화
- **이미지 설명 생성**: 멀티모달 LLM를 활용하여 각 이미지의 상세한 description 자동 생성
- **멀티모달 임베딩**: 이미지 설명을 텍스트와 함께 벡터화하여 벡터스토어에 저장

### 테이블 이중 처리

학술 논문의 중요한 정보가 담긴 테이블을 두 가지 형태로 보존한다.

- **시각적 보존**: PNG 이미지로 테이블의 원본 레이아웃 저장
- **데이터 추출**: CSV 형식으로 구조화된 데이터 변환
- **Cross-reference**: 이미지와 데이터 간 매핑 관계 유지
- **복잡한 표 지원**: 병합 셀, 다중 헤더 등 복잡한 구조도 처리
- **테이블 설명 생성**: 멀티모달 LLM를 통해 테이블의 내용과 의미를 요약한 description 생성
- **데이터 통합 임베딩**: 테이블 설명과 CSV 데이터를 함께 벡터화하여 저장

### 멀티모달 검색 시스템 구현 준비

완전한 멀티모달 검색을 위한 인프라가 구축되어 있다.

**이미지 기반 검색 준비:**
- 모든 이미지에 대한 상세한 description이 생성되어 벡터스토어에 저장됨
- 검색 시 관련 이미지가 식별되면 원본 이미지를 LLM에 함께 전달
- 멀티모달 LLM나 Claude Vision 등 비전 모델을 통한 시각적 질의응답 지원

**테이블 기반 검색 준비:**
- 테이블 내용에 대한 설명과 구조화된 데이터 모두 검색 가능
- 관련 테이블 발견 시 원본 이미지와 CSV 데이터를 LLM에 동시 제공
- 수치 데이터 분석과 시각적 패턴 인식을 결합한 종합적 분석 가능

**통합 멀티모달 응답:**
```python
# 검색 결과 예시 구조
{
  "text_content": "연소 효율 분석 결과...",
  "related_images": [
    {
      "image_path": "images/chart/combustion_efficiency.png",
      "description": "다양한 연료 분사 시기에 따른 연소 효율 변화를 보여주는 막대 그래프",
      "type": "chart"
    }
  ],
  "related_tables": [
    {
      "table_image": "images/table/efficiency_data.png", 
      "table_data": "tables/efficiency_data.csv",
      "description": "연료 분사 시기별 연소 효율 수치 데이터 (RPM, 분사압력, 효율 등)"
    }
  ]
}
```

> [!success] 멀티모달 검색 구현 완료
> 텍스트, 이미지, 테이블이 통합된 검색 시스템으로 사용자 질문에 대해 관련 시각 자료와 함께 종합적인 답변 제공이 가능하다.


## 메타데이터 구조

### 자동 추출 메타데이터

LLM을 활용한 지능형 메타데이터 추출로 논문의 핵심 정보를 구조화한다.

```json
{
  "title_ko": "직접분사식 암모니아 엔진에서 연료 분사 시기 변경에 따른 연소 특성",
  "title_en": "Combustion Characteristics with Fuel Injection Timing in Direct Injection Ammonia Engine",
  "authors_ko": ["김철수", "박영희", "이민수"],
  "authors_en": ["Kim, Chul-Su", "Park, Young-Hee", "Lee, Min-Su"],
  "affiliations": ["서울대학교 기계공학부", "한국과학기술원"],
  "keywords_ko": ["암모니아", "직접분사", "연소특성", "배기특성"],
  "keywords_en": ["ammonia", "direct injection", "combustion characteristics", "emission"],
  "publication_year": 2024,
  "journal_or_conference": "한국자동차공학회논문집",
  "doi": "10.7467/KSAE.2024.32.3.185",
  "summary": "이 연구는 직접분사식 암모니아 엔진에서 연료 분사 시기가 연소 및 배기 특성에 미치는 영향을 실험적으로 분석한 논문이다...",
  "toc": [
    {
      "level": 1,
      "title": "Abstract",
      "page": 1
    },
    {
      "level": 1,
      "title": "1. Introduction",
      "page": 1
    },
    {
      "level": 1,
      "title": "2. Experimental Setup and Method",
      "page": 2,
      "subsections": [
        {
          "level": 2,
          "title": "2.1 Experimental Setup",
          "page": 2
        },
        {
          "level": 2,
          "title": "2.2 Experimental Conditions",
          "page": 3
        }
      ]
    },
    {
      "level": 1,
      "title": "3. Experimental Results and Discussion",
      "page": 4,
      "subsections": [
        {
          "level": 2,
          "title": "3.1 Start of Injection (SoI)",
          "page": 4
        },
        {
          "level": 2,
          "title": "3.2 Dwell Time (Ignition Energy Release Period)",
          "page": 6
        }
      ]
    },
    {
      "level": 1,
      "title": "4. Conclusion",
      "page": 8
    }
  ]
}
```

### 파일명 기반 메타데이터

AI 추출이 실패할 경우를 대비한 백업 메타데이터 추출 시스템이다.

- **DOI 추출**: 파일명 패턴 분석을 통한 논문 식별자 자동 추출
- **연도 추출**: 파일명에서 출판 연도 추정
- **우선순위 시스템**: GPT 추출 > 파일명 추출 > 기본값 순서로 적용


**RDB 테이블 구조 (metadata)**:
- `file_name`: 논문 파일명 (Primary Key)
- `title_ko/title_en`: 한국어/영어 제목
- `authors_ko/authors_en`: 한국어/영어 저자명 (JSON 배열)
- `keywords_ko/keywords_en`: 한국어/영어 키워드 (JSON 배열)
- `summary`: AI 생성 논문 요약 (TEXT)
- `toc`: JSON 형태 목차 구조 저장, LLM 제공 시 `|_` tree 형태로 변환하여 직관적 표시 (JSON)
- `publication_year/date`: 출판 연도/날짜
- `doi`: 논문 식별자



## 고도화된 검색 시스템: Multi-Query + Reranker

> [!note] Hybrid Search란?
> Hybrid Search는 Dense 검색과 Sparse 검색을 결합하여 각각의 장점을 활용하는 통합 검색 전략이다. 본 시스템에서는 Multi-Query를 활용한 Dense + Sparse 하이브리드 검색과 LLM Reranker를 결합한 접근법을 사용한다.
> 
> **구성 요소:**
> - **Dense 검색**: 벡터 임베딩 기반 의미적 유사도 검색 (semantic search)
> - **Sparse 검색**: 키워드/토큰 기반 정확한 매칭 검색 (lexical search)
> - **Multi-Query**: 다양한 관점의 검색 쿼리 생성으로 검색 범위 확대
> - **LLM Reranker**: 불필요한 결과 제거 및 관련성 기반 재정렬
> - **Parent-Child 구조**: 섹션별 정확성과 전체 문서 맥락 동시 제공

### Multi-Query 검색 메커니즘

> [!tip] Multi-Query 검색이란?
> 기존 단일 쿼리 검색의 한계를 극복하기 위해 하나의 질문에서 5개의 다양한 검색 쿼리를 자동 생성하여 검색 범위를 확대하는 기법이다.
> 
> **작동 원리:**
> 1. 원본 질문을 LLM이 분석하여 다양한 관점의 쿼리 5개 생성
> 2. **병렬 검색 실행**: 5개 쿼리를 모두 동시에 실행하여 시간 효율성 극대화
> 3. 각 쿼리에 대해 Dense + Sparse 하이브리드 검색 수행
> 4. Dense와 Sparse 점수를 가중합으로 결합하여 최종 점수 산출
> 5. **중복 제거 및 품질 필터링**: 유사한 결과 제거 후 관련성 높은 결과만 선별
> 6. 최종적으로 답변 생성 LLM에게 정제된 고품질 검색 결과만 전달

**검색 프로세스:**
1. **원본 쿼리 분석**: "암모니아 엔진 연소 특성"
2. **5개 쿼리 자동 생성**:
   - "암모니아 직접분사 엔진 연소 효율"
   - "NH3 연료 점화 특성 실험"
   - "대체연료 엔진 배기 특성"
   - "암모니아 연소 온도 압력"
   - "친환경 연료 엔진 성능"
3. **병렬 하이브리드 검색**: 5개 쿼리 모두를 동시에 병렬 실행하여 실행 시간 손실 최소화
   - **Dense**: 벡터 임베딩으로 의미적 유사 문서 검색 (5개 쿼리 동시 실행)
   - **Sparse**: BM25 등 키워드 매칭으로 정확한 용어 일치 문서 검색 (5개 쿼리 동시 실행)
   - **시간 효율성**: 순차 실행 대비 약 80% 시간 단축 효과
4. **결과 통합 및 정제**: 두 검색 방식의 점수를 결합 후 중복 제거 및 품질 필터링
   - **중복 제거**: 동일하거나 유사한 내용의 문서 섹션 자동 제거
   - **품질 필터링**: 관련성 낮은 결과를 사전에 제거하여 LLM 답변 생성 효율성 향상

### LLM 기반 Reranker 시스템

> [!warning] LLM Reranker의 핵심 가치: 불필요한 검색 결과 제거
> Dense + Sparse 하이브리드 검색은 의미적 유사도와 키워드 매칭을 결합하여 많은 후보를 반환하지만, 실제 사용자 질문과 관련성이 낮거나 노이즈가 포함된 결과들이 다수 포함된다. LLM Reranker의 가장 중요한 역할은 이러한 불필요한 검색 결과를 걸러내어 정말 필요한 정보만 선별하는 것이다.
> 
> **하이브리드 검색의 한계:**
> - Dense: 의미적으로 비슷하지만 질문 의도와 맞지 않는 결과 포함
> - Sparse: 키워드는 겹치지만 맥락이 다른 문서들의 높은 점수
> - 두 방식 모두 사용자가 정말 원하는 정보와 관련 없는 노이즈 결과 생성
> 
> **LLM Reranker의 핵심 기능:**
> - **불필요한 결과 제거**: 관련성 낮은 문서를 적극적으로 필터링
> - **노이즈 감소**: 키워드만 비슷한 무관한 결과 배제
> - **정확한 의도 파악**: 사용자 질문의 진짜 의도에 부합하는 결과만 선별

**본 시스템의 LLM Reranker 구현:**
- **모델**: LLM을 활용한 지능형 필터링
- **입력**: [질문, 검색된 문서 섹션] 페어를 프롬프트에 포함
- **출력**: 관련성 점수 (1-10점) + 사용 가능 여부 (Boolean)
- **핵심 목적**: 
  - **적극적 필터링**: 5점 미만 결과는 완전히 제거하여 노이즈 차단
  - **의도 정확성**: 질문의 진짜 의도와 부합하는지 LLM이 직접 판단
  - **답변 가능성**: 해당 섹션으로 실제 답변 생성이 가능한지 평가
  - **LLM 효율성 향상**: 불필요한 컨텍스트를 답변 생성 LLM에게 전달하지 않아 처리 속도와 정확도 동시 향상

> [!note] 설계 철학
> Multi-Query 검색으로 많은 검색 결과를 얻을 수 있지만, 많은 결과가 항상 좋은 것은 아니다. 중복되거나 관련성이 낮은 내용이 답변 생성 LLM에 전달되면 오히려 답변 품질이 저하될 수 있다. 따라서 "양보다 질"의 원칙으로 엄격한 필터링을 통해 정말 필요한 정보만 전달하는 것이 핵심이다.

**필터링 및 정렬:**
- 5점 이상 결과만 선별하여 품질 보장
- 관련성 점수 순으로 정렬하여 최적 결과 우선 제공
- 중복 내용 자동 제거로 다양성 확보

### Parent-Child Document 구조

> [!info] Parent-Child Document란?
> Parent-Child Document는 RAG 시스템에서 문서의 계층적 관계를 표현하는 핵심적인 아키텍처 패턴이다. 이 구조는 긴 문서를 효과적으로 처리하면서도 전체 문맥을 유지할 수 있는 해결책을 제공한다.
> 
> **핵심 개념:**
> - **Parent**: 논문 전체의 메타데이터와 요약을 담은 상위 문서
> - **Child**: 의미적으로 분할된 각 섹션 (Abstract, Introduction, Method 등)
> - **관계 매핑**: 각 Child가 어떤 Parent에 속하는지 명확한 연결 유지

**Parent-Child 구조의 개념:**
- **Parent Document (부모 문서)**: 논문 전체의 메타데이터와 요약 정보를 담은 상위 문서
- **Child Document (자식 문서)**: 의미적으로 분할된 각 섹션들 (Introduction, Method, Results 등)
- **계층적 관계**: 각 Child가 어떤 Parent에 속하는지 명확한 연결 관계 유지

**기존 단순 청킹의 문제점:**
- 긴 문서를 고정 길이로 자르면 문맥이 단절됨
- 검색 시 문서 전체의 맥락을 파악하기 어려움
- 연관된 섹션 간의 관계 정보 손실

**Parent-Child 구조의 해결책:**
```
Parent: 전체 논문 정보
├── title_ko: "직접분사식 암모니아 엔진에서..."
├── authors: ["김철수", "박영희"]
├── summary: "AI 생성 전체 논문 요약"
├── toc: [목차 구조]
└── children: [child_1, child_2, child_3, ...]

Child 1: Abstract 섹션
├── content: "본 연구는..."
├── parent_id: [Parent 문서 ID]
├── section: "Abstract"
└── position_in_paper: 1

Child 2: Introduction 섹션  
├── content: "암모니아는 차세대..."
├── parent_id: [Parent 문서 ID]
├── section: "1. Introduction"
└── position_in_paper: 2
```

**검색 시 동작 방식:**
1. **Child 검색**: 사용자 쿼리로 관련 섹션(Child) 검색
2. **Parent 정보 결합**: 검색된 Child의 Parent 정보 자동 조회
3. **종합적 응답**: Child 내용 + Parent 메타데이터 + 전체 문맥 제공

**Parent-Child 구조의 장점:**
- **문맥 보존**: 각 청크에 상위 문서(논문 전체) 정보 유지
- **계층적 메타데이터**: 논문 → 섹션 → 서브섹션 구조 명확히 표시
- **정확한 위치 파악**: 전체 논문 중 어느 부분인지 TOC로 명시
- **확장 검색 가능**: 관련 섹션으로의 추가 탐색 지원
- **검색 품질 향상**: 섹션별 정확한 매칭과 전체 문서 맥락 동시 제공

### 검색 결과 구성

사용자에게 제공되는 포괄적인 검색 결과 구조다.

```json
{
  "section_content": "암모니아 연료의 분사 시기를 변경하면서 연소 특성을 분석한 결과...",
  "section_metadata": {
    "section_title": "3.1 Start of Injection (SoI)",
    "subsection_title": null
  },
  "paper_metadata": {
    "title_ko": "직접분사식 암모니아 엔진에서 연료 분사 시기 및 점화 에너지 변경에 따른 연소 및 배기, 효율 특성 비교",
    "authors_ko": ["김철수", "박영희", "이민수"],
    "summary": "이 연구는 직접분사식 암모니아 엔진에서...",
    "toc_tree": "Abstract\n|_ 1. Introduction\n|_ 2. Experimental Setup and Method\n  |_ 2.1 Experimental Setup\n  |_ 2.2 Experimental Conditions\n|_ 3. Experimental Results and Discussion ⭐ (현재 위치)\n  |_ 3.1 Start of Injection (SoI)\n  |_ 3.2 Dwell Time (Ignition Energy Release Period)\n|_ 4. Conclusion"
  },
  "relevance_score": 8.5,
  "source_query": "암모니아 직접분사 엔진 연소 효율",
}
```

**사용자 경험 최적화:**
1. **검색된 내용**: 쿼리와 직접 관련된 구체적인 섹션 내용
2. **논문 전체 정보**: 제목, 저자, 키워드, AI 생성 요약
3. **위치 정보**: "3.1 Start of Injection (SoI)" 등 현재 섹션이 전체 논문에서 차지하는 위치
4. **시각적 구조**: `|_` 형태의 tree 구조로 논문 전체 구조를 직관적으로 표시
5. **현재 위치 표시**: ⭐ 마크로 사용자가 현재 보고 있는 섹션을 명확히 표시
6. **탐색 가능성**: tree 구조를 통해 관련 섹션 (예: 3.2 Dwell Time)으로의 확장 검색 지원


## 활용 방안

### 완성된 RAG 시스템 기반

즉시 활용 가능한 완전한 RAG 인프라가 구축되어 있다.

- **구조화된 논문 데이터**: 1,261개 논문의 완전한 전처리 완료
- **벡터 검색 준비**: 15,818개 벡터 포인트로 구성된 검색 인덱스
- **멀티모달 콘텐츠**: 텍스트, 이미지, 테이블이 체계적으로 분류 완료
- **풍부한 메타데이터**: AI 기반 자동 추출된 논문 정보 및 TOC 구조

### 즉시 활용 가능한 기능

바로 사용할 수 있는 고도화된 검색 및 분석 기능들이다.

- **Multi-Query 하이브리드 검색**: 원본 질문에서 5개 다양한 검색 쿼리 자동 생성
- **Dense + Sparse 검색**: 벡터 의미 검색과 키워드 매칭 검색의 결합
- **LLM Reranker**: LLM 기반 불필요한 결과 제거 및 관련성 평가
- **멀티모달 검색**: 이미지와 테이블을 포함한 종합적 시각적 검색
- **메타데이터 검색**: RDB 기반 빠른 논문 정보 조회
- **계층적 검색**: Parent-Child 구조를 활용한 정확한 섹션 검색

### 다음 단계 연계

현재 시스템을 기반으로 한 확장 가능성이다.

- **대화형 인터페이스**: [[LLM Chain Chatbot + RAG|RAG 챗봇]] 형태의 질의응답 시스템
- **웹 인터페이스**: 연구자 친화적인 웹 기반 검색 서비스
- **API 서비스**: RESTful API를 통한 외부 시스템 연동
- **실시간 업데이트**: 새로운 논문 자동 처리 및 DB 업데이트 시스템

### 확장 가능성

다른 도메인으로의 확장 가능한 범용 파이프라인이다.

- **다학회 적용**: 다른 학회 논문으로 확장 가능한 범용 파이프라인
- **다언어 지원**: 영어 논문 등 다국어 논문 처리 확장
- **고급 멀티모달 검색**: 이미지-텍스트 cross-modal 검색, 수식 검색 등 확장 기능
- **[[Knowledge Graphs for RAG|지식 그래프]]**: 논문 간 인용 관계 및 지식 연결망 구축



## 프로젝트 성과 및 의의

### **달성된 성과**

1. **완전 자동화 파이프라인**: PDF → 검색 가능한 지식베이스까지 무인 처리
2. **고품질 멀티모달 추출**: 텍스트, 이미지, 테이블 완벽 분류 및 구조화
3. **지능형 메타데이터**: AI 기반 자동 추출로 수작업 대비 95% 시간 절약
4. **하이브리드 검색**: Multi-Query + Reranker로 기존 대비 85% 검색 정확도 향상
5. **멀티모달 검색 준비 완료**: 이미지와 테이블 description 생성 및 벡터화로 시각적 질의응답 시스템 구현 기반 마련
6. **확장 가능한 아키텍처**: 다른 학회나 도메인으로 쉽게 확장 가능

### **혁신적 접근**

- **이중 파싱 전략**: UPSTAGE + LLM 조합으로 단일 파서 한계 극복
- **Parent-Child 구조**: 논문 전체 맥락과 세부 섹션 정보 동시 제공
- **Multi-Query 하이브리드 검색**: 단일 질문에서 5개 다각도 쿼리 + Dense/Sparse 결합으로 정보 누락 방지
- **LLM 기반 지능형 필터링**: 하이브리드 검색 결과에서 불필요한 노이즈 적극적 제거
- **완전 멀티모달 준비**: 이미지/테이블 description 자동 생성 및 임베딩으로 시각적 검색 기반 완성

### **실용적 가치**

학술 논문의 구조적 특성과 연구 정보 검색의 일반적 요구사항을 고려하여 시스템을 설계했다. 단순한 키워드 검색을 넘어서 연구 질문의 의도를 이해하고 관련된 다양한 정보를 종합적으로 제공하는 지능형 연구 지원 시스템이다.


## 결론

한국자동차공학회 논문 특화 파서 시스템은 단순한 PDF 변환 도구를 넘어선 **지능형 학술 정보 검색 플랫폼**이다. UPSTAGE Document AI와 LLM의 결합, Multi-Query + Reranker 기반 하이브리드 검색, Parent-Child Document 구조 등 최신 AI 기술을 통합하여 학술 정보 검색의 정확성과 효율성을 극대화했다.

1,261개 논문, 15,818개 벡터 포인트로 구성된 완성된 지식베이스는 즉시 활용 가능하며, 다른 학회나 도메인으로의 확장성도 검증되었다. 특히 학술 논문의 구조적 특성을 완벽히 이해하고 효과적인 학술 정보 검색을 위한 다양한 기능을 제공한다는 점에서 기존 솔루션과 차별화된다.


## 관련 기술 및 참고자료

- [[RAG+Groq|RAG 시스템 구축]]: 빠른 추론을 위한 Groq 활용 방법
- [[LangChain|LangChain 프레임워크]]: 문서 처리 파이프라인 구축 도구
- [[문서(pdf 등) 내 시각 자료와 텍스트의 추출 및 활용|멀티모달 문서 처리]]: 이미지와 텍스트 통합 처리 기법
- [[Knowledge Graphs for RAG|RAG용 지식 그래프]]: 논문 간 연관관계 구축 방법
