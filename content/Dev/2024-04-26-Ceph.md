---
layout: post
title: Ceph 정리
date: 2024-04-27 23:57 +0900
categories:
  - ETC
  - Tech
tags: 
math: true
---

## Intro: 

## Ceph란?

- 오픈 소스 스토리지 플랫폼

- 여러 스토리지들을 클러스터로 묶어 하나로 보이게 하는 분산형 스토리지

  
  

장점:

  

- 분산으로 저장하여 복구에 용이

- 하나의 클러스터로 묶어 접근 용이



### RADOS(Reliable Automatic Distributed Object)

  

- 분산 스토리지 클러스터를 구성하기 위한 기초 기술

- 주로 Ceph에서 사용

- 데이터의 복제, 장애 조치(failover) 및 자동 복구 등을 자동화 -> 고가용성, 확장성 제공

  

#### RADOS의 주요 특징:

  

1. **분산 처리 및 스토리지**: 데이터를 여러 서버에 걸쳐 분산시켜 저장함으로써, 단일 장비의 실패가 전체 시스템에 미치는 영향을 최소화

2. **확장성**: 클러스터의 크기를 쉽게 조정할 수 있어, 소규모 시스템에서부터 수천 대의 서버를 포함하는 대규모 시스템까지 확장 가능

3. **자동 복구**: 장비의 실패가 발생하면 RADOS는 다른 장비에 데이터의 복사본을 자동으로 재배치하여 데이터의 내구성 유지

4. **데이터 복제 및 일관성**: 데이터는 여러 서버에 복제되어 저장되므로, 어느 하나의 서버에 문제가 생겨도 데이터의 안전성과 접근성 보장

5. **오버헤드 감소**: 데이터를 저장하거나 접근할 때 발생하는 네트워크 오버헤드와 디스크 I/O를 최소화하여, 전체적인 성능 향상 도모

6. **모니터링 및 관리**: 상태 모니터링과 자동 관리 기능을 통해 시스템의 건강을 지속적으로 확인하고 대처

  

![](https://i.imgur.com/CP5XJjb.png)

#### RBD (Rados Block Device)

 - Ceph에서 제공하는 virtual disk device

  
  

특징:

- Client는 kernel module 또는 librbd를 통해 RBD 사용

- Thin- Provisioning 지원 

  

![](https://blog.kakaocdn.net/dn/tTvNa/btq3hgfs7j6/xzmgeBvDPR4r1kqPhLtSqk/img.png)

  

#### Ceph File System (CephFS)

- POSIC-conpliant 한  Distributed file system

  

특징

- CephFS kernel or FUSE를 통해 사용

- Resize와 snapshot 기능 

- File의 Metadata를 관리 를 위해 **MDS(메타데이터 저장)**사용

  

![](https://blog.kakaocdn.net/dn/rytKQ/btq3dxowbso/Kpn0cmHbnBUM90ZebCW5dK/img.png)

  

#### Ceph Object Storage 

- Ceph Object Gateway

  

Ceph에서 제공하는 Object Storage  Interface

  

특징

  

- Client는 cluster와 통신하기 위해 RGW 사용

- Client는 S3API와 Swift API 사용가능

  

![](https://blog.kakaocdn.net/dn/esBNux/btq3dPbKi7b/CRj30dhk6nxEc5BMO9PlSk/img.png)

  

#### 종합 적인구조 

  

Data가 들어오면   Data의 종류의 따라 위의 설명 대로 변경이 됩니다.

  

변경된 결과 값은 결국 Object로 변환되고 변환된 Object는 Libados에 따라 이후과정은 룰에 따라 OSD에 저장 됩니다.

  

![](https://blog.kakaocdn.net/dn/ex3uQw/btq3ghZ8lKe/uxOcYxDrOtR74t4WH9XMSK/img.jpg)

  

출처 : https://www.slideshare.net/VijayendraShamanna/optimizingcephflash