---
layout: post
title: 빅분기-실기-1유형
date: 2023-11-27 21:10 +0900
categories:
  - 자격증
  - 빅분기
tags: 
math: true
---

## 1유형-데이터 다루기

### 유형

1. 데이터 타입(object, int, float, bool 등)
2. 기초통계량(평균, 중앙값, 사분위수, IQR, 표준편차 등)
3. 데이터 indexing, filtering, sort, 변경 등
4. 중복값, 결측치, 이상치 처리(제거 or 대체)
5. 데이터 Scaling(데이터 표준화(z), 데이터 정규화(min-max))
6. 데이터 합치기
7. 날짜/시간 데이터, index 다루기

> 날짜, 시간 데이터 연습이 많이 필요할듯!



## 명령어 정리
### 1. 데이터 타입(object, int, float, bool 등)


| 명령어           | 설명                       | 사용 예시                           |
| ---------------- | -------------------------- | ----------------------------------- |
| `dtypes`         | 데이터 타입 확인           | `df.dtypes`                         |
| `astype`         | 데이터 타입 변경           | `df.astype({'column':'data type'})` |
| `value_counts()` | 컬럼에 대한 발행 횟수 반환 | `df['column'].value_counts()`       |


### 2. 기초통계량(평균, 중앙값, 사분위수, IQR, 표준편차 등)

#### 1) 중심측도


| 명령어     | 설명   | 사용 예시              |
| ---------- | ------ | ---------------------- |
| `mean()`   | 평균값 | `df['column'].mean()   |
| `median()` | 중앙값 | `df['column'].median() |
| `mode()`   | 최빈값 | `df['column'].mode()`  |

#### 2) 산포도

| 명령어             | 설명     | 사용 예시                     |
| ------------------ | -------- | ----------------------------- |
| `var()`            | 분산     | `df['column'].var()`          |
| `std()`            | 표준편차 | `df['column'].std()`          |
| `quantile([수치])` | IQR      | `Q1 = df['column'].quantile(0.25)`<br>`Q3 = df['column'].quantile(0.75)`<br>`IQR = Q3 - Q1` |
| `max(), min()` | 범위 | `col_max = df['coulmn'].max()`<br>`col_min = df['column'].min()`<br>`col_range = col_max - col_min`   |


#### 3) 분포의 비대칭도

| 명령어   | 설명 | 사용 예시             |
| -------- | ---- | --------------------- |
| `skew()` | 왜도 | `df['column'].skew()` |
| `kurt()` | 첨도 | `df['column'].kurt()` |


#### 4) 기타(합계, 절대값, 데이터 수 등)

| 명령어  | 설명   | 사용 예시         |
| ------- | ------ | ----------------- |
| `sum()` | 합계   | `df['col'].sum()` |
| `abs()` | 절대값 | `abs(숫자변수)`       |

#### 5) 그룹화하여 계산

| 명령어      | 설명                 | 사용 예시                                                                   |
| ----------- | -------------------- | --------------------------------------------------------------------------- |
| `groupby()` | 특정 컬럼을 기준삼기 | `df.groupby('column명')` <br> `df.groupby('column').mean() # 컬럼별 평균값` |

### 3. 데이터 indexing, filtering, sort, 변경 등

#### 1) 데이터 인덱싱

| 명렁어           | 설명                 | 사용 예시                      |
| ---------------- | -------------------- | ------------------------------ |
| `df.loc[행, 열]` | 행/열 인덱싱         | `df.loc[:, 'column':'column']` |
| `df.head()`      | 앞에서 n행(기본:5행) | `df.head(n)`                   |
| `df.tail()`      | 뒤에서 n행(기본:5행) | `df.tail(n)`                               |


#### 2) 열(columns) 추가/제거

| 명령어                              | 설명    | 사용 예시                                        |
| ----------------------------------- | ------- | ------------------------------------------------ |
| `df.drop(columns=['col1', 'col2'])` | 열 제거 | `df.drop(columns=['col1', 'col2', inplace=True]` <br> `df.drop('col1', axis=1, inplace=True)` |


#### 3) 데이터 필터링

| 명령어                            | 설명            | 사용 예시          |
| --------------------------------- | --------------- | ------------------ |
| `df[df['column'] [비교연선자] n]` | 1개 조건 필터링 | `df[df['col']==1]` |
| `df[cond1 [비교연산자] cond2]`               | 2개 조건 필터링 | `df[cond1 & cond2]` <br> `df[(df['col1']==4) & (df['col2']>=2)`|

#### 4) 데이터 정렬

| 명령어             | 설명 | 사용 예시 |
| ------------------ | ---- | --------- |
| `df.sort_values()` | 정렬 | 내림차순 정렬: `df.sort_values('col', ascending=False)` <br> 오름차순 정렬: `df.sort_values('col', ascending=True)`         |


#### 5) 데이터 변경(조건문)

| 명령어                                              | 설명                                  | 사용 예시                                                                                                       |
| ------------------------------------------------ | ----------------------------------- | ----------------------------------------------------------------------------------------------------------- |
| `np.where()`                                     | 조건 만족 인덱스 반환                        | `np.where(`                                                                                                 |
| `np.where([조건], [조건만족시 변경할 값], [조건 불만족시 변경할 값])` | python if, else 문과 같이 조건에 따라 데이터 변경 | col 변수값중 205가 넘는 값은 205로 처리하고 나머지는 그대로 유지: <br> `df['new_col'] = np.where(df['col'] >= 205, 205, df['col']` |


### 4. 결측치, 이상치, 중복값 처리(제거 or 대체)

#### 1) 결측치 확인 및 처리

| 명령어           | 설명        | 사용 예시                                                    |
| ---------------- | ----------- | ------------------------------------------------------------ |
| `isnull().sum()` | 결측치 확인 | `df.isnull().sum()`                                          |
| `drop.na()`      | 결측치 제거 | 행 기준:`df.dropna(axis=0)`<br> 열 기준: `df.dropna(axis=1)` |
| `fillna()`       | 결측치 대체 | 평균으로 대체: `df['col'] = df['col'].fillna(df['col'].mean())` <br> 중앙값으로 대체: `df['col'] = df['col'].fillna(df['col'].median())` |                                                             |

> 결측치 제거 or 대체 후 `isnull().sum()`으로 확인 잊지말자!


#### 2) 이상치 확인 및 처리

##### 상자 그림 활용(이상치: Q1, Q3로부터 1.5\*IQR 초과하는 값)

> `seaborn` 라이브러리를 사용해 boxplot을 그리는 방법(시험 환경에서는 그래프 못그림)
> ```python
> sns.boxplot(df['col'])
> ```



```python
# Q1, Q3, IQR

Q1 = df['col'].quantile(0.25)
Q3 = df['col'].quantile(0.75)
IQR = Q3 - Q1

print(Q1, Q3, IQR)
```

	20.125 38.0 17.875

```python
upper = Q3 + 1.5*IQR
lower = Q1 - 1.5*IQR
print(upper, lower)
```

	64.8125 -6.6875

```python
# 문제: col 변수의 이상치를 제외한 데이터 수 구하기
cond1 = (df['col']<=upper)
cond2 = (df['col']>=lower)

print(len(df[cond1 & cond2]))
print(len(df[cond1]))
print(len(df))
```

	703
	703
	891

```python
# 문제: col 변수의 이상치를 제외한 데이터셋 만들기
df_new = df[cond1 & cond2]
```


##### 표준정규분포 활용(이상치: ±3Z 값을 넘어가는 값)


>###### 통계 기법을 이용한 데이터 이상값 검출
>###### (1) ESD(Extreme Studentized Deviation)
>- 평균(μ)으로부터 `3 표준편차(σ)` 떨어진 값을 이상값으로 판단하여 검출
>###### (2) 기하평균
>- 기하평균으로부터 `2.5 표준편차(σ)` 떨어진 값을 이상값으로 판단하여 검출
> ###### (3) 사분위수
> - 제 1사분위, 제 3사분위를 기준으로 `사분위간 범위(IQR)의 1.5배` 한 값과 떨어진 위치를 이상값으로 판단하는 기법
> ###### (4) Z-score(표준화 점수)
>- 평균이 μ이고 표준편차가 σ인 정규분포를 따르는 관측치들이 자료의 중심에서 얼마나 떨어져 있는지 파악하여 이상값을 검출
> ###### (5) Dixon Q-test(딕슨의 Q검정)
>- 오름차순으로 정렬된 데이터에서 범위에 대한 관측치 간 차이에 대한 비율을 활용하여 이상값 여부 검정
>- 데이터가 `30개 미만`일 경우 적절
> ###### (6) Grubbs T-test(그럽스의 T검정)
>- 데이터가 정규분포를 만족하거나, 단변량 자료에서 이상값을 검정하는 방법
> ###### (7) Chi-square test(카이제곱 검정)
> - 데이터가 정규분포를 만족하나, 자료 수가 적은 경우 이상값을 검정하는 방법
> ###### (8) Mahalanobis distance(마할라노비스 거리)
>- 데이터의 분포를 고려한 거리 측도로, 관측치가 평균으로부터 벗어난 정도를 측정
>- 마할라노비스 거리를 이용하여 평균으로부터 벗어난 이상값을 검출
>- 모든 변수 간 선형관계를 만족하고, 각 변수가 정규분포를 따르는 경우 적용 가능


- 데이터 표준화 : Z = (개별 값-평균) / 표준편차

```python
# 데이터 표준화 : Z = (개별 값-평균) / 표준편차
mean_age = df['age'].mean()
std_age = df['age'].std()
print(mean_age)
print(std_age)
```

	29.69911764705882
	14.526497332334044


```python
znorm = (df['age']-mean_age) / std_age
znorm
```
	0     -0.530005
	1      0.571430
	2     -0.254646
	3      0.364911
	4      0.364911
	         ...   
	886   -0.185807
	887   -0.736524
	888         NaN
	889   -0.254646
	890    0.158392
	Name: age, Length: 891, dtype: float64

문제: 이상치의 개수는 몇개인가? (±3Z 기준)

```python
cond1 = (znore >3) # 2개
cond2 = (znorm <-3) # 0개

print(len(df[cond1|cond2]))
print(len(df[cond1]) + len(df[cond2]))
```

	2
	2


##### Scipy 라이브러리 사용하여 Z-Score 구하는법:

```python
from scipy.stats import zscore

df['zscore'] = zscore(df['column'])
```
#### 3) 중복값 제거

| 명령어              | 설명      | 사용 예시                          |
| ------------------- | --------- | ---------------------------------- |
| `drop_duplicates()` | 중복 제거 | `df.drop_duplicates(inplace=True)` |

> 중복값이 필요한 경우도 있음으로 무분별한 사용을 주의하자



### 5. 데이터 Scaling(데이터 표준화(z), 데이터 정규화(min-max))

#### 1) 데이터 표준화(Z-score normalization)

```python
from sklearn.proprocessing import StandardScaler

scaler = StandardScaler() 
X_train_scaled = scaler.fit_transform(X_train) 
X_test_scaled = scaler.transform(X_test)
```

> StandardScaler의 `fit_transform` 함수의 입력값은 DataFrame 형태({array-like, sparse matrix})임을 주의하자(Series형태로 입력하면 에러)

| 명령어            | 설명                 | 사용 예시 |
| ----------------- | -------------------- | --------- |
| `fit_transform()` | 표준화 fit+transform | `StandardScaler().fit_transform(df[['col']])`          |


#### 2) 데이터 정규화(min-max normalization)

```python
from sklearn.preprocessing import MinMaxScaler

mscaler = MinMaxScaler()
df['col'] = mscaler.fit_transform(df[['mpg']])
```



> ### 데이터 표준화 (Data Standardization), 데이터 정규화 (Data Normalization) 차이점
>
 > #### 데이터 표준화 (Data Standardization)
> - **목적**: 평균을 0, 표준편차를 1로 만들어 다른 척도의 데이터 비교 용이
> - **방법**: 
>     - 공식: $Z = \frac{(X - \mu)}{\sigma}$
>     - $X$: 원래 값, $\mu$: 평균, $\sigma$: 표준편차
> - **적용**: 변수 간 비교, 가중치 부여에 유용. 예: SVM, 로지스틱 회귀
> 
> #### 데이터 정규화 (Data Normalization)
> 
> - **목적**: 데이터 범위를 특정 범위(0과 1 등)로 조정
> - **방법**: 
>     - 공식: $X_{\text{normalized}} = \frac{(X - X_{\text{min}})}{(X_{\text{max}} - X_{\text{min}})}$
>     - $X$: 원래 값, $X_{\text{min}}$, $X_{\text{max}}$: 데이터 최소값과 최대값
> - **적용**: 입력 변수 크기 중요시하는 경우. 예: 신경망, K-NN, K-Means 클러스터링
> 
> #### 차이점
> 
> - **척도 조정**: 
>     - 표준화: 데이터 분포 고려 척도 조정
>     - 정규화: 데이터의 범위 조정
> - **목적**: 
>     - 표준화: 데이터 분포 중요시
>     - 정규화: 데이터 스케일 통일 중점
> - **결과 범위**: 
>     - 표준화: 음수 값 포함 가능
>     - 정규화: 0과 1 사이 값으로 제한

### 6. 데이터 합치기

| 명령어        | 설명          | 사용 예시                                                                                                                              |
| ------------- | ------------- | -------------------------------------------------------------------------------------------------------------------------------------- |
| `pd.concat()` | 데이터 합치기 | 행 방향으로 결합(위아래): `df_sum = pd.concat([df1, df2], axis=0)`<br> 열 방향으로 결합(좌우): `df_sum = pd.concat(df1, df2], axis=1)` |


### 7. 날짜/시간 데이터, index 다루기
#### 1) 날짜 다루기

| 명령어             | 설명                         | 사용 예시                                                                            |
| ------------------ | ---------------------------- | ------------------------------------------------------------------------------------ |
| `pd.to_datetime()` | 데이터타입 datetime으로 변경 | `df['date'] = pd.to_datetime(df['date'])`                                            |
| `dt.year`          | 년,월,일 변수 추출하기       | 년: `df['date'].dt.year` <br> 월: `df['date'].dt.month` <br> 일: `df['date'].dt.day` |
| `between()`        | 날짜 구간 필터링             | `df[df['date'].between('2023-01-01', '2023-12-31')]`                                 |
| `loc[]`            | loc 필터링            | `df.loc['2023-01-01':'2023-12-31']` <br>`df.loc[(df.index>='2023-01-01') & (df.index<='2023-12-31')`                                                                                     |


> `between()` 함수에서 2023-12-31까지 포함임을 주의하자

> `loc[]` 첫번째 방법을 사용시엔 날짜가 index 컬럼이어야 함

#### 2) 시간 다루기

| 명령어                | 설명                                                | 사용 예시                                                     |
| --------------------- | --------------------------------------------------- | ------------------------------------------------------------- |
| `between_time`        | 시간이 index일때 날짜와 상관없이 특정 시간대 필터링 | `df.between_time(start_time='00:00:00', end_time='00:00:00')` |
| `set_index('column')` | 특정 컬럼을 인덱스로 지정                           | `df = df.set_index('time)'`                                                              |

