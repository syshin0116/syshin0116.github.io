---
layout: post
title: Natural Language Process(자연어 처리)
date: 2023-09-24 13:27 +0900
categories:
  - ETC
  - Tech
tags: 
math: true
---
## 1. 자연어 처리의 개념
### 자연어 처리(Natural Language Processing)란?
- 자연어의 의미를 분석하여 컴퓨터가 처리할 수 있도록 하는 일
- ex) 음성 인식, 요약, 번역, 감성 분석, 텍스트 분류, 질의 응답 시스텝, 챗복 등...
- '텍스트 분석' 이라고도 불리우나 '자연어 처리'라고 하면 인공지능을 이용한 분야라는 의미가 추가된다
### 자연어 처리를 배워야 하는 이유
- 회사 도메인(유통, 금융, 제조)를 가리지 않고 수요가 있음 
- 현재 실무에서 여전히 PLM(Pre-trained Language Model)을 이용한 자연어 사용
- 처리할 수 있는 중급 이상의 인력이 많지 않음 -> 기회!
- 성능 좋은 오픈 소스가 지속적으로 공개되고 있다

### 한국어 NLP 특징
한국어 자연어 처리는 영어보다 훨씬 어렵다
- 교착어 → 형태소 분석기의 필요성


|        | 대표언어                 | 특징                                                          |
| ------ | ------------------------ | ------------------------------------------------------------- |
| 교착어 | 한국어, 일본어, 몽골어   | 어간에 접사가 붙어, 단어를 이루고 의미와 문법적 기능이 정해짐 |
| 굴절어 | 라틴어, 독일어, 러시아어 | 단어의 형태가 변함으로써 문법적 기능이 정해짐                 |
| 고립어 | 영어, 중국어             | 어순에 따라 단어의 문법적 기능이 정해짐                       |

- 한국어 띄어쓰기가 잘 지켜지지 않는다
- 어순이 그렇게 중요하지 않다
- 한자어라는 특성상 하나의 음절조차도 다른 의미를 가질 수 있다
- 주어가 손쉽게 생략된다
- 데이터와 언어에 특화된 모델이 영어에 비해 부족하다

### 토큰화(Tokenization)
- 기계에게 어느 구간까지가 문장이고, 단어인지를 알려주는 것
- Token의 단위는 문장, 단어, 형태소 등 다양한 단위가 존재
- ex) 문장 토큰화, 단어 토큰화, Subword 토큰화 등

#### 단어 토큰화(Word Tokenization)
- 토큰의 단위가 단어
- 특수문자, 단어 중간의 '.', 영어에서 're 와 같은 단어들 떄문에 어려움
- TreebankWordTokenizer
	- Penn Treebank Tokenization 규칙을 따름
		1. 하이픈으로 구성된 단어는 하나로 유지
		2. doesn't와 같이 apostrophe로 접어가 함꼐하는 단어는 분리해준다

#### 문장 토큰화(Sentence Tokenization)
- 문장의 끝을 '., !, ?' 등으로 쉽게 구분히 가능할 것 같으나 생각보다 어렵다
- 영어는 NLTK Sentence Tokenizer, 한국어는 KSS 가 유명하다


#### 형태소 분석
- 한국어는 토크나이저로 형태소 분석기를 사용하는 것이 보편적
- Mecab: 연산 속도가 빠름
- Khali: 최근에 나옴, 딥러니이 기반 형태소 분석기
- KOMORAN: 오탈자에 강건함
- Soynlp: 학습 기반으로 복합 명사를 잘 추출해냄

![](https://i.imgur.com/UFM9q06.png)


### 정수 인코딩(Integer Encoding)
- 각 단어에 고유한 정수를 부여
- 중복이 허용되지 않는 모든 단어들의 집합을 만든다
- 이를 단어 집합(Vacabulary)라고 하며, 이를 기반으로 문서를 정수로 인코딩한다

![](https://i.imgur.com/Q5CTAXz.png)

### 패딩(Padding)
- 정수 인코딩을 수행 후 다른 길이를 가상의 단어를 추가하여 맞춰준다
- 기계가 병렬 연산 할 수 있도록 

### 텍스트의 벡터화
- Vocabulary의 생성
- Integer Encoding
- OOV(Out-Of-Vocabulary Problem)
	- 단어 집합에 없는 단어로 인해 생기는 문제
	- 일괄적으로 하나의 토큰으로 매핑해주기도 한다

### 벡터화(Vectorization)
1. 벡터화에 신경망을 사용하지 않을 경우
	- 단어에 대한 벡터 표현 방법: One-Hot Encoding
	- 문서에 대한 벡터 표현 방법: Document Term Matrix, TF-IDF

### TF-IDF(Term Frequency-Inverse Document Frequency)


## 1. 자연어 처리의 개념

### 1.1 정의
- 자연어의 의미를 분석하여 컴퓨터가 처리할 수 있도록 하는 일
- ex) 음성 인식, 요약, 번역, 감성 분석, 텍스트 분류, 질의 응답 시스텝, 챗복 등...
- '텍스트 분석' 이라고도 불리우나 '자연어 처리'라고 하면 인공지능을 이용한 분야라는 의미가 추가된다

### 1.2 주요 응용 분야

- 번역:
    - 구글 번역기 같은 도구들이 여러 언어 간의 실시간 번역을 가능케 함.
    - ex) "안녕하세요"를 영어로 번역하면 "Hello".
- 감성 분석:
    - 소셜 미디어 데이터를 분석하여 사용자의 감정 상태 파악.
    - ex) 상품 리뷰를 통한 긍정, 부정 의견 분석.
- 챗봇:
    - 사용자와의 대화를 통해 서비스를 제공.
    - ex) 고객 문의에 자동으로 응답하는 챗봇 서비스.
- 음성 인식:
    - 사용자의 음성 명령을 인식하여 동작 수행.
    - ex) "시리, 날씨 어때?"라고 물으면 날씨 정보 제공.
- 텍스트 요약:
    - 긴 문서의 주요 내용을 짧게 요약.
    - ex) 뉴스 기사의 핵심 내용 요약.
- 질의 응답 시스템:
    - 사용자의 질문에 대해 정확한 답변 제공.
    - ex) "세계에서 가장 큰 도시는 어디인가요?"에 대한 답변 제공.

### 1.3 자연어 처리의 중요성

- 다양한 산업 분야에서의 활용:
    - 유통, 금융, 제조 등 다양한 분야에서 NLP 기술 활용.
- 인력 수요와 기회:
    - 중급 이상의 NLP 전문가 부족, 해당 분야에 대한 수요와 기회 증가.
- 오픈 소스 및 자원의 공개:
    - 성능 좋은 NLP 모델과 도구의 오픈 소스 공개로 접근성 향상.

### 1.4 한국어 NLP의 특징과 어려움

- 교착어:
    - 한국어는 교착어로 분류, 형태소 분석 중요.
- 띄어쓰기:
    - 한국어에서는 띄어쓰기 규칙이 복잡하고, 일관성이 떨어짐.
- 어순:
    - 한국어의 어순은 상대적으로 자유로움.
- 주어 생략:
    - 문장 내에서 주어가 생략되는 경우가 자주 발생.
- 데이터와 모델의 다양성 부족:
    - 한국어에 특화된 모델과 데이터셋의 다양성이 영어에 비해 부족함.

## 2. 텍스트 전처리

### 2.1 토큰화 (Tokenization)

- 토큰화는 텍스트를 의미 있는 단위로 나누는 과정으로, 이를 통해 컴퓨터가 텍스트를 이해할 수 있게 됨.
- 종류와 특징: 단어 토큰화, 문장 토큰화, 형태소 토큰화 등이 있으며, 각각의 특징과 사용 상황이 다름.
- 도구 및 라이브러리: NLTK, KSS, Mecab, Khali, KOMORAN, Soynlp 등이 있음.

### 2.2 정수 인코딩 (Integer Encoding)

- 각 단어에 고유한 정수를 부여하여, 텍스트를 정수의 시퀀스로 변환하는 과정.
- 단어 집합 (Vocabulary)의 생성: 중복이 허용되지 않는 모든 단어들의 집합을 만들어, 단어에 정수를 부여함.
- OOV 문제와 해결 방안: 단어 집합에 없는 단어는 OOV로 처리하며, 이를 해결하기 위한 다양한 방법이 있음.

### 2.3 패딩 (Padding)

- 다양한 길이의 문장을 동일한 길이로 맞춰주기 위해 패딩을 사용함. 이를 통해 기계가 병렬 연산을 수행할 수 있음.

### 2.4 텍스트의 벡터화

- 텍스트 데이터를 벡터로 변환하는 방법: One-Hot Encoding, Document Term Matrix, TF-IDF 등의 방법을 사용하여 텍스트 데이터를 벡터로 변환함.

## 3. 단어 임베딩

### 3.1 단어 임베딩의 개념

- 단어 임베딩은 단어를 고차원의 벡터로 표현하는 것으로, 이를 통해 단어 간의 유사도를 계산할 수 있음.
- 단어 임베딩의 종류와 특징: Word2Vec, GloVe, FastText 등의 다양한 단어 임베딩 방법이 있음.

### 3.2 임베딩 학습 방법

- 대량의 텍스트 데이터를 사용하여 단어 임베딩을 학습할 수 있음. 이를 통해 비지도 학습 방식으로 단어의 벡터 표현을 얻을 수 있음.

## 4. 문장 임베딩과 문맥화 임베딩

### 4.1 문장 임베딩의 개념

- 문장 임베딩은 전체 문장을 고차원의 벡터로 표현하는 것으로, 이를 통해 문장 간의 유사도를 계산할 수 있음.
- 문장 임베딩의 종류와 특징: Doc2Vec, Sent2Vec, InferSent 등의 다양한 문장 임베딩 방법이 있음.

### 4.2 문맥화 임베딩의 개념

- 문맥화 임베딩은 단어의 문맥을 고려하여 단어를 벡터로 표현하는 방법으로, 이를 통해 동일한 단어라도 문맥에 따라 다른 벡터를 갖게 됨.
- 문맥화 임베딩의 종류와 특징: ELMo, BERT, GPT 등의 다양한 문맥화 임베딩 방법이 있음.

## 5. 텍스트 분류와 감성 분석

### 5.1 텍스트 분류의 개념

- 텍스트 분류는 주어진 텍스트를 미리 정의된 카테고리 중 하나로 분류하는 작업임.
- 텍스트 분류의 응용: 스팸 메일 필터링, 뉴스 카테고리 분류, 감성 분석 등 다양한 분야에서 활용됨.

### 5.2 감성 분석의 개념

- 감성 분석은 텍스트에서 나타나는 저자의 감정이나 태도를 파악하는 과정임.
- 감성 분석의 응용: 제품 리뷰 분석, 소셜 미디어 감정 분석 등 다양한 분야에서 활용됨.