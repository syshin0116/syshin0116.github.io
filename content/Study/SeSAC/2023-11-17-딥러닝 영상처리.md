---
layout: post
title: 딥러닝 영상처리
date: 2023-11-17 09:09 +0900
categories:
  - SeSAC
  - Computer-Vision
tags: 
math: true
---
## To-do:
- Yann LeCun LeNet-5 논문 읽어보기
### 권고 도서
- 대니얼 콴 생각에 대한 생각
- 인공지능 교과서: 스튜어트 러셀의 인공지능 1: 현대적 접근방식(AI: Modern Approach)
- 정통파: 비숍의 패턴인식과 머신러닝(Pattern Recognition and Machine Learning)

- 오바마의 디지털 참모: 신호와 소음
### NeurIPS 2019에서 소개된 System 1, System 2
- NeurIPS 2019에서 소개된 "System 1"과 "System 2"의 개념은 인지 심리학의 이론을 인공지능에 적용한 것
- 이 이론은 다니엘 카너먼의 저서 "생각에 관한 생각(Thinking, Fast and Slow)"에서 비롯되었는데, 여기서 그는 인간의 사고 과정을 두 가지 시스템으로 나눈다

1. **System 1 (시스템 1)**: 
	- 이는 빠르고 직관적인 사고를 담당
	- 자동적이고 무의식적인 반응과 결정을 포함하며, 일상적인 상황에서 빠른 판단이나 간단한 문제 해결에 활용
    
2. **System 2 (시스템 2)**: 
	- 느리고 논리적인 사고 과정
	- 의식적이고 주의를 요하는 작업, 복잡한 계산, 논리적 추론, 비판적 사고 등에 관여
    

NeurIPS 2019에서는 이러한 개념을 인공지능에 적용하여, 시스템 1과 같은 빠르고 직관적인 결정을 내리는 알고리즘과, 시스템 2처럼 더 복잡하고 계산이 많이 필요한 문제를 해결하는 알고리즘을 연구하고 개발하는 데 초점을 맞췄습니다. 이는 인공지능이 인간처럼 다양한 유형의 문제를 해결하고, 더 복잡하고 유연한 방식으로 사고할 수 있게 하는 데 목적을 두고 있습니다.

이러한 접근 방식은 인공지능이 단순히 데이터와 알고리즘에 의존하는 것을 넘어서, 인간의 사고 방식을 모방하여 더욱 직관적이고 창의적인 해결책을 제시할 수 있게 돕습니다.



## LeNet-5

![](https://i.imgur.com/cxcklV5.png)

- 1998년 Lecun
- 특징: 레이어가 많지 않기 때문에 Relu activation function을 안써도 문제가 생기지 않음

### Code:
#### keras:

```python
from keras.models import Sequential

from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense

#Instantiate an empty model

model = Sequential()

# C1 Convolutional Layer
model.add(Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=input_shape, padding='same'))

# S2 Pooling Layer
model.add(AveragePooling2D(pool_size=(2, 2), strides=2, padding='valid'))

# C3 Convolutional Layer
model.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))

# S4 Pooling Layer
model.add(AveragePooling2D(pool_size=(2, 2), strides=2, padding='valid'))

# C5 Fully Connected Convolutional Layer
model.add(Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))

#Flatten the CNN output so that we can connect it with fully connected layers
model.add(Flatten())

# FC6 Fully Connected Layer
model.add(Dense(84, activation='tanh'))

# Output Layer with softmax activation
model.add(Dense(10, activation='softmax'))

# print the model summary
model.summary()

```

#### torch:

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class MyCNN(nn.Module):
    def __init__(self):
        super(MyCNN, self).__init__()
        # C1 Convolutional Layer
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding='same')
        # S2 Pooling Layer
        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)
        # C3 Convolutional Layer
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding='valid')
        # S4 Pooling Layer
        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)
        # C5 Fully Connected Convolutional Layer
        self.conv3 = nn.Conv2d(16, 120, kernel_size=5, stride=1, padding='valid')
        # FC6 Fully Connected Layer
        self.fc1 = nn.Linear(120, 84)
        # Output Layer
        self.fc2 = nn.Linear(84, 10)

    def forward(self, x):
        x = F.tanh(self.conv1(x))
        x = self.pool1(x)
        x = F.tanh(self.conv2(x))
        x = self.pool2(x)
        x = F.tanh(self.conv3(x))
        # Flatten the output for the fully connected layer
        x = torch.flatten(x, 1)
        x = F.tanh(self.fc1(x))
        x = self.fc2(x)
        return F.softmax(x, dim=1)

# Create the model instance
model = MyCNN()

# Print the model summary (You'll need to provide a sample input size for this)
from torchsummary import summary
summary(model, (1, 28, 28))  # Assuming input shape is (1, 28, 28) for MNIST dataset

```
## AlexNet

![](https://i.imgur.com/S6eSsWF.png)

- winner of ILSVRC 2012

#### Novel features of AlexNet
- RELU activation function
- dropout layer
- data augmentation
- training on multiple GPUS
	- GTX580 with 3G MEmeory

AlexNet 병렬 처리:

![](https://i.imgur.com/lRu3dkB.png)


TOP-1, TOP-5 error
- class percentage 중 탑 1에 들어가는지, 탑5에 들어가는지

```
1 Cat: 70%
2 Dog: 20%
3 Horse: 5%
4 Motorcycle: 4%
5 Car: 0.6%
6 Plane: 0.4%
```


### Code

```python
# Instantiate an empty sequential model

model = Sequential(name="Alexnet")

# 1st layer (conv + pool + batchnorm)

model.add(Conv2D(filters= 96, kernel_size= (11,11), strides=(4,4), padding='valid', kernel_regularizer=l2(0.0005),

input_shape = (227,227,3)))

model.add(Activation('relu')) #<---- activation function can be added on its own layer or within the Conv2D function

model.add(MaxPool2D(pool_size=(3,3), strides= (2,2), padding='valid'))

model.add(BatchNormalization())

# 2nd layer (conv + pool + batchnorm)

model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same', kernel_regularizer=l2(0.0005)))

model.add(Activation('relu'))

model.add(MaxPool2D(pool_size=(3,3), strides=(2,2), padding='valid'))

model.add(BatchNormalization())

# layer 3 (conv + batchnorm) <--- note that the authors did not add a POOL layer here

model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', kernel_regularizer=l2(0.0005)))

model.add(Activation('relu'))

model.add(BatchNormalization())

# layer 4 (conv + batchnorm) <--- similar to layer 3

model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', kernel_regularizer=l2(0.0005)))

model.add(Activation('relu'))

model.add(BatchNormalization())

# layer 5 (conv + batchnorm)

model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', kernel_regularizer=l2(0.0005)))

model.add(Activation('relu'))

model.add(BatchNormalization())

model.add(MaxPool2D(pool_size=(3,3), strides=(2,2), padding='valid'))

  

# Flatten the CNN output to feed it with fully connected layers

model.add(Flatten())

  

# layer 6 (Dense layer + dropout)

model.add(Dense(units = 4096, activation = 'relu'))

model.add(Dropout(0.5))

  

# layer 7 (Dense layers)

model.add(Dense(units = 4096, activation = 'relu'))

model.add(Dropout(0.5))

# layer 8 (softmax output layer)

model.add(Dense(units = 1000, activation = 'softmax'))

  

# print the model summary

model.summary()


```


## VGGNet

![](https://i.imgur.com/TZ4hCp1.png)

- 2014년 옥스퍼드 대학의 Visual Geometry Group이 만듬
- 구성:
	- 16 weight layers
	- 13 convolutional layers
	- 3 fully connected layers
	- Convolutional layers
		- 3 x 3 kernel-sized filters
		- 1 stride
		- 1 padding value
	- Pooling layers
		- 
- 바닐라 CNN와 가장 비슷한 구조



RCNN