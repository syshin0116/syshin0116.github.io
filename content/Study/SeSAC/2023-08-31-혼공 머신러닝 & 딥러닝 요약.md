---
layout: post
title: "[SeSAC]혼공 머신러닝 & 딥러닝 요약"
date: 2023-08-31 14:23 +0900
categories:
  - SeSAC
  - 머신러닝 데이터분석
tags: []
math: true
---

# 1. Machine Learning

1. 지도 학습(Supervised-Learning)
	- Target(Label)이 있음
	- ex) 여태 배운 모델중 K-Means를 제외한 나머지
2. 비지도 학습(Unsupervised-Learning)
	- 라벨이 없음 → 성능 평가 불가
	- ex) K-means
3. 강화 학습(Reinforcement-Learning)
	- 라벨이 없음
	- 경험을 기반으로 학습해나감(?)
## 1-1. 모델(Model)
### 수학적 분류

1. **유사성 기반 학습 (Similarity-based Learning)**:
	- 새로운 데이터 포인트와 가장 유사한 학습 데이터 포인트를 찾아서 예측을 하는 방법
	- 예: KNN(K-Nearest Neighbors), K-Means
2. **정보 기반 학습 (Information-based Learning)**:
	- 데이터에서 가장 유용한 특성(정보)을 찾아내서 예측 모델을 구성
	- 예: Decision Trees, Random Forest
3. **확률 기반 학습 (Probability-based Learning)**:
	- 데이터의 확률 분포를 학습하여 예측을 하는 방법
4. **에러 기반 학습 (Error-based Learning)**:
	- 예측의 에러를 최소화하도록 모델을 조정하는 방법
	- 예: Linear Regression, Logistic, Lasso, Ridge, SGD(Stochatic Gradient Descent)

## 1-2. 성능 평가 & 비용 함수(Cost-Function)

### 성능 평가
1. $R^2$ : 회귀 모델 평가
2. Accuracy: 분류 모델 평가

#### $R^2$ (결정 계수)

$$R^2 = 1-\tfrac{오차^2}{편차^2} 
	= 1-\tfrac{\sum (예측값 - 실제값)^2}{\sum (실제값평균-실제값)^2}
	= 1-\tfrac{\sum (\widehat{y} - y)^2}{\sum (\bar{y}-y)^2}$$

- **해석**:
	- 값이 0과 1 사이에 있으며, 1에 가까울수록 모델이 데이터의 변동성을 잘 설명한다는 것을 의미
	- 반면, 0에 가까울수록 모델의 설명력이 떨어진다는 것을 의미

#### 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1 Score


![](https://i.imgur.com/pRzUU1i.png)

##### Accuracy (정확도)
 - 전체 예측 중 올바르게 예측된 비율

$$
\text{Accuracy} = \frac{\text{올바르게 예측된 샘플 수}}{\text{전체 샘플 수}}
$$

##### Precision (정밀도)
- 양성(positive)으로 예측된 샘플 중 실제로 양성인 비율

$$
\text{Precision} = \frac{\text{진짜 양성 (TP)}}{\text{진짜 양성 (TP) + 거짓 양성 (FP)}}
$$

##### Recall (재현율)
- Recall은 실제 양성(positive) 중 양성(positive)으로 올바르게 예측된 비율


$$
\text{Recall} = \frac{\text{진짜 양성 (TP)}}{\text{진짜 양성 (TP) + 거짓 음성 (FN)}}
$$

교수님 예시: 

|     | o, o, o, o, o, o, o, o, x, x | 정확도(A) | 정밀도(P) | 재현률(R) |
| --- | ---------------------------- | --------- | --------- | --------- |
| A   | o, o, o, o, o, o, o, o, o, x | 9/10      | 8/9       | 8/8       |
| B   | o, o, o, o, o, o, o, x, x, x | 9/10      | 7/9       | 7/8          |

##### F1 Score (F1 점수)
- Precision과 Recall의 조화 평균
$$
\text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
$$
### 비용 함수(Cost-Function)
1. MSE / RMSE
2. log-loss
3. hinge

- MSE는 예측 오차의 제곱 평균을 나타내며, 값이 낮을수록 좋다.
- RMSE는 MSE의 제곱근으로, 예측 오차의 실제 크기를 나타낸다.
- **$R^2$는 모델이 데이터의 변동성을 얼마나 잘 설명하는지를 나타내는 지표로, 1에 가까울수록 좋다.

#### 평균제곱근 오차, RMSE(Root Mean Squared Error)

$$\sqrt{\frac{1}{n}\sum_{i=1}^{n}((y-\widehat{y})^2)}$$

1. $n$: 데이터 포인트의 개수
2. $y_{i}$: 실제 관측된 값(데이터 포인트), 여기서 $i$는 데이터 포인트의 인덱스
3. $\widehat{y_{i}}$: 모델이 예측한 값,  실제 관측된 값과 모델이 예측한 값 사이의 차이
4. $(y_{i}-\widehat{y_{i}})^2$: 각 데이터 포인트에 대한 오차의 제곱. (실제 값과 예측 값의 차이를 제곱한 값)
5. $\sum_{i=1}^{n}$: 모든 데이터 포인트에 대해 오차 제곱을 합산하는 부분. ($i$는 1부터 $n$까지 변화한다.)
6. $\frac{1}{n}$: 데이터 포인트의 개수로 나눠줌으로써 오차 제곱의 평균을 계산
7. $\sqrt{\text{...}}$: 앞서 계산한 평균 오차 제곱을 제곱근을 취해 RMSE를 계산. (이것은 오차의 제곱 평균의 제곱근으로, 실제 값과 예측 값 사이의 평균적인 오차 크기를 나타낸다.)

**해석**:
- 예측 오차의 크기를 직관적으로 해석하기 쉽게 만듬
- 값이 낮을수록 모델의 성능이 좋다
#### 평균제곱 오차, MSE(Mean Squared Error)

$$\frac{1}{n}\sum_{i=1}^{n}((y-\widehat{y})^2)$$

**해석**: 
- MSE는 예측 오차의 제곱 평균
- RMSE에 제곱근을 취하지 않은 것
- 값이 낮을수록 모델의 성능이 좋다
- 오차를 나타내기 때문에 정확한 평가지표가 될 수 없다



#### 로지스틱 회귀의 비용 함수(Cost Function):

$$cost F = -(Plog_{e}\widehat{P})$$

- $P$: 실제 관측값을 나타낸다. 이 값은 0 또는 1일 수 있으며, 각 데이터 포인트의 실제 클래스를 나타낸다.
- $\widehat{P}$: 모델의 예측 확률을 나타낸다. 이 값은 로지스틱 함수를 통해 계산된 예측 확률이며, 0과 1 사이의 값이다.
- $\log_e$: 자연 로그(natural logarithm)를 나타낸다. 자연 로그는 $e$ (2.71828...)를 밑으로 하는 로그를 의미한다.


$$ J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \left[ p \log_{e}(\widehat{p})) + (1 - p) \log_{e}(1 - (\widehat{p})) \right] $$

##### 로지스틱 함수(Logistic Function), 시그모이드 함수(Sigmoid Function)

$$
h_\theta(x) = \frac{1}{1 + e^{-z}}
$$


* 미분 가능하면서 classification을 위해 고안된 함수
* `z` 에 선형회귀식 대입
* 선형회귀식을 z자리에 넣으면 곡선으로 바뀐다
* 로지스틱 함수의 값은 0에서 부터 1 사이의 값이 나온다

$$선형회귀식 = (W_{1}X_{1} + W_{2}X_{2}\cdots +W_{0}))$$
![](https://i.imgur.com/Ti1bntp.png)


## 1-3. Cross Validation (교차 검증) & Grid Search (그리드 검색)

### Cross Validation (교차 검증)

**정의**: 
- 모델의 일반화 성능을 평가하기 위한 통계적 방법
- 전체 데이터를 여러 서브셋으로 나누어, 각 서브셋을 학습 및 검증용으로 반복적으로 사용

**목적**:
- 모델의 성능을 보다 안정적으로 평가하기 위함
- 데이터의 편향을 최소화하여 과적합(overfitting)을 방지

**작동 과정:**
1. 데이터 분할: 데이터셋을 일정한 수의 분할(폴드)로 나눈다. 
	- 예를 들어, 5000개의 데이터가 있다면 1000개씩 5개의 폴드로 나눌 수 있다.
2. 모델 훈련과 평가: 분할된 데이터 중 일부(예를 들어, 4개의 폴드)를 선택하여 훈련 데이터로 사용하고, 나머지 1개의 폴드를 검증 데이터로 사용한다. 이때 검증 데이터는 모델의 성능을 평가하는데 사용된다.
3. 검증 성능 평가: 선택한 폴드를 검증 데이터로 사용해 모델을 훈련하고, 나머지 1개 폴드를 검증 데이터로 사용해 모델의 성능을 평가한다. 이렇게 하여 모델이 새로운 데이터에 얼마나 잘 일반화되는지를 평가한다.
4. 반복: 위의 과정을 각 폴드에 대해 번갈아가며 반복한다. 모든 폴드에 대해 각각 한 번씩 검증 데이터로 사용하면서 모델을 훈련하고 평가한다.
5. 평균 성능 계산: 모든 반복을 마치면 각 검증 데이터에서 얻은 성능 지표들을 평균내어 최종 성능 평가 지표를 계산한다. 이로서 모델의 일반화 성능을 더 신뢰할 수 있는 값으로 추정할 수 있다.
	
**유형**:
- k-Fold Cross Validation: 데이터를 k개의 서브셋으로 나누어 k번 검증을 반복
- Stratified k-Fold: 각 클래스의 비율을 유지하면서 데이터를 서브셋으로 분할
> - Leave-One-Out: 하나의 데이터 포인트를 제외한 나머지로 학습 후, 제외된 데이터 포인트로 검증

![](https://i.imgur.com/hCysTOA.png)

### Grid Search (그리드 검색)

****정의**:**
- 모델의 최적 하이퍼파라미터를 찾기 위한 방법
- 가능한 모든 하이퍼파라미터 조합을 시도하여 최적의 성능을 가지는 조합을 구한다

**목적**:
- 모델의 성능을 최대화하기 위해 가장 적합한 하이퍼파라미터 값을 찾는다

**작동 원리**:
- 지정된 범위 내의 모든 하이퍼파라미터 조합을 시도한다
- 각 조합에 대해 교차 검증을 수행하여 성능을 평가한다
- 가장 높은 성능을 보이는 하이퍼파라미터 조합을 선택한다


## 1-4. 트리의 앙상블(Ensemble)
- 목표: 과적합을 방지하고 모델의 분산을 줄여 전반적인 예측 성능을 향상
### Bagging(Bootstrap Aggregating)
- 정의: 복원추출 (bootstrapping)을 통해 생성된 여러 개의 서브셋을 활용해 독립적으로 여러 모델을 학습시키는 앙상블 방법
	- 부트스트랩: 
		- 데이터 세트에서 중복을 허용하여 데이터를 세는 기법
		- 1000개의 샘플이 있을 때, 먼저 1개를 뽑고 다시 가방에 넣어 그다음 샘플을 뽑는다
- 작동 원리:
	1. 원본 데이터 세트에서 복원추출을 통해 여러 개의 서브셋을 생성(부트스트랩)
	2. 각 서브셋에 대해 독립적으로 모델 학습
	3. 회귀 문제에서는 예측값의 평균을, 분류 문제에서는 투표 방식을 사용해 최종 예측
- 대표적인 알고리즘: Random Forest, Extra Tree
### Boosting
- 정의: Boosting은 약한 학습기를 순차적으로 훈련시켜 강한 학습기를 만드는 앙상블 방법이다.
- 작동 원리:
	1. 초기에는 모든 데이터 포인트에 동일한 가중치를 부여한다.
	2. 약한 학습기를 훈련시켜 오류를 줄인다.
	3. 잘못 분류된 데이터 포인트에 더 높은 가중치를 부여하고 다시 학습한다.

- 대표적인 알고리즘:  SGD, XG Boost, Light GBM, Histogradient Boosting, 그래디언트 부스팅 (Gradient Boosting)
### 요약
- 트레이닝 데이터에 대한 성능은 기본적으로 boosting이 bagging보다 더 좋다
- 배깅에 비해 부스팅이 과적합에 취약하다

### 혼잡도 & 불확실성 측정 방법 2가지
- 어떤 분할이 데이터를 더 잘 구분할 수 있는지를 평가
#### 정보 이득(Information Gain) & 엔트로피(Entropy)

##### 정보 이득(Information Gain)
- 특정 특성으로 노드를 분할할 때 얻게 되는 정보의 양
- 부모 노드의 엔트로피와 자식 노드들의 **가중 평균 엔트로피의 차이**로 계산
- 즉, 정보이득은 특정 분할을 통해 얼마나 많은 엔트로피(불확실성)를 감소시킬 수 있는지를 나타낸다

$$
\text{Information Gain} = \text{Entropy(parent)} - \sum \left( \frac{\text{no. of samples in child}}{\text{no. of samples in parent}} \times \text{Entropy(child)} \right)
$$
##### 엔트로피(Entropy)
- 데이터의 불확실성 혹은 혼잡도를 측정하는 지표
- 특정 노드의 데이터가 모두 동일한 클래스에 속하면 엔트로피는 0, 여러 클래스에 균등하게 분포되어 있을 경우 최대값

다중 클래스:

$$ \text{Entropy}(S) = - \sum_{i=1}^{c} p_i \log_2(p_i) $$

두 개의 클래스:

$$ \text{Entropy}(S) = -p_+ \log_2(p_+) - p_- \log_2(p_-) $$

- $p_+$: 양성 샘플의 비율
- $p_-$: 음성 샘플의 비율
- $c$: 클래스의 개수

##### Gini 불순도(Gini Impurity)
- 임의의 데이터 집합 내의 다양한 클래스의 분포를 측정하여 얼마나 '순수한' 상태인지를 나타내는 지표

다중 클래스:

$$Gini(D)=1−∑_{i=1}^c​p_{i}^2​$$

두 개의 클래스:

$$
\text{Gini Impurity}(S) = 1 - (p_+^2 + p_-^2)
$$

여기서,
- $D$: Data의 약자이며, 이 집합은 다양한 클래스의 샘플을 포함
- $S$: Subset의 약자이며, Data와 Subset은 교재에 따라 다르게 표시될 뿐 같은 의미로 사용
- $c$: 클래스의 개수
- $p_{i}$​: 데이터 집합 내에서 클래스 $i$에 속하는 샘플의 비율

> 예를 들어, 레드와인이 4개, 화이트와인이 6개라면?
> 
> $p_{red}=\frac{4}{10} =0.4$  및 $p_{white}=\frac{6}{10}=0.6$$
> 
> $Gini(D)=1−(p_{red}^2​+p_{white}^2​)$


### 주성분 분석(PCA: Principal Component Analysis)
**정의:**
- 고차원의 데이터를 저차원의 데이터로 변환하는 차원 축소 방법

> PCA 자체는 비지도 학습 방법이나 PCA로 차원이 축소된 데이터는 지도 학습에 활용될 수 있다

**목적:**
- 데이터의 차원을 줄여 계산 효율성을 높임
- 데이터 시각화를 용이하게 함
- 노이즈를 제거하여 데이터의 특징을 더 잘 나타내게 함

**주의:**
- PCA는 완벽 복원이 불가능하다
	- 역변환을 수행하면 재구성 오차(reconstruction error) 또는 복원 노이즈(restoration noise)가 발생한다

> 작동 원리:
> 1. 데이터의 공분산 행렬을 계산
> 2. 공분산 행렬의 고유값과 고유벡터를 찾음
> 3. 고유값이 큰 순서대로 K개(축소하려는 차원 수)의 고유벡터를 선택
> 4. 선택된 고유벡터를 사용하여 원래 데이터를 변환

# 2. Deep Learning

**딥러닝 (Deep Learning):** 
- 인공신경망을 기반으로 한 머신러닝의 한 분야로, 다층 구조의 신경망을 사용하여 복잡한 패턴을 학습하고 추론하는 기술을 의미

## 2-1. 인공신경망(Artificial Neural Network)
- **인공신경망**: 딥러닝의 기본 구조로, 노드(node)와 엣지(edge)로 연결된 계층적 구조를 가짐

### 퍼셉트론 (Perceptron)

퍼셉트론은 입력층과 출력층으로만 이루어진 단층 구조의 인공신경망이다. 입력값과 가중치의 선형 조합을 계산하고, 이 결과를 활성화 함수에 넣어 출력을 생성한다. 퍼셉트론은 이진 분류 문제에 사용되며, 선형적으로 분리 가능한 문제를 해결할 수 있다.

![](https://i.imgur.com/SHzBZr9.png)
프랭크 로젠블릿의 인간의 뉴런을 모방한 Perceptron 

**정의:** 
- 초기 인공신경망 모델 중 하나로, 프랑크 로젠블랫에 의해 개발

퍼셉트론의 구성
1. 입력층(Input Layer): 입력값이 들어오는 층
2. 가중치(Weight): 입력값에 각각의 가중치가 곱해져서 합산된다
3. 합산(Sum): 가중치와 입력값의 곱을 모두 합산한다
4. 활성화 함수(Activation Function): 합산된 결과에 활성화 함수를 적용하여 출력을 생성한다. 활성함수로는 주로 계단 함수, 시그모이드 함수, ReLU(Rectified Linear Activation) 함수 등이 사용된다
5. 출력(Output): 활성화 함수를 거친 결과가 출력된다

> 퍼셉트론의 한계는 XOR 문제와 같은 비선형 문제를 해결할 수 없다는 것이었으나, 이를 극복하기 위해 다층 퍼셉트론(MLP)와 같은 다양한 딥러닝 모델이 개발되었다.
> 
> 딥러닝은 퍼셉트론의 아이디어를 발전시켜, 비선형 활성화 함수, 다양한 레이어 및 연결 방식, 효율적인 학습 알고리즘 등을 포함하여 다층 구조의 인공신경망을 사용하는 방법을 지칭합니다. 따라서 딥러닝은 퍼셉트론의 제약을 극복하고, 다양한 문제를 해결할 수 있는 강력한 도구로 발전한 것입니다.

## 2-2. 딥러닝 계층 구조

![](https://i.imgur.com/O5WS2IT.png)

#### 1. 입력층 (Input Layer):
- 모델의 첫 번째 층으로, 데이터를 입력받는 역할을 함
- 각 노드는 데이터의 특성을 나타내며, 입력 데이터의 차원에 따라 노드 개수 결정
- 데이터를 그대로 전달하거나 간단한 전처리만 수행

#### 2. 은닉층 (Hidden Layer):
- 입력층과 출력층 사이에 위치하며, 중간 표현을 학습하는 역할을 함
- 입력 데이터를 가중치와 활성화 함수를 통해 변환하여 추상화된 특징을 학습
- 여러 은닉층 사용 시 복잡한 패턴과 특징을 더 깊게 학습 가능
- 중간 표현은 직접 확인하기 어렵지만, 출력층으로 전달되어 최종 결과를 생성

#### 3. 출력층 (Output Layer):
- 모델의 최종 출력을 생성하는 층
- 문제에 따라 다양한 형태로 구성됨 (이진 분류, 다중 클래스 분류, 회귀 등)
- 은닉층에서 학습된 중간 표현을 바탕으로 최종 결과 생성

## 2-3. 활성화 함수(Activation Function)
비선형 함수를 은닉층에 도입함으로써 모델은 비선형 관계를 학습하게 된다. 이러한 비선형 함수를 '활성화 함수'라고 한다.

#### ReLU (Rectified Linear Activation):
- **정의**: 입력 값이 양수일 경우 그대로 반환하고, 음수일 경우 0을 반환하는 함수.
- **장점**: 연산 비용이 낮고, 학습이 빠름.
- **주의점**: 음수 값에 대해 출력이 0이므로, 뉴런이 "죽을" 가능성이 있음.
#### 시그모이드 (Sigmoid):
- **정의**: 0과 1 사이의 값을 출력하는 S 형태의 함수.
- **장점**: 이진 분류 문제에서 출력층에 주로 사용.
- **주의점**: 활성화 값이 0 또는 1에 가까울 때 기울기가 소실되는 문제 발생 가능.
#### Leaky ReLU:
- **정의**: ReLU의 변형으로, 입력 값이 음수일 때도 작은 기울기를 갖는 함수.
- **장점**: "죽은" 뉴런 문제를 해결하려고 도입된 함수.
- **특징**: 작은 음수 기울기 값은 하이퍼파라미터로 설정 가능.
#### 은닉층에서 비선형 함수의 중요성

**표현력 향상**
- 은닉층 추가로 네트워크의 표현력은 향상됨
- 선형 함수(1차 방정식)만 사용시 여러 은닉층이 있어도 결과는 선형적(1차 방정식)인 관계만 표현
- 비선형 활성화 함수 도입으로 복잡한 패턴과 관계를 학습 가능

**복잡한 데이터 모델링**
- 대부분의 현실 세계 데이터는 복잡한 비선형 관계를 가짐
- 선형 함수만 사용시 이러한 관계를 제대로 포착 및 모델링 불가
- 비선형 활성화 함수를 사용하면 복잡한 관계도 학습 및 표현 가능

---
# 인공지능 관련 인물들

#### **Marvin Lee Minsky**:

- **정보**:
    - 1927년에 태어난 미국의 컴퓨터 과학자 및 인공지능 연구자
    - MIT 미디어 랩의 공동 창립자로, 인공지능 및 인지과학 분야에서 큰 영향을 끼침
    - 인간의 지능을 기호와 규칙으로 모델링하는 '기호주의자'로 알려짐.
    - 지식의 표현과 추론, 학습 및 기억 연구에 관심
    - "인공지능의 아버지" 중 한 명으로 불림
    - 심리학 및 컴퓨터 과학을 접목시켜 인간의 지능을 모델링하려는 노력을 기울임
    - "프레임(Frame)"이라는 개념을 소개하여 지식 표현을 발전시킴
    - '퍼셉트론(Perceptron)'의 한계를 지적함

#### **Frank Rosenblatt**:

- **정보**:
    - 1928년에 태어난 미국의 심리학자 및 컴퓨터 과학자.
    - "퍼셉트론(Perceptron)" 개념을 개발한 인공지능의 선구자 중 한 명.
    - 퍼셉트론은 초기 인공 신경망 모델로, 단순한 이진 분류를 수행하는 모델이다.
    - 기계 학습에서 신경망을 활용한 패턴 인식의 초기 기초를 마련한 인물로 평가됨.

#### **Geoffrey Everest Hinton**:

- **정보**:
    - 1947년에 태어난 캐나다의 컴퓨터 과학자.
    - '딥 러닝' 분야의 선구자 중 한 명으로 꼽힘.
    - 역전파 알고리즘을 개발하여 다층 퍼셉트론의 학습을 가능하게 함.
    - '드롭아웃(Dropout)'과 같은 기법을 도입하여 신경망의 과적합 문제를 해결하는데 기여.
    - 이미지 인식 등 다양한 분야에서 혁신적인 딥러닝 모델을 개발하며 인공지능 분야를 선도.

#### **Yann LeCun**:

- **정보**:
    - 1960년에 태어난 프랑스 출신의 컴퓨터 과학자 및 머신러닝 연구자.
    - "딥 러닝의 아버지"로 불리며, 현대 딥러닝의 발전에 큰 역할을 한 인물 중 하나.
    - 합성곱 신경망(CNN, Convolutional Neural Network)의 개념과 구조를 개발하여 컴퓨터 비전 분야에서의 중요한 기여를 함.
    - 손글씨 숫자를 인식하는 MNIST 데이터셋을 활용한 CNN의 성공적인 적용으로 유명.
    - 뉴욕대학교 (NYU) 교수이자, Facebook 인공지능 연구부 (FAIR)의 연구원이기도 함.


### 인공지능 파벌
#### **기호주의자(Symbolist or Symbolic AI)**:
- 기호와 기호 간의 관계에 중점을 둠.
- 추론과 논리를 핵심적인 요소로 간주.
- 수작업으로 시스템에 규칙과 지식을 프로그래밍하여 지능적 행동을 유도.
- 복잡한 지식을 처리하는 데 어려움이 있음.

#### **연결주의자(Connectionist or Connectionist AI)**:
- 뉴런과 신경망을 모방한 인공 신경망 활용.
- 데이터와 패턴을 학습하여 시스템이 스스로 지능적 행동을 개발하도록 함.
- 신경망을 통한 특징 추출, 패턴 학습, 문제 해결에 초점.
- 대량의 데이터와 학습이 필요하며 복잡한 문제에 강점을 보임.