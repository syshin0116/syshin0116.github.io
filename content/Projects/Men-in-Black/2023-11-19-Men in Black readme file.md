---
layout: post
title: Men in Black readme file
date: 2023-11-19 22:39 +0900
categories:
  - SeSAC
  - Project
tags: 
math: true
---
# Men-in-Black

## 1. ê°œìš”
- ë„ë¡œ êµí†µ ë²•ê·œ ìœ„ë°˜ ì°¨ëŸ‰ ê°ì§€
- ë„ë¡œ ìœ„ì˜ ì¼ìƒì ì¸ êµí†µ ë²•ê·œ ìœ„ë°˜, íŠ¹íˆ ì£¼ìš” ë„ë¡œì—ì„œì˜ ë¼ì–´ë“¤ê¸° ê°™ì€ í–‰ìœ„ëŠ” ë§ì€ ìš´ì „ìë“¤ì—ê²Œ ë¶ˆí¸í•¨ê³¼ ì•ˆì „ ìœ„í—˜ì„ ì´ˆë˜í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ìœ„ë°˜ í–‰ìœ„ë¥¼ ëª©ê²©í•˜ì—¬ë„, ì£¼í–‰ ì¤‘ ì‹ ê³ ê°€ ì–´ë ¤ì›Œ ì‹ ê³ ë¥¼ ë¯¸ë£¨ë‹¤ ê²°êµ­ í•˜ì§€ ì•Šê²Œ ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
- ë”°ë¼ì„œ ë³¸ í”„ë¡œì íŠ¸ì—ì„œ ì˜ìƒì„ í†µí•´ êµí†µ ë²•ê·œ ìœ„ë°˜ì„ ìë™ìœ¼ë¡œ íƒì§€í•˜ê³  ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ ê°œë°œí•˜ê³ ì í–ˆìŠµë‹ˆë‹¤.
- ì´ ëª¨ë¸ì„ ë‹¤ì–‘í•œ ë²•ê·œ ìœ„ë°˜ ìƒí™©ì„ ì‹ë³„í•˜ê³  ìë™ ì‹ ê³  ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬, ì•ˆì „í•˜ê³  ê³µì¥í•œ ë„ë¡œ í™˜ê²½ ì¡°ì„±ì— ê¸°ì—¬í•˜ê³ ì í•©ë‹ˆë‹¤.

## 2. í”„ë¡œì íŠ¸ êµ¬ì„± ë° ë‹´ë‹¹ì

### [Line Violation Detection](https://github.com/SeSAC-Men-in-Black/Men-in-Black/tree/074ad63391bab45290966de5b0f9d747f9a252ae/Line%20violation%20detection) by [ì§„í•œë³„](https://github.com/Moonbyeol)
<details>
<summary>Details</summary>

## ì§„í–‰ ê³¼ì •:

1. ì°¨ëŸ‰ ì¸ì‹
2. ì°¨ì„  ì¸ì‹
3. ìœ„ë°˜ íƒì§€ì§€

## ëª¨ë¸ êµ¬ì„± ë° ë¶„ë¥˜:

### 1. ì°¨ëŸ‰ ì¸ì‹ ëª¨ë¸
   
    a. ëª¨ë¸ êµ¬ì„±
   
       â…°. Detection Model : Mask R-CNN
   
       â…±. BackBone Network : ResNet101
   
       â…². BackBone Pre-trained : torchvision://resnet101
   
       â…³. Loss function : SeesawLoss
   
       â…´. Optimizer : SGD, lr ì´ˆê¸°ê°’: 1e-6
   
    b. Class ë¶„ë¥˜
   
       â…°. ì´ë¥œì°¨(vehicle_bike) : 10066
   
       â…±. ë²„ìŠ¤(vehicle_bus) : 75198
   
       â…². ìŠ¹ìš©ì°¨(vehicle_car) : 232013
   
       â…³. íŠ¸ëŸ­(vehicle_truck) : 28905

### 2. ì°¨ì„  ì¸ì‹ ëª¨ë¸

    a. ëª¨ë¸ êµ¬ì„±
   
       â…°. Detection Model : FCN(Fully Convolutional Network)
   
       â…±. BackBone Network : ResNet50
   
       â…². Loss function : FocalLoss
   
       â…³. Optimizer : Adam, lr ì´ˆê¸°ê°’: 0.001
   
    b. Class ë¶„ë¥˜
   
       â…°. ìƒ‰ìƒë³„
   
           1) ì²­ìƒ‰(lane_blue) : 133654
   
           2) ê°“ê¸¸ì°¨ì„ (lane_shoulder) : 55639
   
           3) í°ìƒ‰(lane_white) : 128181
   
           4) í™©ìƒ‰(lane_yellow) : 29554
   
       â…±. íƒ€ì…ë³„
   
            1) 1ì¤„ ì ì„ (single_dashed) : 78953
   
            2) 1ì¤„ ì‹¤ì„ (single_solid) : 181342
   
            3) 2ì¤„ ì‹¤ì„ (double_solid) : 84914
   
            4) ì¢Œì ì„ _ìš°ì‹¤ì„ (left_dashed_double) : 1095
   
            5) ì¢Œì‹¤ì„ _ìš°ì ì„ (right_dashed_double) : 724
   

### 3. ìœ„ë°˜ íƒì§€ ëª¨ë¸

    a. ëª¨ë¸ êµ¬ì„±
   
       â…°. Detection Model : ResNet18
   
       â…±. Loss function : CrossEntropyLoss
   
       â…². Optimizer : SGD, lr ì´ˆê¸°ê°’: 0.001
   
    b. Class ë¶„ë¥˜
   
       â…°. ì •ìƒ(normal): 197618
   
       â…±. ìœ„í—˜(danger): 31229
   
       â…². ìœ„ë°˜(violation): 117335
   
    c. ìœ„ë°˜ íƒì§€ ê³¼ì •
   
       â…°. ì •ìƒ
![image](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/140053617/2e074200-ff13-47c8-9781-ea10440611ae)

![image](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/140053617/a0ce2c45-06a2-4d8b-a9a9-1856df83fd89)

![image](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/140053617/8fc3ccee-c625-48f9-a12c-6e77046a8507)
   
       â…±. ìœ„í—˜
![image](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/140053617/7d8d9cea-9e1d-4f7b-8391-93abd1474d1b)

![image](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/140053617/f463b8a0-07ad-4f24-b5fb-65cd146aa369)

![image](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/140053617/4e0f5535-8d59-4045-87c9-d13ea7040ba2)
   
        â…². ìœ„ë°˜
![image](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/140053617/139735ea-e164-4e1f-9834-fd0bec7cd076)

![image](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/140053617/8cc27f2e-a4d5-484e-b559-e01796cd88c3)

![image](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/140053617/1c059bb2-0456-4fd9-bcd8-7a576c1e315c)




</details>

### [Traffic Light Recognition](https://github.com/SeSAC-Men-in-Black/Men-in-Black/tree/main/Traffic-Light-Recognition) by [ìµœìš°ì„](https://github.com/Wangws1004)
<details>
<summary>Details</summary>
<br>
</details>

### [License Plate Recognition](https://github.com/SeSAC-Men-in-Black/Men-in-Black/tree/main/Automatic%20License%20Plate%20Recognition) by [ì‹ ìŠ¹ì—½](https://github.com/syshin0116)
<details>
<summary>Details</summary>

## ì§„í–‰ ê³¼ì •:

1. ì°¨ëŸ‰ ê°ì§€(Vehicle Detection)
    
2. ë²ˆí˜¸íŒ ê°ì§€(License Plate Detection)
    
3. OCR(Optical Character Recognition)
    

## 1. ì°¨ëŸ‰ ê°ì§€(Vehicle Detection)

- Model: Yolov8n, Yolov8m
    
- Dataset: COCO Dataset
    
    - 330K images (>200K labeled)
        
    - 1.5 million object instances
        
    - 80 object categories
        
- Classes: Car, Motorcycle, Bus, Truck
    

YOLO model structure

![](https://i.imgur.com/eFgToyo.png)


### ì°¨ëŸ‰ íŠ¸ë˜í‚¹(Object Tracking)

- model: Sort
    
    - A simple online and realtime tracking algorithm for 2D multiple object tracking in video sequences
        
- [GitHub - abewley/sort: Simple, online, and realtime tracking of multiple objects in a video sequence.](https://github.com/abewley/sort)
    

###   2. ë²ˆí˜¸íŒ ê°ì§€(License Plate Detection)

- Model: Yolov8m 50 epoch, 120epoch
    
- Dataset:Â \[Roboflow][License Plate Recognition Object Detection Dataset (v4, resized640_aug3x-ACCURATE) by Roboflow Universe Projects](https://universe.roboflow.com/roboflow-universe-projects/license-plate-recognition-rxg4e/dataset/4 "https://universe.roboflow.com/roboflow-universe-projects/license-plate-recognition-rxg4e/dataset/4")
    
    - 24242 images
        
        - Augmentations
            
            - Flip: Horizontal
                
            - Crop: 0% Minimum Zoom, 15% Maximum Zoom
                
            - Rotation: Between -10Â° and +10Â°
                
            - Shear: Â±2Â° Horizontal, Â±2Â° Vertical
                
            - Grayscale: Apply to 10% of images
                
            - Hue: Between -15Â° and +15Â°
                
            - Saturation: Between -15% and +15%
                
            - Brightness: Between -15% and +15%
                
            - Exposure: Between -15% and +15%
                
            - Blur: Up to 0.5px
                
            - Cutout: 5 boxes with 2% size each
                
- Training:
    

hyper parameters:

`task=detect, mode=train, model=yolov8m.pt, data=/content/License_plate_recognition/dataset/License-Plate-Recognition-4/data.yaml, epochs=500, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=license_plate_detection_yolov8m, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=license_plate_detection_yolov8m/train`

model summary:

`from n params module arguments 0 -1 1 1392 ultralytics.nn.modules.conv.Conv [3, 48, 3, 2] 1 -1 1 41664 ultralytics.nn.modules.conv.Conv [48, 96, 3, 2] 2 -1 2 111360 ultralytics.nn.modules.block.C2f [96, 96, 2, True] 3 -1 1 166272 ultralytics.nn.modules.conv.Conv [96, 192, 3, 2] 4 -1 4 813312 ultralytics.nn.modules.block.C2f [192, 192, 4, True] 5 -1 1 664320 ultralytics.nn.modules.conv.Conv [192, 384, 3, 2] 6 -1 4 3248640 ultralytics.nn.modules.block.C2f [384, 384, 4, True] 7 -1 1 1991808 ultralytics.nn.modules.conv.Conv [384, 576, 3, 2] 8 -1 2 3985920 ultralytics.nn.modules.block.C2f [576, 576, 2, True] 9 -1 1 831168 ultralytics.nn.modules.block.SPPF [576, 576, 5] 10 -1 1 0 torch.nn.modules.upsampling.Upsample [None, 2, 'nearest'] 11 [-1, 6] 1 0 ultralytics.nn.modules.conv.Concat [1] 12 -1 2 1993728 ultralytics.nn.modules.block.C2f [960, 384, 2] 13 -1 1 0 torch.nn.modules.upsampling.Upsample [None, 2, 'nearest'] 14 [-1, 4] 1 0 ultralytics.nn.modules.conv.Concat [1] 15 -1 2 517632 ultralytics.nn.modules.block.C2f [576, 192, 2] 16 -1 1 332160 ultralytics.nn.modules.conv.Conv [192, 192, 3, 2] 17 [-1, 12] 1 0 ultralytics.nn.modules.conv.Concat [1] 18 -1 2 1846272 ultralytics.nn.modules.block.C2f [576, 384, 2] 19 -1 1 1327872 ultralytics.nn.modules.conv.Conv [384, 384, 3, 2] 20 [-1, 9] 1 0 ultralytics.nn.modules.conv.Concat [1] 21 -1 2 4207104 ultralytics.nn.modules.block.C2f [960, 576, 2] 22 [15, 18, 21] 1 3776275 ultralytics.nn.modules.head.Detect [1, [192, 384, 576]] Model summary: 295 layers, 25856899 parameters, 25856883 gradients`

optimizer: SGD(lr=0.01, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)

Image sizes: 640 train, 640 val

#### WandB

![](https://i.imgur.com/wKFGARx.png)

![](https://i.imgur.com/ZwzZCZh.png)

![](https://i.imgur.com/iGsTw9O.png)

![](https://i.imgur.com/AKzo4Tz.png)

![](https://i.imgur.com/UKG85j0.png)

![](https://i.imgur.com/1B8dgOW.png)

![](https://i.imgur.com/Ml5ZYbH.png)

![](https://i.imgur.com/p7nY8Mx.png)

## 3. OCR(Optical Character Recognition)

Model: EasyOCR

Preprocessing steps:

1. **Grayscale Conversion**: This simplifies the image by removing color information, making further processing faster and focusing on intensity.
    
2. **Contrast Enhancement with CLAHE (Contrast Limited Adaptive Histogram Equalization)**: Improves the contrast of the image, making details more distinct, especially useful in varying lighting conditions.
    
3. **Gaussian Blur**: Reduces noise and smoothes the image, which can help in reducing false edges detected in the subsequent edge detection step.
    
4. **Canny Edge Detection**: Identifies edges in the image. This is useful for finding the boundaries of objects, in this case, the license plate.
    
5. **Finding Contours and Perspective Transformation**: Identifies contours in the image and, if a rectangular contour (assumed to be the license plate) is found, applies a perspective transformation to get a front-facing view of the license plate.
    

Original Image:

![](https://i.imgur.com/63v2mMO.png)


Detected Car:

![](https://i.imgur.com/50zAgWN.png)


Grayscale:

![](https://i.imgur.com/3h2XYY4.png)

CLAHE:

![](https://i.imgur.com/Nt70a3p.png)

Gaussian Blur:

![](https://i.imgur.com/I0Cg8wH.png)


Canny Edge Detection:

![](https://i.imgur.com/vEbTsXy.png)

## Attempts and Failure:

- Tracking cars with yolov8:
    
    - worse outputs compared to Sort, took longer timeâ†’ attempted at early stages, improved output expected
        
- Clips from Dashboard cam:
    
    - Car and License Plates were well detected, but video quality too low for OCR
        
    - phenomenon occurred more frequently when relative speed of vehicle was faster
        

## Room for Improvements:

- Try variety of Object Detection models for comparison
    
- Try variety of OCR models for comparison(TesseractOCR, PaddleOCR)
    
- Enhance Video Quality for better detection and recognition
    
- Try Segmentation
</details>

### [Monocular Depth Estimation](https://github.com/syshin0116/Men-in-Black/tree/main/Monocular%20Depth%20Estimation)
- [ZoeDepth](https://github.com/syshin0116/Men-in-Black/tree/main/Monocular%20Depth%20Estimation/ZoeDepth) by [ì‹ ìŠ¹ì—½](https://github.com/syshin0116)
- [VDE](https://github.com/syshin0116/Men-in-Black/tree/main/Monocular%20Depth%20Estimation/VDE) by [ì§„í•œë³„](https://github.com/Moonbyeol)
- [MonoDepth2](https://github.com/syshin0116/Men-in-Black/tree/main/Monocular%20Depth%20Estimation/MonoDepth2) by [ì´í˜„ì§€](https://github.com/FrontHeadNULL)
- [End-to-end-Learning](https://github.com/syshin0116/Men-in-Black/tree/main/Monocular%20Depth%20Estimation/End-to-end-Learning) by [ìµœìš°ì„](https://github.com/Wangws1004)

## 3. ë°ì´í„°ì…‹

#### [COCO Dataset](https://cocodataset.org/#home)
- 330K images (>200K labeled)
- 1.5 million object instances
- 80 object categories
- Classes: Car, Motorcycle, Bus, Truck

![](https://i.imgur.com/X6FioAe.png)




#### [\[Roboflow\]License Plate Recognition Object Detection Dataset (v4, resized640_aug3x-ACCURATE)](https://universe.roboflow.com/roboflow-universe-projects/license-plate-recognition-rxg4e/dataset/4)
- 24242 images
- ë°ì´í„° ì¦ê°•(Augmentation)
  - Flip: Horizontal 
  - Crop: 0% Minimum Zoom, 15% Maximum Zoom 
  - Rotation: Between -10Â° and +10Â° 
  - Shear: Â±2Â° Horizontal, Â±2Â° Vertical 
  - Grayscale: Apply to 10% of images 
  - Hue: Between -15Â° and +15Â° 
  - Saturation: Between -15% and +15% 
  - Brightness: Between -15% and +15% 
  - Exposure: Between -15% and +15% 
  - Blur: Up to 0.5px 
  - Cutout: 5 boxes with 2% size each
 
![](https://i.imgur.com/CqP6mNG.png)


 #### [\[AIHUB\]ì°¨ë¡œ ìœ„ë°˜ ì˜ìƒ ë°ì´í„°](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=628)
 - 80,000ì¥ ì´ë¯¸ì§€
 - ì›ì‹œ ë°ì´í„° í¬ë§¥ ì˜ˆì‹œ(ë™ì˜ìƒ)
   - MP4 í¬ë§·ì˜ ë™ì˜ìƒ í´ë¦½
   - FHD í•´ìƒë„
   - ì´ˆë‹¹ 5 í”„ë ˆì„
 - ì›ì²œë°ì´í„° í¬ë§· ì˜ˆì‹œ(ì´ë¯¸ì§€ ì¶”ì¶œ ë° ë¹„ì‹ë³„í™” ì´í›„)
   - JPG í¬ë§¥ ì´ë¯¸ì§€ ì‹¤ ì˜ˆì‹œ
   - FHD í•´ìƒë„
   - ë¹„ì‹ë³„í™” ì²˜ë¦¬(ì‚¬ëŒì–¼êµ´, ìë™ì°¨ ë²ˆí˜¸íŒ, ê°œì¸ ì „í™”ë²ˆí˜¸ ë“±)

![](https://i.imgur.com/8PRmusV.png)

## 4. ì‚¬ìš© íˆ´

| Category 	| Techs 	|
|---	|:---:	|
| ğŸ–¥ï¸ ê°œë°œ  	| ![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) ![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white) ![PyCharm](https://img.shields.io/badge/pycharm-143?style=for-the-badge&logo=pycharm&logoColor=black&color=black&labelColor=green) ![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white) ![OpenCV](https://img.shields.io/badge/opencv-%23white.svg?style=for-the-badge&logo=opencv&logoColor=white) ![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white) ![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)|
| â˜ï¸ í™˜ê²½ 	| ![nVIDIA](https://img.shields.io/badge/nVIDIA-%2376B900.svg?style=for-the-badge&logo=nVIDIA&logoColor=white) ![Anaconda](https://img.shields.io/badge/Anaconda-%2344A833.svg?style=for-the-badge&logo=anaconda&logoColor=white) ![Ubuntu](https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=ubuntu&logoColor=white) ![AWS](https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white)|
| ğŸ“‹ í˜‘ì—… 	| ![Notion](https://img.shields.io/badge/Notion-%23000000.svg?style=for-the-badge&logo=notion&logoColor=white) ![Git](https://img.shields.io/badge/git-%23F05033.svg?style=for-the-badge&logo=git&logoColor=white) ![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white) ![Slack](https://img.shields.io/badge/Slack-4A154B?style=for-the-badge&logo=slack&logoColor=white) ![Jira](https://img.shields.io/badge/jira-%230A0FFF.svg?style=for-the-badge&logo=jira&logoColor=white)|

## 5. í”„ë¡œì íŠ¸ ì¼ì • 

![](https://i.imgur.com/35Cr1cR.png)

![image](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/140369529/0c31325c-acec-4954-a768-e079714aa469)


## 6. ëª¨ë¸ êµ¬ì¡°

![KakaoTalk_20231221_173206463](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/140053617/09883330-4bb9-4651-9688-28010e4458c9)
![KakaoTalk_20231208_151131324](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/140053617/9f171f80-f9a8-4ffc-8ff1-b17b0f7967dd)

## 7. ê²°ê³¼

### Line Violation Detection
![](https://i.imgur.com/Y0zF3xK.gif)

### Traffic Light Recognition
![](https://i.imgur.com/l8Pfqdw.gif)

### License Plate Recognition
![](https://i.imgur.com/hGnGJXv.gif)
![á„‡á…¥á†«á„’á…©á„‘á…¡á†«_result](https://github.com/SeSAC-Men-in-Black/Men-in-Black/assets/99532836/78355fa4-4104-4a43-a21f-9ab55822a435)


### Monocular Depth Estimation
![](https://i.imgur.com/tZfKRJr.gif)


## 8. ì°¸ê³  ë¬¸í—Œ

- Bhat, Shariq Farooq, et al. â€œZoedepth: Zero-Shot Transfer by Combining Relative and Metric Depth.â€ arXiv.Org, 23 Feb. 2023, arxiv.org/abs/2302.12288. 
- Birkl, Reiner, et al. â€œMidas V3.1 -- a Model Zoo for Robust Monocular Relative Depth Estimation.â€ arXiv.Org, 26 July 2023, arxiv.org/abs/2307.14460. 
- Godard, ClÃ©ment, et al. â€œDigging into Self-Supervised Monocular Depth Estimation.â€ arXiv.Org, 17 Aug. 2019, arxiv.org/abs/1806.01260. 
- He, Kaiming, et al. â€œMask R-CNN.â€ arXiv.Org, 24 Jan. 2018, arxiv.org/abs/1703.06870. 
- Lee, Seungyoo, et al. â€œVehicle Distance Estimation from a Monocular Camera for Advanced Driver Assistance Systems.â€ MDPI, Multidisciplinary Digital Publishing Institute, 15 Dec. 2022, www.mdpi.com/2073-8994/14/12/2657. 
- Lin, Tsung-Yi, et al. â€œMicrosoft Coco: Common Objects in Context.â€ arXiv.Org, 21 Feb. 2015, arxiv.org/abs/1405.0312. 
- Ranftl, RenÃ©, et al. â€œTowards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer.â€ arXiv.Org, 25 Aug. 2020, arxiv.org/abs/1907.01341. 
- Reis, Dillon, et al. â€œReal-Time Flying Object Detection with Yolov8.â€ arXiv.Org, 17 May 2023, arxiv.org/abs/2305.09972. 
- Song, Zhenbo, et al. â€œEnd-to-End Learning for Inter-Vehicle Distance and Relative Velocity Estimation in ADAS with a Monocular Camera.â€ arXiv.Org, 9 June 2020, arxiv.org/abs/2006.04082. 

